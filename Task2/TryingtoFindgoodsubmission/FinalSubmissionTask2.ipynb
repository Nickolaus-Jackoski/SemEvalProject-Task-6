{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 999,
     "referenced_widgets": [
      "7951853f82364d3782572e69f50598db",
      "3a709296b2f44b5fbb4bd681978a8fd0",
      "3fd632ef5b1b4f0a9a7c986c5b69c4db",
      "a7bf384a94424e71aba9abdd5474e372",
      "33b61975737748bd987739578c1d0b6e",
      "b6cf625834504111b146b784226f1c1c",
      "36d16b7e8342450bb25b45ed8e559c8c",
      "8bfffa004e81414ea10d37cf07278f64",
      "4bda800561fe4fc0be00c42a35a33011",
      "3071d849d4df4575becbb345256564c8",
      "7bb5f259b86042ed8d62a4007cd0c8eb",
      "a9052c7ec18f4d8bbaa76fefb7624402",
      "e7f865608b704f8899eb1b0817452454",
      "e062465897fd4cd680e19027191d9e1a",
      "283860b88c6647bfbe4d61b8d09cc9f2",
      "ca3b07641dca40a0b004c7f7af74f85d",
      "37e0f86431164e74962d03814411cc5b",
      "e6dff39ac12f48baa2a5292071874495",
      "94d02f0546444e36a79b0830213af4a9",
      "178a17ea59544aeb8b893b7cd254adb4",
      "cc242ddfceb14b4782005e77e9b6233c",
      "61e3106c64ff4c3b993f99113e8ec1aa",
      "48b4338010cb441e96fd011b7e62374a",
      "804cd50f62ed4348afe24e4b05d46db7",
      "51ffe4cee22f4f98a4a66623d972321a",
      "9479c4fe77db47a7955fe14e029e9fc0",
      "207a78560abb4d1fb2b946e90bf646d6",
      "d0ebb3393f7e4fb1a015250a93e6a620",
      "f18a700a3f9c4f3a945282097c43cbf5",
      "3f7bf9978a664bfe8db5760cca1b015c",
      "9460b0a6e70e48b4913d089e76467f8a",
      "aa86b7e219fb4908bf822d7b0ba11b1c",
      "7516667b796d4fc1bf949ed9bc873e0c",
      "40c3c90a4e9148f59f199faa99453436",
      "6b7ea07d553c43749cf08712b7075932",
      "4db0cb2b502b4c4b84f81d9725b650ae",
      "e16df741e0294430a3e6cc8e3d60af9c",
      "0121671b3980475ea39c018f10f4a372",
      "c558b0e8a4df4b2dbee2ca7dbbdc2658",
      "d3350fc1340f43799404fee3db1be4f6",
      "48e4cc2d033840fda221f8064808c330",
      "c91c3241831749c3b6adb96aab98d97a",
      "6be8280bd0034cf496a7dddf1509d73f",
      "4c3de596be854c21a13521ad30e6f6f0",
      "43579cd3539f4ef2b4b7de0df5cce4af",
      "ba800c7dbede4bf5bb82ae3324aeb21a",
      "5efb7cd539ea43b28523babbba0325ed",
      "6e074743de8941fc81b53cd06b0befbe",
      "01394268edea4c2caa43df147e0df8a3",
      "314dda94da464075a847313f67ace137",
      "b26ebb807520442f9b4c6f22e0974588",
      "6611a632942c4e269f22fce50a89b817",
      "88e51311fd174122834eaf4cf867ed18",
      "25e663ec92c74c17b83af142ebe1e713",
      "eac35d1401c841cb8a1d6d5f358329fc",
      "6c951f52330041449c4900179c2a3aee",
      "0209338715114b3db822ebfc08d205af",
      "1cab19a791c54115982389832bd3ccd7",
      "567a540a7de14dd09c3c2c000dfa2521",
      "c0d01d8a969241b3aa41807a68cd98e5",
      "4de30e46ec0842b8b726daa54e649323",
      "7e6cbb38514845a8b121c5a3ff6d635f",
      "5c8413b9a7324b238e4386e9fca5271a",
      "7d16c739326b41b3ac7c3e4d0f39ce4b",
      "b10f22efe5284ff692f5f88ee9650425",
      "2da4daf6c20e4825a898192bb832fec7",
      "1411e986cad44895b36cfb0b3425ecf0",
      "edc567625d524a168d4fe54b728a8326",
      "19ba70712d274ed88d75a8f1082ab7ed",
      "cf7b9964843d414bb3e527a359d532b7",
      "d42db1dc288e4a46a1fe03545193f636",
      "cb2c0a74cc734373b514d1b2f954831e",
      "de6ebbcbd8a642b78a63c462f30a8bde",
      "0c0d5772d6eb49ffafced05ad02ec31f",
      "d48e77287fe54a5ebc3044bf20faab6e",
      "67b1d76c273e44729679429687389119",
      "65fc078e06154d459d01b005266600f0",
      "a0f3554882884f3bac409cd9d94b86e7",
      "186f420ff0294639b3d32f69ccafc643",
      "b5bb5cc292124f7aa027e45b27e2aba1",
      "8281eb1fd44c4fdf81e64a5fc33e79db",
      "2ae85ce3570b4e499af7565402cccef5",
      "0af4c15acb94412283cf661e2e5de476",
      "d7210990abe54e8ab8a90aaf44402180",
      "2e6bb49d33b6414f90b8691c4c36e98b",
      "c6140460d208449893199ae01a77e2e5",
      "6eeb06733a19401e808103e985803302",
      "e93a07bb9ccc432e8c06daf9701c284e",
      "89b6f9e2795749c59bc7b3db4dc63ef3",
      "f0ecc55989b6497f9527078c408cb250",
      "52ff36097ead4ee8bf5c9986c5a66f5e",
      "fb0225e18b654f4fba7d81817e3d52de",
      "99438ca3c913431ea1d686fb2c586962",
      "c26a328559c8492090808a24b50b1a47",
      "a96161195efd4e0b922e981705ba5e05",
      "a771895483a847769bfa0328608a7147",
      "0f2a6dfc997e4f019370f726078c7ac3",
      "821ffe90fd2748d38c36f99af7d800a8",
      "1aa66db13b9148568e3c07e6518fc4cb",
      "1157a57e30684000b366994816ae4e59",
      "ae2f427a6ef94c298b8890c52b2a8b68",
      "2fab8aba4e854a38adc9edebda28a605",
      "78a6d303bc454297943c5881aab5a36f",
      "16a3dcba6c33445baf644caaa4b9b786",
      "993ad3428a7a41b4ba3e3f9c8f119020",
      "92458acec78c4dceb592897d44574078",
      "f3970631ef2a4fac93da479f1d32560f",
      "3ad0b0a3eb3249518e3225c9b0636d94",
      "83ead4f1f4f644d0813b762a0160b044",
      "9a3e2e580ecf474b90006009b04b6593",
      "dee5897aa4e34415a575cc247812a3a5",
      "a12b7835e8f04dbb820e46618e1adc40",
      "3f007374976f448fad24cb8ef9fc4151",
      "3447d77267e94acd91dc1c7ba5c635f1",
      "8ada80f8c1ec464786697a636a1fd9eb",
      "2b43f5a56ee54e6badeac99844b79e5b",
      "006c383e9e2d4dc487f61a13e474fd1d",
      "aebe4a7245a341a8968abe676fed5893",
      "1d15d4a37f8345eeaf5f805809eb3017",
      "2ed040148eb94d2fb2f36e48b11cdd10",
      "b2c27d041cfb4f74a36bc39993379e22",
      "9f8e3c016a4149fb817d028282898b07",
      "8397802f53a84f0ebaacfa223d33bf50",
      "92f68db5336e4205955a5f14b213d472",
      "5333af980be44576a8a40cb2804ec402",
      "ffbbc09b20a7417e9e15d7f81a865e05",
      "5d73b8a0158446059e980794eac0d021",
      "bf071f0432014d1d987170fb1257686d",
      "527d733f849a46a1849a824b5ad8ec64",
      "89b439b3f3914a13bff6b09e74290407",
      "998ab460ca2c46758936703215a68dfb",
      "b638dfd943c04f3c83afb2d1a864293e",
      "8dbaddc49dda408994730a64d1a40301",
      "cbeee2b477a6422fa0977869a10ad504",
      "e8acebb2033242fe9465e648ed6e62e2",
      "d2943704651947d89dbcad0423072f18",
      "5a740c25daf842719eff4ec1b6123c5c",
      "9620b112365e4296a32dc864d89e6ec2",
      "feb1811d14994df78b1e1685ffcda393",
      "716813282e1648f29dd62bc4c84418b9",
      "a06c7d4a7871491ea4dc10942caf9eae",
      "69906eb62f9d463d81076b4621c70c13",
      "d81064223efd4ed7b7c95bb546a0eb06",
      "8f795c53ffc948c7aca9dbbd67451ba3",
      "ad613818d3db413da149c8582da023ce",
      "94158320cffa499bbb7e0aa985b28349",
      "f91e3ea5f0c0431aa64c9b09b2b3488e",
      "02c91c0248b44177bb97aa2d964aba1c",
      "b6bbb2974e0c4d54afde7debae4d1aea",
      "096f18b3eda24f86bfe7f1a18da4c023",
      "562d3b1d25d24c84a8cc7e2c14d865f1",
      "1661e461cb154a8faf44a41498b07e79",
      "0973358aed5c4ebebe62be2761f981ad",
      "819ad9a08fe0491abfa860036791fe9f",
      "7b133db8cfa049c49e3db3757f494d08",
      "a3de5f24458f455ea6524aaf9b4980e7",
      "891e6d0ba14c4e9d917275773b7e6ba6",
      "a6c8375746c14602809c0ea65279b0ba",
      "e48eafaa0b094d938ab6cb68886c197c",
      "558fcff058cd429cb953d4433f51dde0",
      "2d57561a8f1c4dc5955888ced2aa77bb",
      "3b0d8b1b40ca4b7eaa2ffe913246d700",
      "2ee38acc8ff74661994502ebbbadf3ba",
      "dc70976aaaf64e78a6754fa831a7798f",
      "c47a1d4625c246e88965c4aba4636d11",
      "8362a434663c4ad2b6ce4015642db8a0",
      "a76a1682dc794ec7afd50a12c7982e43",
      "3704296b5e3c423b98af55b737ac025e",
      "28bd7e03973849b691ada079591cd00d",
      "714886dd025448c89cc8150d3a11f1b0",
      "e4bf4d47388d47e7b47055ad7f902c46",
      "93dff939e6c64b72bf4732393f5d7f29",
      "19df045374c749e6917f5782a24352b6",
      "123d23cb5a5a4efea72fe0314d97712a",
      "a2ab6989a5084ca1a479c2f8ac8e4cc1",
      "6e5c7684db9543fbb34998f57ca7a246"
     ]
    },
    "id": "av05ebPh2gKh",
    "outputId": "04eebfe3-abd6-4d4c-9d5e-f84e96c15bde"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7951853f82364d3782572e69f50598db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9052c7ec18f4d8bbaa76fefb7624402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/3.90M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b4338010cb441e96fd011b7e62374a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/259k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c3c90a4e9148f59f199faa99453436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43579cd3539f4ef2b4b7de0df5cce4af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c951f52330041449c4900179c2a3aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1411e986cad44895b36cfb0b3425ecf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f3554882884f3bac409cd9d94b86e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b6f9e2795749c59bc7b3db4dc63ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1157a57e30684000b366994816ae4e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee5897aa4e34415a575cc247812a3a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8e3c016a4149fb817d028282898b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dbaddc49dda408994730a64d1a40301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f795c53ffc948c7aca9dbbd67451ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b133db8cfa049c49e3db3757f494d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/874M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8362a434663c4ad2b6ce4015642db8a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/874M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2808' max='2808' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2808/2808 28:48, Epoch 13/13]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.749300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.577700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.314500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.158700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_c14b1e62-f514-446a-86b2-16184e3370ee\", \"submission.csv\", 4136)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install -q transformers datasets scikit-learn accelerate torch pandas\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from google.colab import files\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "set_seed(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "MODEL_NAME = \"microsoft/deberta-v3-large\"\n",
    "OUTPUT_DIR = \"./deberta_v3_final_submission\"\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 4\n",
    "GRAD_ACCUMULATION = 4\n",
    "LR = 8e-6\n",
    "EPOCHS = 13\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"ailsntua/QEvasion\")\n",
    "\n",
    "def preprocess_text(example):\n",
    "    clarity = example.get(\"clarity_label\", \"Unknown\")\n",
    "    if clarity is None:\n",
    "        clarity = \"Unknown\"\n",
    "    text = f\"Context: {clarity} | Question: {example['question']} Answer: {example['interview_answer']}\"\n",
    "    return {\"text\": text, \"evasion_label\": example.get(\"evasion_label\", -1)}\n",
    "\n",
    "\n",
    "train_ds = dataset[\"train\"].map(preprocess_text)\n",
    "\n",
    "if \"test\" in dataset:\n",
    "    test_ds = dataset[\"test\"].map(preprocess_text)\n",
    "else:\n",
    "    raise ValueError(\"Test set not found in QEvasion dataset!\")\n",
    "\n",
    "# encode labels on training set\n",
    "train_ds = train_ds.class_encode_column(\"evasion_label\")\n",
    "labels = train_ds.features[\"evasion_label\"].names\n",
    "label2id = {l: i for i, l in enumerate(labels)}\n",
    "id2label = {i: l for l, i in label2id.items()}\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "    )\n",
    "\n",
    "train_ds = train_ds.map(tokenize_fn, batched=True)\n",
    "test_ds = test_ds.map(tokenize_fn, batched=True)\n",
    "\n",
    "# set labels\n",
    "train_ds = train_ds.map(lambda x: {\"labels\": x[\"evasion_label\"]})\n",
    "\n",
    "y_train = train_ds[\"evasion_label\"]\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train,\n",
    ")\n",
    "class_weights_tensor = torch.tensor(\n",
    "    class_weights,\n",
    "    dtype=torch.float,\n",
    ").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class ProTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\", None)\n",
    "        if logits is None:\n",
    "            logits = outputs[0]\n",
    "\n",
    "        loss_fct = nn.CrossEntropyLoss(\n",
    "            weight=class_weights_tensor,\n",
    "            label_smoothing=0.1,\n",
    "        )\n",
    "        loss = loss_fct(\n",
    "            logits.view(-1, self.model.config.num_labels),\n",
    "            labels.view(-1),\n",
    "        )\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    learning_rate=LR,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=GRAD_ACCUMULATION,\n",
    "    num_train_epochs=EPOCHS,\n",
    "\n",
    "    weight_decay=0.05,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "\n",
    "    eval_strategy=\"no\",      # no dev trains on all data\n",
    "    save_strategy=\"no\",\n",
    "    load_best_model_at_end=False,\n",
    "\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "trainer = ProTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "if \"index\" not in test_ds.column_names:\n",
    "    test_ds = test_ds.add_column(\"index\", range(len(test_ds)))\n",
    "\n",
    "test_preds = trainer.predict(test_ds)\n",
    "pred_ids = np.argmax(test_preds.predictions, axis=-1)\n",
    "pred_labels = [id2label[p] for p in pred_ids]\n",
    "\n",
    "out_df = pd.DataFrame(\n",
    "    {\n",
    "        \"index\": test_ds[\"index\"],\n",
    "        \"evasion_label\": pred_labels,\n",
    "    }\n",
    ")\n",
    "out_df.to_csv(\"submission.csv\", index=False)\n",
    "files.download(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kcqBWO_Z_MDy",
    "outputId": "d57feeb9-f7c3-4006-b5c7-9753a8fb0a18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evasion_label\n",
      "Implicit               85\n",
      "Explicit               79\n",
      "Dodging                43\n",
      "General                42\n",
      "Deflection             33\n",
      "Declining to answer    12\n",
      "Claims ignorance        7\n",
      "Clarification           4\n",
      "Partial/half-answer     3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"submission.csv\")\n",
    "\n",
    "print(df[\"evasion_label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lKR53GyQ_MW4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
