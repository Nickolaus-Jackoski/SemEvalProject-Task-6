{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "A100"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VHZf23bKjPsC"
   },
   "outputs": [],
   "source": [
    "!pip install -q \"transformers>=4.45.0\" \"datasets>=2.20.0\" \"peft>=0.18.0\" \"accelerate>=1.2.0\" bitsandbytes scikit-learn huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359,
     "referenced_widgets": [
      "61cd5c607eae4cc7a2425fcf049e6ddf",
      "d85c4da1744447de8f28dddbba9aefe6",
      "3839b1b389ba4b81b95ec212d10f0312",
      "fa029fada22241b6adbcd18a77500e92",
      "188341082a9144f58c0082c69a555710",
      "79e885057f3c4105a103dc71dd6f3867",
      "c8f2efee5357429186217680dd316fe8",
      "5bce5c4ff6ae4c178737fadd2fe46e40",
      "83be05beb774485daa5a20374c27249a",
      "d434d778d74b4682b5ca7ab4cc0ec5e3",
      "4b8183be418f4803ac91446fde729321",
      "2f423ce5084d403991be80b0aef513f2",
      "32dbda2c404a4c9e819bba3956621785",
      "a7a8209ff5974c7eaaa384b16b8dc718",
      "281f91b122864f5b98df95b3da0cca14",
      "6b22792f52ae42e6929a72a66054dfbb",
      "4c3961635c464ba9af0dac33a6266dcb"
     ]
    },
    "id": "wfCV7PpNlH25",
    "outputId": "35330232-9346-4e6e-d7fb-5219c7721e5f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61cd5c607eae4cc7a2425fcf049e6ddf"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount(\"/content/drive\")\n",
    "cache_dir = \"/content/drive/MyDrive/hf_cache\"\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "os.environ[\"HF_HOME\"] = cache_dir\n",
    "\n",
    "print(f\"Hugging Face cache: {cache_dir}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iOjJBP_NmwYx",
    "outputId": "84f4a624-5e2b-4bed-9fdd-70b5b64c463a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Hugging Face cache is now set to: /content/drive/MyDrive/hf_cache\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%%writefile task2_inference_fix.py\n",
    "import argparse\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "from typing import List, Dict\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from peft import PeftModel\n",
    "\n",
    "EVASION_LABEL_DESCRIPTIONS = {\n",
    "    \"Claims ignorance\": \"The speaker says they do not know or are not aware.\",\n",
    "    \"Clarification\": \"The speaker clarifies or asks for clarification.\",\n",
    "    \"Declining to answer\": \"The speaker explicitly refuses to answer.\",\n",
    "    \"Deflection\": \"The speaker changes the subject.\",\n",
    "    \"Dodging\": \"The speaker avoids answering without explicitly refusing.\",\n",
    "    \"Explicit\": \"The speaker directly answers.\",\n",
    "    \"General\": \"The speaker answers vaguely.\",\n",
    "    \"Implicit\": \"The speaker implies the answer without stating it clearly.\",\n",
    "    \"Partial/half-answer\": \"The speaker answers only part of the question.\",\n",
    "}\n",
    "\n",
    "def build_label_mappings(labels: List[str]):\n",
    "    uniq = sorted(set(labels))\n",
    "    label2id = {lab: i for i, lab in enumerate(uniq)}\n",
    "    id2label = {i: lab for lab, i in label2id.items()}\n",
    "    return label2id, id2label\n",
    "\n",
    "def build_prompt(question, full_question, answer, inference_mode=False):\n",
    "    # force inference_mode=False to match the training data format\n",
    "    q = (question or \"\").strip()\n",
    "    if not q: q = (full_question or \"\").strip()\n",
    "\n",
    "    system_instructions = (\n",
    "        \"You are an expert at analyzing political and media interviews.\\n\"\n",
    "        \"Your task is to classify an answer into one of the following evasion techniques:\\n\\n\"\n",
    "    )\n",
    "\n",
    "    label_list_str = \"\"\n",
    "    for name, desc in EVASION_LABEL_DESCRIPTIONS.items():\n",
    "        label_list_str += f\"- {name}: {desc}\\n\"\n",
    "\n",
    "    user_block = (\n",
    "        f\"Question: {q}\\n\"\n",
    "        f\"Answer: {answer.strip()}\\n\\n\"\n",
    "        \"From the list above, which single evasion label best describes this answer?\\n\"\n",
    "        \"Respond with exactly one label name (no extra words).\\n\"\n",
    "        \"Evasion label:\"\n",
    "    )\n",
    "    return system_instructions + label_list_str + \"\\n\" + user_block\n",
    "\n",
    "def extract_label_robust(text, valid_labels):\n",
    "    text = text.strip()\n",
    "    # check exact match first\n",
    "    for lab in valid_labels:\n",
    "        if lab.lower() == text.lower():\n",
    "            return lab\n",
    "    # check starts with\n",
    "    for lab in valid_labels:\n",
    "        if text.lower().startswith(lab.lower()):\n",
    "            return lab\n",
    "    # check contains\n",
    "    for lab in valid_labels:\n",
    "        if lab.lower() in text.lower():\n",
    "            return lab\n",
    "    return \"Explicit\"\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--base_model\", type=str, default=\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "    parser.add_argument(\"--adapter_dir\", type=str, required=True) # Where your training saved\n",
    "    parser.add_argument(\"--output_file\", type=str, default=\"task2_predictions_fixed.csv\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "\n",
    "    print(\"Loading Dataset...\")\n",
    "    raw = load_dataset(\"ailsntua/QEvasion\")\n",
    "    if \"test\" not in raw:\n",
    "        print(\"Warning: No test split found, using dev as dummy test.\")\n",
    "        test_raw = raw[\"train\"].select(range(10))\n",
    "    else:\n",
    "        test_raw = raw[\"test\"]\n",
    "\n",
    "    train_raw = raw[\"train\"]\n",
    "    label2id, id2label = build_label_mappings(train_raw[\"evasion_label\"])\n",
    "    label_ids = [label2id[l] for l in train_raw[\"evasion_label\"]]\n",
    "    train_raw = train_raw.add_column(\"evasion_label_id\", label_ids)\n",
    "    train_raw = train_raw.class_encode_column(\"evasion_label_id\")\n",
    "\n",
    "    splits = train_raw.train_test_split(test_size=0.1, stratify_by_column=\"evasion_label_id\", seed=42)\n",
    "    dev_ds = splits[\"test\"]\n",
    "\n",
    "    print(f\"Loading Base Model: {args.base_model}...\")\n",
    "    bnb_cfg = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.base_model)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        args.base_model,\n",
    "        quantization_config=bnb_cfg,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "\n",
    "    checkpoints = sorted(glob.glob(os.path.join(args.adapter_dir, \"checkpoint-*\")), key=os.path.getmtime)\n",
    "    if checkpoints:\n",
    "        adapter_path = checkpoints[-1]\n",
    "        print(f\"Found checkpoint: {adapter_path}\")\n",
    "    else:\n",
    "        adapter_path = args.adapter_dir\n",
    "        print(f\"Using root dir: {adapter_path}\")\n",
    "\n",
    "    print(\"Loading LoRA Adapter...\")\n",
    "    model = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "    model.eval()\n",
    "\n",
    "    print(\"\\nStarting FIXED Inference (Direct, No CoT, Repetition Penalty)...\")\n",
    "\n",
    "    def run_predict(dataset, desc):\n",
    "        preds = []\n",
    "        golds = []\n",
    "\n",
    "        # Generation config to stop looping\n",
    "        gen_config = {\n",
    "            \"max_new_tokens\": 10,\n",
    "            \"do_sample\": False,\n",
    "            \"repetition_penalty\": 1.2,\n",
    "            \"pad_token_id\": tokenizer.pad_token_id,\n",
    "            \"eos_token_id\": tokenizer.eos_token_id\n",
    "        }\n",
    "\n",
    "        for i, row in enumerate(dataset):\n",
    "            q = row.get(\"question\", row.get(\"interview_question\"))\n",
    "            iq = row.get(\"interview_question\", q)\n",
    "            a = row.get(\"interview_answer\")\n",
    "\n",
    "            prompt = build_prompt(q, iq, a, inference_mode=False)\n",
    "            inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                out = model.generate(**inputs, **gen_config)\n",
    "\n",
    "            gen_text = tokenizer.decode(out[0][inputs.input_ids.shape[-1]:], skip_special_tokens=True)\n",
    "            pred = extract_label_robust(gen_text, list(label2id.keys()))\n",
    "            preds.append(pred)\n",
    "\n",
    "            if \"evasion_label\" in row:\n",
    "                golds.append(row[\"evasion_label\"])\n",
    "\n",
    "            if i % 50 == 0:\n",
    "                print(f\"[{desc}] {i}/{len(dataset)} | Gen: {gen_text.strip()} -> Pred: {pred}\")\n",
    "\n",
    "        return preds, golds\n",
    "\n",
    "    # check Dev Score\n",
    "    dev_preds, dev_golds = run_predict(dev_ds, \"DEV\")\n",
    "    dev_ids = [label2id[g] for g in dev_golds]\n",
    "    pred_ids = [label2id[p] for p in dev_preds]\n",
    "\n",
    "    macro_f1 = f1_score(dev_ids, pred_ids, average=\"macro\")\n",
    "    print(f\"\\n=== NEW MACRO F1 SCORE: {macro_f1:.4f} ===\")\n",
    "\n",
    "    print(\"Generating Test Predictions...\")\n",
    "    test_preds, _ = run_predict(test_raw, \"TEST\")\n",
    "\n",
    "    out_path = os.path.join(args.adapter_dir, args.output_file)\n",
    "    df = pd.DataFrame({\"index\": test_raw[\"index\"], \"evasion_label\": test_preds})\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"Saved predictions to: {out_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "id": "oe6mEVaOkvhv",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "04ebc922-c714-4549-9893-cf6a5b9ed2c9"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Writing task2_inference_fix.py\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ[\"HF_HOME\"] = \"/content/hf_cache\""
   ],
   "metadata": {
    "id": "ydl1p-RMpRyy"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!python task2_inference_fix.py \\\n",
    "    --adapter_dir \"/content/drive/MyDrive/SemEval_Clarity/v2_results\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g0KkUqooogxY",
    "outputId": "0564c4f2-da72-4b1c-8bb8-0473aa824fe0"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2025-11-28 04:07:55.522352: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-28 04:07:55.541100: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764302875.563577   70659 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764302875.570436   70659 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1764302875.587496   70659 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764302875.587523   70659 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764302875.587526   70659 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764302875.587528   70659 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-28 04:07:55.592509: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Loading Dataset...\n",
      "README.md: 12.7kB [00:00, 24.6MB/s]\n",
      "data/train-00000-of-00001.parquet: 100% 3.90M/3.90M [00:00<00:00, 6.91MB/s]\n",
      "data/test-00000-of-00001.parquet: 100% 259k/259k [00:00<00:00, 1.25MB/s]\n",
      "Generating train split: 100% 3448/3448 [00:00<00:00, 51646.72 examples/s]\n",
      "Generating test split: 100% 308/308 [00:00<00:00, 48772.82 examples/s]\n",
      "Stringifying the column: 100% 3448/3448 [00:00<00:00, 115776.26 examples/s]\n",
      "Casting to class labels: 100% 3448/3448 [00:00<00:00, 113768.00 examples/s]\n",
      "Loading Base Model: meta-llama/Meta-Llama-3-8B-Instruct...\n",
      "tokenizer_config.json: 100% 51.0k/51.0k [00:00<00:00, 5.06MB/s]\n",
      "tokenizer.json: 100% 9.09M/9.09M [00:00<00:00, 29.5MB/s]\n",
      "special_tokens_map.json: 100% 73.0/73.0 [00:00<00:00, 762kB/s]\n",
      "config.json: 100% 654/654 [00:00<00:00, 7.31MB/s]\n",
      "model.safetensors.index.json: 100% 23.9k/23.9k [00:00<00:00, 123MB/s]\n",
      "Fetching 4 files:   0% 0/4 [00:00<?, ?it/s]\n",
      "model-00002-of-00004.safetensors:   0% 0.00/5.00G [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   0% 0.00/4.98G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:   0% 0.00/1.17G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   0% 0.00/4.92G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   0% 500k/5.00G [00:00<2:01:45, 684kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   0% 816k/4.92G [00:01<3:09:02, 433kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:   1% 8.44M/1.17G [00:02<05:04, 3.80MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   0% 23.3k/4.98G [00:02<133:08:49, 10.4kB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   1% 67.6M/5.00G [00:02<02:32, 32.4MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   5% 269M/5.00G [00:02<00:30, 156MB/s]  \u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   0% 43.8k/4.98G [00:02<73:12:56, 18.9kB/s] \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  10% 120M/1.17G [00:02<00:17, 60.2MB/s] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   0% 1.18M/4.98G [00:02<1:50:03, 753kB/s]  \u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   9% 470M/5.00G [00:02<00:19, 238MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  12% 605M/5.00G [00:04<00:26, 169MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  16% 807M/5.00G [00:04<00:17, 235MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   1% 67.9M/4.92G [00:04<04:46, 16.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  16% 187M/1.17G [00:04<00:22, 43.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  17% 874M/5.00G [00:04<00:17, 234MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  19% 941M/5.00G [00:05<00:18, 225MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  22% 255M/1.17G [00:05<00:16, 55.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   3% 135M/4.92G [00:05<02:31, 31.5MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  28% 322M/1.17G [00:05<00:10, 80.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   4% 202M/4.92G [00:05<01:25, 55.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  39% 456M/1.17G [00:06<00:05, 124MB/s] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  45% 523M/1.17G [00:06<00:04, 136MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  52% 605M/1.17G [00:06<00:03, 159MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  20% 1.01G/5.00G [00:06<00:34, 115MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  58% 672M/1.17G [00:09<00:08, 62.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   6% 271M/4.92G [00:09<02:41, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  75% 873M/1.17G [00:09<00:02, 128MB/s] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  11% 539M/4.92G [00:09<00:48, 90.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   0% 1.48M/4.98G [00:09<10:09:57, 136kB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   0% 1.66M/4.98G [00:10<8:25:00, 164kB/s] \u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   0% 1.91M/4.98G [00:10<6:16:55, 220kB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   0% 2.10M/4.98G [00:10<5:03:50, 273kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  14% 673M/4.92G [00:10<00:36, 115MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  86% 1.01G/1.17G [00:10<00:01, 145MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  19% 941M/4.92G [00:10<00:19, 202MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  23% 1.14G/5.00G [00:10<01:02, 62.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  22% 1.08G/4.92G [00:11<00:20, 185MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   1% 25.2M/4.98G [00:21<46:54, 1.76MB/s] \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  23% 1.14G/4.92G [00:21<01:46, 35.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  94% 1.10G/1.17G [00:22<00:02, 27.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  25% 1.21G/4.92G [00:22<01:30, 41.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  24% 1.21G/5.00G [00:22<03:08, 20.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  26% 1.28G/4.92G [00:22<01:12, 50.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  27% 1.34G/4.92G [00:22<01:00, 59.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  26% 1.28G/5.00G [00:22<02:29, 24.9MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   1% 66.0M/4.98G [00:22<15:15, 5.36MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors: 100% 1.17G/1.17G [00:23<00:00, 49.3MB/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  29% 1.41G/4.92G [00:23<00:57, 60.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  30% 1.48G/4.92G [00:24<00:46, 73.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  28% 1.41G/5.00G [00:24<01:43, 34.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  31% 1.54G/4.92G [00:24<00:39, 84.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  30% 1.48G/5.00G [00:24<01:24, 41.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  33% 1.61G/4.92G [00:24<00:32, 103MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  31% 1.54G/5.00G [00:24<01:04, 53.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  34% 1.68G/4.92G [00:24<00:24, 135MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  32% 1.61G/5.00G [00:25<00:49, 68.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  35% 1.75G/4.92G [00:25<00:19, 161MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  35% 1.75G/5.00G [00:25<00:30, 106MB/s] \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  37% 1.81G/4.92G [00:25<00:24, 129MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  36% 1.81G/5.00G [00:26<00:32, 98.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  38% 1.88G/4.92G [00:26<00:24, 122MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  38% 1.88G/5.00G [00:26<00:28, 109MB/s] \u001b[A\n",
      "model-00002-of-00004.safetensors:  39% 1.95G/5.00G [00:29<00:48, 63.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  40% 1.95G/4.92G [00:29<00:49, 59.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  40% 2.01G/5.00G [00:29<00:35, 83.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  44% 2.15G/4.92G [00:29<00:21, 127MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  43% 2.15G/5.00G [00:29<00:20, 138MB/s] \u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   3% 133M/4.98G [00:29<10:33, 7.65MB/s] \u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   4% 200M/4.98G [00:29<05:35, 14.2MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  44% 2.21G/5.00G [00:29<00:18, 147MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   7% 334M/4.98G [00:29<02:22, 32.5MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  46% 2.28G/5.00G [00:29<00:15, 176MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  45% 2.22G/4.92G [00:29<00:22, 118MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  50% 2.48G/5.00G [00:30<00:08, 301MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  51% 2.55G/5.00G [00:30<00:09, 261MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  48% 2.35G/4.92G [00:30<00:18, 140MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  52% 2.62G/5.00G [00:36<00:51, 46.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  49% 2.42G/4.92G [00:40<01:33, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  54% 2.69G/5.00G [00:41<01:18, 29.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  51% 2.49G/4.92G [00:41<01:14, 32.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  55% 2.75G/5.00G [00:41<01:00, 37.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  52% 2.55G/4.92G [00:41<00:56, 41.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  56% 2.82G/5.00G [00:41<00:45, 47.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  53% 2.62G/4.92G [00:41<00:44, 52.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  58% 2.89G/5.00G [00:42<00:35, 59.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  55% 2.69G/4.92G [00:42<00:34, 65.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  59% 2.96G/5.00G [00:42<00:28, 70.9MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   7% 334M/4.98G [00:42<02:22, 32.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  56% 2.75G/4.92G [00:43<00:31, 67.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   7% 334M/4.98G [00:43<08:50, 8.75MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  57% 2.82G/4.92G [00:43<00:24, 85.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  60% 3.02G/5.00G [00:43<00:27, 70.8MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   7% 335M/4.98G [00:43<09:03, 8.54MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  59% 2.89G/4.92G [00:43<00:20, 99.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  63% 3.16G/5.00G [00:44<00:18, 99.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  60% 2.96G/4.92G [00:44<00:18, 108MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  64% 3.22G/5.00G [00:44<00:14, 124MB/s] \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  61% 3.02G/4.92G [00:44<00:13, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  66% 3.29G/5.00G [00:44<00:11, 147MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  63% 3.09G/4.92G [00:44<00:10, 171MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  67% 3.36G/5.00G [00:45<00:11, 147MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  64% 3.16G/4.92G [00:45<00:13, 132MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  68% 3.42G/5.00G [00:45<00:11, 132MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  66% 3.22G/4.92G [00:46<00:13, 123MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  70% 3.49G/5.00G [00:46<00:10, 141MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  67% 3.29G/4.92G [00:46<00:11, 144MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  71% 3.56G/5.00G [00:48<00:19, 73.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  68% 3.36G/4.92G [00:48<00:19, 78.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  72% 3.62G/5.00G [00:48<00:15, 88.8MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  74% 3.69G/5.00G [00:48<00:11, 119MB/s] \u001b[A\n",
      "model-00002-of-00004.safetensors:  75% 3.76G/5.00G [00:48<00:07, 155MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  70% 3.42G/4.92G [00:48<00:18, 81.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  77% 3.83G/5.00G [00:48<00:06, 175MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  72% 3.56G/4.92G [00:49<00:09, 139MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   8% 402M/4.98G [00:49<07:35, 10.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  74% 3.62G/4.92G [00:49<00:07, 162MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  78% 3.89G/5.00G [00:49<00:05, 189MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  79% 3.96G/5.00G [00:49<00:04, 240MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  76% 3.76G/4.92G [00:49<00:04, 237MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  82% 4.09G/5.00G [00:49<00:03, 245MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  79% 3.89G/4.92G [00:50<00:04, 224MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   9% 471M/4.98G [00:50<05:04, 14.8MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  83% 4.13G/5.00G [00:54<00:18, 47.9MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  10% 484M/4.98G [00:55<07:15, 10.3MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  84% 4.20G/5.00G [00:55<00:17, 46.2MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  10% 519M/4.98G [00:59<07:58, 9.32MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  81% 3.98G/4.92G [01:00<00:31, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  85% 4.26G/5.00G [01:00<00:26, 27.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  82% 4.04G/4.92G [01:00<00:23, 36.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  84% 4.11G/4.92G [01:00<00:17, 46.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  87% 4.33G/5.00G [01:01<00:18, 35.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  85% 4.18G/4.92G [01:00<00:12, 59.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  88% 4.40G/5.00G [01:01<00:12, 47.3MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  12% 586M/4.98G [01:01<05:15, 13.9MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  89% 4.47G/5.00G [01:01<00:08, 61.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  86% 4.25G/4.92G [01:01<00:10, 64.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  88% 4.31G/4.92G [01:02<00:08, 72.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  89% 4.38G/4.92G [01:02<00:05, 94.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  91% 4.53G/5.00G [01:02<00:07, 61.6MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  13% 653M/4.98G [01:02<03:45, 19.2MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  92% 4.60G/5.00G [01:02<00:04, 82.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  90% 4.45G/4.92G [01:03<00:04, 106MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  93% 4.66G/5.00G [01:03<00:03, 106MB/s] \u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  14% 678M/4.98G [01:03<03:12, 22.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  15% 738M/4.98G [01:03<02:03, 34.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  16% 805M/4.98G [01:03<01:21, 51.3MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  95% 4.73G/5.00G [01:03<00:02, 113MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  93% 4.58G/4.92G [01:03<00:02, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  18% 872M/4.98G [01:03<00:56, 72.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  19% 939M/4.98G [01:03<00:41, 96.5MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  96% 4.80G/5.00G [01:03<00:01, 126MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  20% 1.01G/4.98G [01:03<00:30, 131MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  21% 1.06G/4.98G [01:04<00:25, 154MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  23% 1.13G/4.98G [01:04<00:19, 194MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  24% 1.19G/4.98G [01:04<00:17, 220MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  96% 4.71G/4.92G [01:06<00:02, 75.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  25% 1.26G/4.98G [01:06<00:49, 75.8MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  97% 4.87G/5.00G [01:06<00:02, 56.0MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  29% 1.46G/4.98G [01:06<00:21, 166MB/s] \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  97% 4.78G/4.92G [01:06<00:01, 91.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  32% 1.60G/4.98G [01:06<00:14, 238MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  99% 4.93G/5.00G [01:07<00:00, 72.5MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  35% 1.73G/4.98G [01:07<00:10, 313MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  37% 1.83G/4.98G [01:07<00:08, 382MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  40% 1.98G/4.98G [01:07<00:05, 514MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors: 100% 5.00G/5.00G [01:07<00:00, 74.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  43% 2.13G/4.98G [01:07<00:07, 395MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  99% 4.85G/4.92G [01:08<00:00, 74.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  45% 2.24G/4.98G [01:08<00:08, 338MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  46% 2.31G/4.98G [01:08<00:08, 301MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors: 100% 4.92G/4.92G [01:08<00:00, 71.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  48% 2.37G/4.98G [01:10<00:25, 103MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  51% 2.52G/4.98G [01:10<00:15, 163MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  53% 2.65G/4.98G [01:11<00:09, 233MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  56% 2.78G/4.98G [01:11<00:07, 307MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  59% 2.95G/4.98G [01:11<00:04, 436MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  63% 3.16G/4.98G [01:11<00:03, 600MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  67% 3.31G/4.98G [01:11<00:02, 574MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  69% 3.41G/4.98G [01:12<00:03, 502MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  71% 3.55G/4.98G [01:12<00:03, 392MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  73% 3.61G/4.98G [01:12<00:03, 394MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  74% 3.68G/4.98G [01:12<00:03, 383MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  75% 3.74G/4.98G [01:13<00:03, 381MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  76% 3.80G/4.98G [01:13<00:03, 351MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  78% 3.87G/4.98G [01:13<00:03, 319MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  80% 3.97G/4.98G [01:13<00:03, 325MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  81% 4.04G/4.98G [01:14<00:03, 306MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  82% 4.10G/4.98G [01:14<00:02, 302MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  87% 4.31G/4.98G [01:14<00:01, 463MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  88% 4.37G/4.98G [01:14<00:01, 446MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  91% 4.51G/4.98G [01:15<00:00, 503MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  92% 4.57G/4.98G [01:15<00:00, 472MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  93% 4.64G/4.98G [01:15<00:00, 449MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  95% 4.71G/4.98G [01:15<00:00, 394MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors: 100% 4.98G/4.98G [01:15<00:00, 65.7MB/s]\n",
      "Fetching 4 files: 100% 4/4 [01:15<00:00, 18.97s/it]\n",
      "Loading checkpoint shards: 100% 4/4 [00:17<00:00,  4.33s/it]\n",
      "generation_config.json: 100% 187/187 [00:00<00:00, 1.87MB/s]\n",
      "Found checkpoint: /content/drive/MyDrive/SemEval_Clarity/v2_results/checkpoint-582\n",
      "Loading LoRA Adapter...\n",
      "\n",
      "Starting FIXED Inference (Direct, No CoT, Repetition Penalty)...\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "[DEV] 0/345 | Gen: Explicit\n",
      "Evasion description: Explicitly states that -> Pred: Explicit\n",
      "[DEV] 50/345 | Gen: Explicit: Explicitly states that Rumsfeld will -> Pred: Explicit\n",
      "[DEV] 100/345 | Gen: Dodging\n",
      "The President dodges the original question -> Pred: Dodging\n",
      "[DEV] 150/345 | Gen: Implicit: Implicitly acknowledges that busing is a -> Pred: Implicit\n",
      "[DEV] 200/345 | Gen: Explicit\n",
      "Evasion description: Explicitly states the -> Pred: Explicit\n",
      "[DEV] 250/345 | Gen: Claims ignorance\n",
      "Evasion description: Claims ignorance -> Pred: Claims ignorance\n",
      "[DEV] 300/345 | Gen: Explicit\n",
      "Evasion description: Explicitly states the -> Pred: Explicit\n",
      "\n",
      "=== NEW MACRO F1 SCORE: 0.3227 ===\n",
      "Generating Test Predictions...\n",
      "[TEST] 0/308 | Gen: Dodging\n",
      "The answer dodges the original question -> Pred: Dodging\n",
      "[TEST] 50/308 | Gen: Explicit\n",
      "Evasion description: Explicitly states all -> Pred: Explicit\n",
      "[TEST] 100/308 | Gen: General\n",
      "Evasion description: General\n",
      "\n",
      "The answer -> Pred: General\n",
      "[TEST] 150/308 | Gen: Explicit\n",
      "Evasion description: Explicitly states that -> Pred: Explicit\n",
      "[TEST] 200/308 | Gen: Explicit\n",
      "Evasion description: Explicit: Dodging -> Pred: Explicit\n",
      "[TEST] 250/308 | Gen: Implicit: Implicitly states that the Defense Secretary has -> Pred: Implicit\n",
      "[TEST] 300/308 | Gen: Clarification\n",
      "Clarification: Clarify or ask -> Pred: Clarification\n",
      "Saved predictions to: /content/drive/MyDrive/SemEval_Clarity/v2_results/task2_predictions_fixed.csv\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "wDRy3Gz6ojYV"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}