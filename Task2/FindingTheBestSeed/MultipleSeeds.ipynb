{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q23JnlAHtCTH"
   },
   "source": [
    "Trying multiple different seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "19b5e10f2c004a70b76c9f7df6da52c8",
      "9e0134032bcb4d71a3196c1f231dd486",
      "b24eeb2a40b8413a8275ee3f68246833",
      "7c4f4384f88645a4ad338c1b4c43cf3e",
      "6ff27766144041178b7a9ea5898c7c07",
      "b3407b23c0d0401bb6c090672221cd53",
      "3c7a9c1d7f404eb48c9fb9f9e7ca5472",
      "d73d2845d2f64b2082cb39928943bc57",
      "ae80762323e84586b58fb211fbe2b853",
      "0cce4303217742de918ed24a6ff24ac7",
      "47c5e1b506f14d0491c0721e3ff87aef",
      "c927e07bbdb349c9b857a0aed3c4bafb",
      "c4b65a34138b43a0bf78dee2dba860b7",
      "77ae0d018f604cd09c8f8f1cff1fe88d",
      "6a097de6c92e4dd0976f847dd202a8b7",
      "3d0f77c2d1ee4811916724818a3678f6",
      "999053dd36b340aebf45190993a7f293",
      "8ad0e29bfa714bea87a7294cbf33d699",
      "568efc4925a043b099bcd4d35772493b",
      "ba94bac9d7ee47d4bcb4d5db89f35800",
      "578ab88965344e598ff935a2582ae0a4",
      "183ae9277d804ac895ebaf54306c045a",
      "e39c51ae6cd74beabce81177cad2f3f4",
      "463bdee8409c4a598acc4f6795bec934",
      "91f47bc9233446c2acfd152f10b7e413",
      "5dde1adfec2345b0aea2580e5db16945",
      "469bdd94f5b94273a2b09c0f798fa3d1",
      "fb594fd5b48d4fb6bd2997f9bd59b092",
      "8fb426e5dd8e418ba9791c249de053e2",
      "551e931258d742eb97b632b5f69c5ca4",
      "f9ec6525f3ed420586e676004c25c924",
      "8e751f7e3910415e9de3035ed4c6df1d",
      "49192ff438454a57a653f733834b8736",
      "033c7229395f49ea944fc7411a8ee095",
      "3057a398ea404dd09d02eba16d9cd014",
      "cff51001bde54f01a62f0bacef37850d",
      "e3ad2bfa96eb418c9102b904ca48f948",
      "6ed61fd9ae0646da988b88d36ef12de8",
      "760842784e4347f4bc2a5062a2f8916a",
      "095b83b8e72141a4ba3de2d5bc44b6ce",
      "bc091aacf17a41d5a83afa34072b6c1e",
      "8d76423780234912b745d7eccc03f6ab",
      "521d849f554943678bc62d068f01de7e",
      "ec18a98ac5ee4063864b377d419ab530",
      "36b15963dc9b46e3962dc0bf1247578c",
      "359564a4a8cb499587e36dd185173a64",
      "fda8ee03d8f24122b3979abcbea57aaf",
      "834ab9bad21f4d26adc471126decb425",
      "747f973435b34ce58f5b94f48ac8ea5d",
      "f77afa6b2efa478f833f1f126fef9717",
      "23fdb120821e4568a1fc54fdfab192e6",
      "c5201c7fc58e41339037ecbd909113f1",
      "88f6039054ca4222afdab03599bed53a",
      "d270dea23d9544c2921f7936f078c883",
      "2ec7b48a062443f5a099c353d026bca3",
      "fd308691ea1040e98dcf63e68111edbe",
      "1ad5964e0f7441f19a92d82a855d5a4c",
      "bde6101d9f744e08952d017332b42601",
      "f6dec6ee305147e39c4f1e12b3122622",
      "1c5cd6b375a849c881d62191e96db558",
      "5a135de2152f42f3bf5f93f009754dad",
      "60f60da6cb5a464d8529796e764391f5",
      "9a6f345e4bab41268c89f15b57b5fea2",
      "0ab8bddb2b834ad6b2bad9d75c058b2c",
      "36944b98f5f74869b52a7d918024af85",
      "8316b776477f469387a4c7d83cf95979",
      "3333dd95904c44a3807bf2c4bf5b5975",
      "eed778e5b09f4eb09762517c8d740f48",
      "e46d374598574e37958ac527ba00e147",
      "be5ede1a9cf04fd195d771cb19bb1fc8",
      "7a3b5fbc3cc1430a9f240e9032cf1ed1",
      "8929af1b3819423faaef1f65b8a8a862",
      "89a2dfee97d5467fa5a9727804909ef6",
      "ada3b0cbbce145c6923f94adfdff0b54",
      "a9ea735695ba4d5aac94b2782c7ab835",
      "aa5208583ad74062a04820b9ac9a6cc7",
      "1f45b4d677e04b009be2990f00f6252f",
      "0c17206d98304b2f8c47e99eaef09ff5",
      "083852b29ae945f7880df7a549e436ab",
      "4bef8aa5556644098aa889c1bdff49be",
      "5fc34bca842d4b618c934dadec5a1c95",
      "ae1b7a1e5c804568a90b71ad86fc6ac2",
      "9fc5c457abfd414fb34c8b304ffa6c76",
      "4a6701c790b14cbabbbf4b3198cd3ddf",
      "f4e31f8d2c0e44f9ae239bce947f3625",
      "e02598612c3c4003822c931919eacb49",
      "c01393fec97d4c9583cd12a4303dec6e",
      "aaff471007f34b2eb1a0fcc766306cea",
      "1a20659ff15a4e29987554c1a1f0bbb3",
      "cda32a786cc64070a738b5feebd9f231",
      "d0641d3caaa74fb5bf3ee9c912d469f9",
      "94ae3ba3904046a5b61cc17f836b2cd3",
      "29157a842ea540bda85bea1462ab43f7",
      "2514cb0c85354aedb273a4a135ab2e6b",
      "a33ef7a2e2934efebc18a6755ab15243",
      "b8362359d86341208a0a77a544529436",
      "9c10705e6fe04de8a51d58df93a12e3d",
      "f587e7aa67ff4bb0943e78b850ad5916",
      "817a651cbaf54c76a9ff7b18ae731a64",
      "6c81f084abad48888868693ddfaafd35",
      "491e1d880cc940e2a905264689a53c87",
      "2b06d302583b45bba656798ccc26581d",
      "0ad77efd7d8e449da66dd334228dc6a9",
      "cf93d6ed1d5e4bf6ad1df54ac35a11e2",
      "4bf6c98dee9446b28753e677ed490ab8",
      "ea62244eecea4e71b7de65003ced71ce",
      "037b4b24fe144d19bdac2317c9ccfc2b",
      "3daf0429dea94aea9c47bad3911d578a",
      "a070ae0107a44713823a1297997ee035",
      "b08965c113554eb69cddd8a3b104a698",
      "c188f47c700b451881a0748e0104e630",
      "adae27239d384310b939e933752bb9c4",
      "ec0c0d32427441ba9fd81b207cbb540a",
      "762c638f1e734978a548cb55f3eea179",
      "2095456e33014b45af58f0f7560b9d7d",
      "6149a744861b46a3a68588ef94645263",
      "7545844d4fc14435ab3146156c8306d0",
      "4fe8dbdc1a06459b8d526e911e30c1f6",
      "dc1add84660648e986d70d7bc690c2d0",
      "8698df96f9874cd9a6523857a78fba1d",
      "fe71442d00734fc9a5145859ac91f315",
      "d2ee0be4ce854144a31aaf8ade1c6a90",
      "4e66ce4a3da84c54b0fc5ef836515399",
      "c7d3f84ad9384c8a9377b4a410dcc967",
      "ddec2d906f584f08a21986e6f3ff3e76",
      "9c814a0538f8446abae919ec6298a131",
      "751f42427e614f6b80dd8398d5efd0c9",
      "7b1dd58812464728899f349e6a2331c0",
      "5d3df85e87644cd5a27d16d7d5151a80",
      "4a65b3b113464393ba50209f8d3ead02",
      "25836c17d4574204b50462bd97cd7595",
      "9f34c48466504dc4901563bb3de6834e",
      "e654f1d77e36496796c976e3b92a326a",
      "75a5f557a97b49e3bddabf611e04bcc6",
      "531b1aa2351d49a494a40a7652980560",
      "66b9903595914c3996fd8ba6cae95d5e",
      "65bb9a263fbe40dfa045ccc0e59a7cd1",
      "0c5c21e3d031490ab25e32ca3285bdd9",
      "9a2523618078486686081787dc9ecd0d",
      "be55471b28704e7d8a857545a4f0df61",
      "3de288c9d04b45da8d770bf1feedd185",
      "a5ffb4e11eea48528cff48bb3ca34cae",
      "91ba9366d377405dbe04b108c1cb2909",
      "6eeaf36e51ec459290d8bcfbe14dcd18",
      "4184925648a8409b98deab58fdf5a1ba",
      "2471f5153ab14e09925b69b002636e9c",
      "27dec97d74434991b0a0f2481b0b58ff",
      "c26b2926c34e45958dbe7c3a057e9ce5",
      "db4b48947d824732b889fe910cf2f7b4",
      "755a3759f70f4ec99282d9cd4778744b",
      "0b57ddac92f0413b890a3fe4483c7470",
      "70165444e40945c385c7786f67b3b842",
      "45fd51c1e0454bd2914cbc376d336731",
      "2f3e8331459a46af945b4560dfba7956",
      "46f94ca1c5c74f32b671351e1423a4ae",
      "eae72fd11d8946aaa1f2df27ebac3d86",
      "b93bed5f234e4100acda45055efcbc20",
      "58cabdda12f74a32a29a6ba9626ac44c",
      "e075bd05089c4d4da4a2ff9db3fcf1ca",
      "4711e700bf1548d29268511f7fffb5f6",
      "009ad051a764461cb53ff8baef6cda60",
      "9bc84d2306524133922ca7ef16e14e2f",
      "c4326b183e444f959920acc141b7282e",
      "055bea01113440fe9e5a8f06a1b477ef",
      "bc02fad96dd94ee390ef4473bd830139",
      "a0bd16f16368490cbc960152e4dc7c22",
      "b05d83374bad4d9c81ed0a8334b5d9e3",
      "a66862785a3848048992930d4b38e775",
      "210db80fcc76435d8ffc8bbd67ad89d4",
      "654d7e7444844de08c608f2c52cb1a83",
      "6d880cc03c7849288842a6d1c86ef517",
      "ea96b37d999c4482aa85bc574764c4b1",
      "a3af87e3922d49c0b45b8b8f355b4d72",
      "4d620024656d4a32a61c42eaf0cd1b23",
      "eba2f61e665b4ea89d683ae32dd4cb63",
      "1698d9ef7d1c42e6ae3e41bc049ce913",
      "484375d3938b40c6bec50c94d7119505",
      "45b19b2151a24761bd3adf9a53dd44ca",
      "f28ea90320894acb9ac6a3914514bdaf",
      "858d328783c149b2a097c2766f038701",
      "10f4b6b8b75a4faa8e321eecc4c89827",
      "572760f1b0f74ea1bbfeb315f766ffae",
      "f5c0a5264ed34e58b9bb3d0248064bb4",
      "2f9948a414a946b19c83dc63a8ff4795",
      "b2385a72ac31462fb8414d5760fb5368",
      "74920d4291dd4928800993e3da2b8a87",
      "0fed1499cd2744eba7de6e976e9d6651",
      "d3cfc7b91d344b3e89a41b99a21d4595",
      "68e91625372c4a02b3d7aa03a8cf655b",
      "db47d6d46dfd46cea4dba23782debe64",
      "563b765784224b379df613862fe84b5b",
      "f02a3f1c91d74f0e9dba397c48ec3141",
      "d6b1bcf5c63446a198bfb15d96656d79",
      "0fdf3d18239e414f9bcb30928960f840",
      "f7edee9672f7440689f1b3b5b1d2199f",
      "43e9d7800aca4afa9aa8c3a6cb188196",
      "c752b816335f4648b6fa328e43ec752a",
      "8a1ef00c2526499b9913184a53c1cbed",
      "15bd00d7530f41daa193c2ec9eb20a37",
      "bab7055aa1554de6b10d92fdd3533dd8",
      "f970404ba4c24a25994181a71da93935",
      "13944fd68ec64358bb44aef81c589c81",
      "0cf3135059cd4a4390822610d45bdc52",
      "67541b0bb787401d98152e9b5fde56b8",
      "237194ee19d14626877f2d1fe78e4a98",
      "63ec518b7a2e4d2a90991e947e5cfd32",
      "aaade3b52c0e4ae49ece243efebeedc9",
      "7918cfb703774adc8bd364d51a8565c3",
      "b712f5cde25b4676b7440129b70013e4",
      "a5f9746f1856442296b87a250728510d",
      "1898af1cbf1f4662a5b1db95cdadeece",
      "bf9b472eb4b2442c9374abb6459be551",
      "352cd4a29b6445daaf99402d42711bb8",
      "3035db7269564a57b4cc35c2211160a6",
      "b9042f374f7444bebad3b53308b0cc14",
      "83498839df244ef794d888bdc1969433",
      "0b305510fd4a498889bb707e7607387d",
      "0c63fe132ae747b3b303334307addac1",
      "934a10b056e04fc9b776eca7b3409778",
      "97ec1a43d6264a4983ed45606694296d",
      "8718c485b5aa440b890c14005cf7ec67",
      "bef89cd758a746079dc733ee786ae10c",
      "d7b1bf8baa674d3085b6480939394023",
      "6c6667ddc4454b128c935fbe0c6c173d",
      "612ac66896c0488ab61e351b0190f48e",
      "1153bbdd94e3462ebebcd93ab95b025c",
      "26929c94bbc64a40b2c2aa6c1631b8f9",
      "666724c00a6642e8bc85524922f9559f",
      "e046b06fd22449b193a3206864d03a81",
      "36f523ef04284e908fd1b7bd390a0107",
      "ac9cf7316d234734827f4fe258ebde35",
      "be5d67bad5994bd6b86f00ff7e0a50f9",
      "83c1bdba25414fd188c08438f97db019",
      "2fca7ecc72c84f72b0df788cff71cf87",
      "95c9146bbc26407384aa944abab73f96",
      "47e67b48f9924d3cb560759c164196a9",
      "35b51396073a4c2fa1273bbcf77c7a74",
      "c9aa9b534c9e465d9afe140b707df784",
      "37bb31dd00cc45a4bb4117d61bccbf46",
      "81a83b3f97c34d8fa1059249000a067f",
      "759e39403c1941f4b2e40a4c6ed326bf",
      "c25fc576e44e434eb42de4e282cbf575",
      "392fb4c9298b4dc3a5875ff19ba96581",
      "9db7191480ee4c52a88a42114ac48fe1",
      "961c49836013438db97d6d535cd7608c",
      "377181e99fe94ef2bcc168ff550303e6",
      "e5df2f28f834458aa85cea05d30503ea",
      "a1e5c8cea9824970907f8137750d1307",
      "1d0149373ff54b05b9bbcc723d704a10",
      "f3d3bdf53bf14664bfbd56768481fdbe",
      "d63f472140b84dcba5f0e4eaed713b90",
      "5e6fd7fe5897438ba4bad267a5cda4ec",
      "01aff4cbdb184ecba91dcdee622285de",
      "a12b0fe702324bdea216d45f939abbad",
      "1b94094e952849dea5b295baf81b8a15",
      "50e17e6bc66046a19472dc3efe475693",
      "e2db3f1805b1446aa03d9f72fa070ea5",
      "0fff63bf55434dc1876ba70e450edae9",
      "212bed630fee40cb9af8b7af2dd3b1f3",
      "042c048823cd49aab20766db9d1caa28",
      "8988ecc1f27d45e3aa07da1d3ebd4621",
      "fa85c2aef87247fda4fcc6fef8200ffd",
      "e33d6bf733e8413ba2701e48ef97b2a7",
      "f7471e5c785b41df932f9371075d1c8e",
      "40f9c20714f54471ab15de4d05c3f84f",
      "c53a6c9280304eeea1b1b8664c44882f",
      "56ad6126c216472d98b6f6505e1f96b8",
      "de0ce01ae4da4d72b5db32c469aa9046",
      "da7a674f02bc4aa5a930bd8cb6c5792b",
      "3abba0909f884c7db2c79e0eaa218371",
      "44ca8e7c7fca41f0947ec5f6f74daf21",
      "39d5b9cb1bbd442eacea136f71b01a6b",
      "efc5a50bc3cc4a1fb007eb1a267c3ed6",
      "22a12958ba2c4a2ea06b910369d5d31b",
      "1f58621c78de4595823d0f200c3a8b51",
      "6be0c813fdb34fe9aab2611776200293",
      "5292ece7e4154ee1bd825348d2f3c0c9",
      "5d4e7ebacea342f8903136e792db7499",
      "37d6620758994e22a374ff69226000d3",
      "e5b6b65ad6de44d29f4b5ea921ea5304",
      "8c2c1381bb364e58a736a9d24039364e",
      "950fec99f3f8411b8c218274021a183b",
      "1d0975f2937849e5be582ee04c35edbc",
      "529b95adaf7b4179919b1abc6534cdea",
      "8a4aaf7b84d14b6a8a97363201c4dd79",
      "46c92fa72ac745b6808c7e58438dc4fb",
      "7987385e398041e49f285740b1967eae",
      "66b9304f50b14d329e090ade9e3155c6",
      "152b33aea4494cfba6e394244053bc13",
      "1f134733acaf47bebfef226deaaf61b1",
      "fac5bfcb984d420292a34c48e3122a9a",
      "73758743ec254aa4a0c01fc35f821b6a",
      "dc112dd1191247f2bfef89d5c52e98de",
      "fa5cb1578f1647428e2d6b7df6cb40a5",
      "3bd877bbee324441983090478abac22a",
      "dec1b0fb0213451aa776dca619093ecd",
      "91749fa19b0d42669d1f9b8c375b0921",
      "1f67b67145fb44c2bed1d71ae40134eb",
      "c11cc0b686ea4bc0b91a95296bb6e0cb",
      "3a18092c54e64b6da92b78604249394f",
      "26ceee767a4d4b0db7bfded94341a511",
      "3271501a200844ad9f3fc176821158fa",
      "1a6eec9096b741c5a91fc0bfcda98d23",
      "253dbf884a7c4998af282050e6cec4ac",
      "f279404b7b82476ca8ec437f56eb8834",
      "36c6406155dd4a2f9881df72a096505f",
      "c7a8c8a41a0340cc98e54397092d16b7",
      "4888d95ab3c74cb78c2d05da15f3f1de",
      "87134adf7a21478aae62308ddc35360f",
      "dbe457d3565040a49b91e2c011d00e58",
      "a4a9dc83a178443d8fe7870a9d4b0ad9",
      "86cb46938a6049a98ce2c8f6485bb7d8",
      "c2c5544ab77a4c11a07570e500ad122e",
      "79b75a4ed4164ff7a201a33d6a7ac74a",
      "6ae8af4c92234d898cb3eb0f7ecd2060",
      "f6f83e7eab924ae09164fcc4e1b5f632",
      "e6f847a08720468e80e7cca7b2ededab",
      "0eae10883ee44b24976d9421c6b14dfc",
      "cf9c23ad67fc48c0b6d7f0a520c98970",
      "274af952223b48b287ae7cea7697ada6",
      "2d9ec349d1f8437087a7e2335b3032ae",
      "dbe2b7b0721f4f18be72588eba56786d",
      "546282175e164bf6a3e7b4806cf05be4",
      "60d1ffa01ad542e1ba9e53ce86a9c024",
      "37f1571b37f64cad8c19bbccdf0a4d80",
      "ff8588cdce5e4016b729bd88ca0418ef",
      "0872d8f52fe54837854533306bfff450",
      "3ccd473d09e8461dbb50e28f74c6aa2a",
      "97b257cc7c394e05af67c63a8a552625",
      "095e909d7791485a876d5eac8378d629",
      "5fb11fea620a43c4a1c620f37bf69a95",
      "317d5be81ca2404d802e5f51a1767f54",
      "ecfe75dbfb394d3ea47949499d263198",
      "664fa49f44494401880412e5e900e3f1",
      "31ee4c40b95042babd3e5346c348df8e",
      "15cf046e173c43668761810deda152ea",
      "50f949162a1146238eed1186787878c0",
      "b554b49d71ce4e6fabf57fdaefa2631e",
      "169b29ba062a4ae9ae06feccdae01aec",
      "4e346c144ae14bf49408a653503b23a0",
      "0ae267a935e84af08f1ff48c5636323e",
      "1ad78939fa624c3e9ca636965f7f0a06",
      "2a198074a5f1452794f76f479f7e576b",
      "3456ac37622a4781a9f179dfb6157704",
      "a5ba4ca58c05490880e16c3aca63eec6",
      "6bc89bb932084e26830fc4cb7d666e77",
      "530f6ffbba9e4410829c66279ee4a6f5",
      "da6b52cc90db43e4bcb60f2a501f1a74",
      "c3a94ed25a7c4070b9b684edac4b17c9",
      "91bd2ee7d60e4034a6402d4282afeb68",
      "c710fd38e6604a4aa82dd58c9be0051f",
      "ec5c8585ccbf42da8d722fdc931d54f4",
      "a815381d282a43ad869d51329294bad9",
      "195bf54e004545c891b2313715bb29e5",
      "d50cd9bacd434acb9e75887bb2fe0bcf",
      "f987928e9e6842eda4dc6e0ea54c07e0",
      "d68a25776e314a26bb8670bb8bc824de",
      "829df235bfd345aaa5df10b0079131a8",
      "d95893a8c0834f10b8546cb26bc451b2",
      "e83713ed065a411682af34880dddba49",
      "5a9438a26bdf4065a2c7e5130637a694",
      "01e0256dd3e045f193def04d2e4ed638",
      "0925cc1870344da88dc3f2ef967c87d8",
      "010ccf53e1fe40dd819d4142219edbf1",
      "e5d3aae0c78442878532d6ea2fb8ae79",
      "1fdb2958345c4e058c3852920a57dd31",
      "a96c8a52d4194d21ae0e400ed4823258",
      "7f8c21fae69847088d23650c5c30763e",
      "da9c4581e15d4fee9f24a3fbc7a4d846",
      "afed6be6565d4e10bf4f8306ba6b5351",
      "722bac119d2f46d8a4d168e14205e516",
      "faf355b069dc4647b1ed94d231a14a25",
      "d5d3772a113f4dd1b246f65da6c9bbe7",
      "ad9ba7e3e7ba446f888004ae915e9348",
      "6ea656842ebd43318a46a1d4b1699414",
      "52cb401d11b248b98792bac682a3e6db",
      "8bdc2c69fd584af8822189520270bae0",
      "fb39fb8453294040b4f6c5f4a24ddb9c",
      "e5de0ed85a0942a5bdc18d14687d99c7",
      "5a0de35a5eb840f2b6cf843bff989ea6",
      "3f2a59e643a941eb8f40e04d9a5a5f19",
      "ea3907cf9dfe45988cb33b8d4d798996",
      "45d7117c0c3c4288a3822716ad8fbd58",
      "cdec7b82d54b409e948ed197fa0b52ca",
      "1cc307ad541a4c00bbb2cec326c94250",
      "85b7d291ecf846c4b995b03c436e87b0",
      "6052972707764962ac6dc032d2f48158",
      "1e1ec001eefe4b549f8312a6f90b473d",
      "b924c7b4b176474bab5be1210411a3cd",
      "342f9f6321404ed28e03382ac4c03a28",
      "3da745350e00470c9d383145e39d9e4f",
      "f362cff8e2e64eab8ae93429a4f9ddd6",
      "cd8c1b1b142349dfac4374a09432e150",
      "545d075fa3a6427db29316c7e68777d7",
      "65f8dd46739a418ca1679107c7fda09f",
      "20ce2124a56f4e25bba6fca2e6107f11",
      "ca9c03176cf5497892ab651440594f43",
      "d564a16ae7d14dc1ae9a15f52ffc6f1b",
      "3e49582222f94f7dade0b900245d30e6",
      "e94bc3258ba945c59eef0cd2dc07cc1b",
      "449910c44bbb49c6b7d96993ff99f2cf",
      "3b45fe2cd09c4b93a2b0cbbe90599d4d",
      "58e701e3b0824143a048af0f2e04ba72",
      "437e8c998caf47da8c578ebcbc4f604d",
      "04ef93d28a1a4417a02baa5ebb0e06f9",
      "f848154db6e24040954b8b26ceebbff2",
      "23834ddec9bc4ad7b8d476d6a2542f36",
      "4db548abfff94f6ca271aedb47e143dd",
      "12c27c09e04a42dcb3e0a6c6a4be389b",
      "7fcd4de83c384a8a948f7491549232d6",
      "f61de5047fe34f1f91bee4d632412168",
      "d2f46672487d421d9461727e8240f5ea",
      "9500f1071b824cc6b8b77e6b9507f0a2",
      "4ffa3338dd0249068e60c5b9bd469cfb",
      "03d13eea0ea64c4d8e8f5c95ee2201b9",
      "a64495faec574aa1ace30181be8d6d0e",
      "8f959cb1682647d691e39f38ca3d7e7f",
      "11ec592bee9d403f813acf02cbf7f3d2",
      "48c57b46230049a9a383cef245f9b3a9",
      "8c6a07db1f044eda8a532942df018e3b",
      "f2c6371b641345689e31c961ec7645ad",
      "b087e0bdc15444a687556de1398c5a5a",
      "42842654ca5f44b9b71f441fe124bd11",
      "79c5bde8e3904310a831e8227cb00bf0",
      "321cd031033f4f52b3cb369a3dda58a4",
      "dff0840de9ad4736b4b4ab90fb7b4cb3",
      "406d330235eb432483c22c0c1cf2f772",
      "f9ed5da27af64929ad6f97dded99f824",
      "db261806b1b14070abaaebd8ad940b39",
      "b36be5a18b034dc3a482a4efb1dd19da",
      "4d26845449e246d7a78ea33904cc4bb2",
      "e637413bfdcf48c88663ecdc874d016d",
      "56814421b767468d8506e0554dd62ea5",
      "df119c4abcd64f96bb505d619ee9b724",
      "6ab22439482149dda28df3ca805ba83b",
      "c796c2a8b4c54b20b18180ed1ace3c00",
      "d5420ce4e9be4cabb2fac79a7f2d66f8",
      "e6966196dddc4788bbaa0a3fc3126351",
      "a4028216a2c44072827024e9b3077f49",
      "28eb01cca1f94df480f5d04d12705170",
      "d3d3645079ab46aaa75b4f20e419a83e",
      "55814480f46b4ccabe5b3717a40b5b12",
      "fcce1027dd9e4de8a3debb17ef5a21d0",
      "f41c42aaa0b241bab85cbc633c2d283c",
      "89452ef49a5d4cb8af280765161d2521",
      "cf5216a83f05487abcc8c35e22149e2a",
      "c0a83a6b7e1041358dc75607e4f98687",
      "b6b66baed8f246159c3447200fd42c34",
      "17d0cf22eb4d43ba856c1aeb8beadc4a",
      "bfe6102d3e6d4ef3b5e94b0fbc260386",
      "09b149add6d64ce6aa04f6e790d7ea20",
      "0e3a4461e37f49c4bea64e3d154f4e76",
      "325bfdaed11245cbb7f6139b34fdc1a8",
      "dd6fbd7723e649c58334937958f06643",
      "7d08febd17174c958fb917dbdf7f1b84",
      "61ee56c58950428d97a9fe352c05ea99",
      "428983e09fa84d769f0d115e47cb9046",
      "0fa62e39bc904766b47348996f69a368",
      "c4f12aec48204b2f9a13d5ca27da36f0",
      "5efed25dca594b37a44e9010e6b98b02",
      "f8c45ad9087f40d5a340f0ddd181e131",
      "0e66d18a049a4b28996a8f925e28dbd4"
     ]
    },
    "id": "YnexZWtnpXxX",
    "outputId": "dfb146f1-dd59-48f0-d097-74d0b92aa220"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b5e10f2c004a70b76c9f7df6da52c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c927e07bbdb349c9b857a0aed3c4bafb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/3.90M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39c51ae6cd74beabce81177cad2f3f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/259k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033c7229395f49ea944fc7411a8ee095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b15963dc9b46e3962dc0bf1247578c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd308691ea1040e98dcf63e68111edbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3333dd95904c44a3807bf2c4bf5b5975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c17206d98304b2f8c47e99eaef09ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a20659ff15a4e29987554c1a1f0bbb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c81f084abad48888868693ddfaafd35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c188f47c700b451881a0748e0104e630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ee0be4ce854144a31aaf8ade1c6a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e654f1d77e36496796c976e3b92a326a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eeaf36e51ec459290d8bcfbe14dcd18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f94ca1c5c74f32b671351e1423a4ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0bd16f16368490cbc960152e4dc7c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "484375d3938b40c6bec50c94d7119505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/874M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3cfc7b91d344b3e89a41b99a21d4595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/874M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='2625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/2625 28:20, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.953408</td>\n",
       "      <td>0.504823</td>\n",
       "      <td>0.307007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.917073</td>\n",
       "      <td>0.524116</td>\n",
       "      <td>0.319185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.104500</td>\n",
       "      <td>1.845688</td>\n",
       "      <td>0.553055</td>\n",
       "      <td>0.407674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.104500</td>\n",
       "      <td>1.805225</td>\n",
       "      <td>0.585209</td>\n",
       "      <td>0.498823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.104500</td>\n",
       "      <td>1.743581</td>\n",
       "      <td>0.594855</td>\n",
       "      <td>0.552780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.757900</td>\n",
       "      <td>1.744460</td>\n",
       "      <td>0.607717</td>\n",
       "      <td>0.530046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.757900</td>\n",
       "      <td>1.823366</td>\n",
       "      <td>0.620579</td>\n",
       "      <td>0.556683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.757900</td>\n",
       "      <td>1.823734</td>\n",
       "      <td>0.633441</td>\n",
       "      <td>0.592736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.468500</td>\n",
       "      <td>1.929965</td>\n",
       "      <td>0.649518</td>\n",
       "      <td>0.605816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.468500</td>\n",
       "      <td>2.014050</td>\n",
       "      <td>0.636656</td>\n",
       "      <td>0.591505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.468500</td>\n",
       "      <td>2.022216</td>\n",
       "      <td>0.655949</td>\n",
       "      <td>0.608672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>2.096241</td>\n",
       "      <td>0.659164</td>\n",
       "      <td>0.609915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>2.139224</td>\n",
       "      <td>0.646302</td>\n",
       "      <td>0.601867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>2.148813</td>\n",
       "      <td>0.639871</td>\n",
       "      <td>0.597039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.096300</td>\n",
       "      <td>2.148410</td>\n",
       "      <td>0.646302</td>\n",
       "      <td>0.601768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42\n",
      "Macro-F1: 0.5923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15bd00d7530f41daa193c2ec9eb20a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f9746f1856442296b87a250728510d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8718c485b5aa440b890c14005cf7ec67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be5d67bad5994bd6b86f00ff7e0a50f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "392fb4c9298b4dc3a5875ff19ba96581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a12b0fe702324bdea216d45f939abbad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='2625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/2625 28:43, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.038611</td>\n",
       "      <td>0.536977</td>\n",
       "      <td>0.296380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.826807</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>0.410045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.091800</td>\n",
       "      <td>1.761662</td>\n",
       "      <td>0.556270</td>\n",
       "      <td>0.484771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.091800</td>\n",
       "      <td>1.682120</td>\n",
       "      <td>0.598071</td>\n",
       "      <td>0.559995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.091800</td>\n",
       "      <td>1.658721</td>\n",
       "      <td>0.591640</td>\n",
       "      <td>0.542271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.725000</td>\n",
       "      <td>1.801554</td>\n",
       "      <td>0.627010</td>\n",
       "      <td>0.523973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.725000</td>\n",
       "      <td>1.790358</td>\n",
       "      <td>0.636656</td>\n",
       "      <td>0.586092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.725000</td>\n",
       "      <td>1.838294</td>\n",
       "      <td>0.652733</td>\n",
       "      <td>0.609664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.486400</td>\n",
       "      <td>1.874767</td>\n",
       "      <td>0.627010</td>\n",
       "      <td>0.578392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.486400</td>\n",
       "      <td>1.963675</td>\n",
       "      <td>0.627010</td>\n",
       "      <td>0.588748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.486400</td>\n",
       "      <td>1.996244</td>\n",
       "      <td>0.646302</td>\n",
       "      <td>0.613309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.254400</td>\n",
       "      <td>2.046728</td>\n",
       "      <td>0.623794</td>\n",
       "      <td>0.594402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.254400</td>\n",
       "      <td>2.075510</td>\n",
       "      <td>0.639871</td>\n",
       "      <td>0.604337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.254400</td>\n",
       "      <td>2.077687</td>\n",
       "      <td>0.627010</td>\n",
       "      <td>0.597210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.131500</td>\n",
       "      <td>2.080146</td>\n",
       "      <td>0.627010</td>\n",
       "      <td>0.595094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 77\n",
      "Macro-F1: 0.6048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f9c20714f54471ab15de4d05c3f84f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be0c813fdb34fe9aab2611776200293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7987385e398041e49f285740b1967eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f67b67145fb44c2bed1d71ae40134eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87134adf7a21478aae62308ddc35360f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274af952223b48b287ae7cea7697ada6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1925' max='2625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1925/2625 20:55 < 07:36, 1.53 it/s, Epoch 11/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.087714</td>\n",
       "      <td>0.520900</td>\n",
       "      <td>0.321219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.849429</td>\n",
       "      <td>0.540193</td>\n",
       "      <td>0.373464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.117600</td>\n",
       "      <td>1.754927</td>\n",
       "      <td>0.607717</td>\n",
       "      <td>0.474402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.117600</td>\n",
       "      <td>1.716058</td>\n",
       "      <td>0.627010</td>\n",
       "      <td>0.529958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.117600</td>\n",
       "      <td>1.724386</td>\n",
       "      <td>0.569132</td>\n",
       "      <td>0.529739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.713800</td>\n",
       "      <td>1.781807</td>\n",
       "      <td>0.614148</td>\n",
       "      <td>0.582737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.713800</td>\n",
       "      <td>1.810127</td>\n",
       "      <td>0.643087</td>\n",
       "      <td>0.610554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.713800</td>\n",
       "      <td>1.904816</td>\n",
       "      <td>0.627010</td>\n",
       "      <td>0.596503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.366200</td>\n",
       "      <td>2.017482</td>\n",
       "      <td>0.633441</td>\n",
       "      <td>0.597058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.366200</td>\n",
       "      <td>2.149503</td>\n",
       "      <td>0.636656</td>\n",
       "      <td>0.606285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.366200</td>\n",
       "      <td>2.191775</td>\n",
       "      <td>0.643087</td>\n",
       "      <td>0.607879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 123\n",
      "Macro-F1: 0.5609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb11fea620a43c4a1c620f37bf69a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad78939fa624c3e9ca636965f7f0a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a815381d282a43ad869d51329294bad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010ccf53e1fe40dd819d4142219edbf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea656842ebd43318a46a1d4b1699414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b7d291ecf846c4b995b03c436e87b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2450' max='2625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2450/2625 26:42 < 01:54, 1.53 it/s, Epoch 14/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.938904</td>\n",
       "      <td>0.569132</td>\n",
       "      <td>0.315321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.851040</td>\n",
       "      <td>0.578778</td>\n",
       "      <td>0.367403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.080900</td>\n",
       "      <td>1.761132</td>\n",
       "      <td>0.601286</td>\n",
       "      <td>0.544479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.080900</td>\n",
       "      <td>1.710198</td>\n",
       "      <td>0.588424</td>\n",
       "      <td>0.547289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.080900</td>\n",
       "      <td>1.671988</td>\n",
       "      <td>0.655949</td>\n",
       "      <td>0.598133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.684600</td>\n",
       "      <td>1.731866</td>\n",
       "      <td>0.643087</td>\n",
       "      <td>0.604486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.684600</td>\n",
       "      <td>1.805898</td>\n",
       "      <td>0.649518</td>\n",
       "      <td>0.629433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.684600</td>\n",
       "      <td>1.841045</td>\n",
       "      <td>0.659164</td>\n",
       "      <td>0.620258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.337100</td>\n",
       "      <td>1.927407</td>\n",
       "      <td>0.652733</td>\n",
       "      <td>0.626951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.337100</td>\n",
       "      <td>1.960917</td>\n",
       "      <td>0.646302</td>\n",
       "      <td>0.632920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.337100</td>\n",
       "      <td>2.021176</td>\n",
       "      <td>0.636656</td>\n",
       "      <td>0.619571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.098700</td>\n",
       "      <td>2.060132</td>\n",
       "      <td>0.649518</td>\n",
       "      <td>0.620957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.098700</td>\n",
       "      <td>2.076230</td>\n",
       "      <td>0.643087</td>\n",
       "      <td>0.614179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.098700</td>\n",
       "      <td>2.071453</td>\n",
       "      <td>0.655949</td>\n",
       "      <td>0.624990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 777\n",
      "Macro-F1: 0.6163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9c03176cf5497892ab651440594f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db548abfff94f6ca271aedb47e143dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c57b46230049a9a383cef245f9b3a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36be5a18b034dc3a482a4efb1dd19da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d3645079ab46aaa75b4f20e419a83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3a4461e37f49c4bea64e3d154f4e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2450' max='2625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2450/2625 27:01 < 01:55, 1.51 it/s, Epoch 14/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.100094</td>\n",
       "      <td>0.456592</td>\n",
       "      <td>0.208724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.841265</td>\n",
       "      <td>0.556270</td>\n",
       "      <td>0.400245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.118700</td>\n",
       "      <td>1.746225</td>\n",
       "      <td>0.591640</td>\n",
       "      <td>0.503877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.118700</td>\n",
       "      <td>1.769097</td>\n",
       "      <td>0.572347</td>\n",
       "      <td>0.485116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.118700</td>\n",
       "      <td>1.781934</td>\n",
       "      <td>0.633441</td>\n",
       "      <td>0.549779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.720100</td>\n",
       "      <td>1.777849</td>\n",
       "      <td>0.646302</td>\n",
       "      <td>0.592669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.720100</td>\n",
       "      <td>1.829087</td>\n",
       "      <td>0.639871</td>\n",
       "      <td>0.604303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.720100</td>\n",
       "      <td>1.905924</td>\n",
       "      <td>0.652733</td>\n",
       "      <td>0.594944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.451300</td>\n",
       "      <td>1.996973</td>\n",
       "      <td>0.623794</td>\n",
       "      <td>0.583687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.451300</td>\n",
       "      <td>2.066633</td>\n",
       "      <td>0.646302</td>\n",
       "      <td>0.613855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.451300</td>\n",
       "      <td>2.171334</td>\n",
       "      <td>0.617363</td>\n",
       "      <td>0.588830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.182600</td>\n",
       "      <td>2.204387</td>\n",
       "      <td>0.620579</td>\n",
       "      <td>0.581825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.182600</td>\n",
       "      <td>2.252600</td>\n",
       "      <td>0.623794</td>\n",
       "      <td>0.601639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.182600</td>\n",
       "      <td>2.266109</td>\n",
       "      <td>0.617363</td>\n",
       "      <td>0.579706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 2024\n",
      "Macro-F1: 0.5265\n",
      "Performance summary:\n",
      "Mean macro-F1: 0.5802\n",
      "Std: 0.0326\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets scikit-learn accelerate torch pandas\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    "    set_seed,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "SEEDS = [42, 77, 123, 777, 2024]\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    set_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "\n",
    "MODEL_NAME = \"microsoft/deberta-v3-large\"\n",
    "OUTPUT_DIR = \"./deberta_task2_results\"\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 4\n",
    "GRAD_ACCUMULATION = 4\n",
    "LR = 8e-6\n",
    "EPOCHS = 15\n",
    "\n",
    "dataset = load_dataset(\"ailsntua/QEvasion\")\n",
    "\n",
    "\n",
    "def preprocess(example):\n",
    "    clarity = example.get(\"clarity_label\", \"Unknown\")\n",
    "    if clarity is None:\n",
    "        clarity = \"Unknown\"\n",
    "    text = f\"Context: {clarity} | Question: {example['question']} Answer: {example['interview_answer']}\"\n",
    "    return {\"text\": text, \"evasion_label\": example[\"evasion_label\"]}\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": (preds == labels).mean(),\n",
    "        \"macro_f1\": f1_score(labels, preds, average=\"macro\"),\n",
    "    }\n",
    "\n",
    "\n",
    "def run_single_seed(seed: int):\n",
    "    set_all_seeds(seed)\n",
    "\n",
    "    # preprocess data\n",
    "    full_data = dataset[\"train\"].map(preprocess)\n",
    "    full_data = full_data.class_encode_column(\"evasion_label\")\n",
    "\n",
    "    # train / dev / test held-out split\n",
    "    split1 = full_data.train_test_split(\n",
    "        test_size=0.1,\n",
    "        seed=seed,\n",
    "        stratify_by_column=\"evasion_label\",\n",
    "    )\n",
    "    train_dev_ds = split1[\"train\"]\n",
    "    held_out_test_ds = split1[\"test\"]\n",
    "\n",
    "    split2 = train_dev_ds.train_test_split(\n",
    "        test_size=0.1,\n",
    "        seed=seed,\n",
    "        stratify_by_column=\"evasion_label\",\n",
    "    )\n",
    "    train_ds = split2[\"train\"]\n",
    "    eval_ds = split2[\"test\"]\n",
    "\n",
    "    labels = train_ds.features[\"evasion_label\"].names\n",
    "    label2id = {name: i for i, name in enumerate(labels)}\n",
    "    id2label = {i: name for name, i in label2id.items()}\n",
    "\n",
    "    # tokenization\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    def tokenize_fn(batch):\n",
    "        return tokenizer(\n",
    "            batch[\"text\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=MAX_LEN,\n",
    "        )\n",
    "\n",
    "    train_ds_tok = train_ds.map(tokenize_fn, batched=True)\n",
    "    eval_ds_tok = eval_ds.map(tokenize_fn, batched=True)\n",
    "    held_out_test_tok = held_out_test_ds.map(tokenize_fn, batched=True)\n",
    "\n",
    "    train_ds_tok = train_ds_tok.map(lambda x: {\"labels\": x[\"evasion_label\"]})\n",
    "    eval_ds_tok = eval_ds_tok.map(lambda x: {\"labels\": x[\"evasion_label\"]})\n",
    "    held_out_test_tok = held_out_test_tok.map(lambda x: {\"labels\": x[\"evasion_label\"]})\n",
    "\n",
    "    # class weights\n",
    "    y_train = train_ds_tok[\"evasion_label\"]\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight=\"balanced\",\n",
    "        classes=np.unique(y_train),\n",
    "        y=y_train,\n",
    "    )\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "    # model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=len(labels),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "\n",
    "    # trainer subclass that closes over class_weights_tensor\n",
    "    class WeightedTrainer(Trainer):\n",
    "       def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "            labels = inputs.get(\"labels\")\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.get(\"logits\")\n",
    "            loss_fct = nn.CrossEntropyLoss(\n",
    "                weight=class_weights_tensor,\n",
    "                label_smoothing=0.1,\n",
    "            )\n",
    "            loss = loss_fct(\n",
    "                logits.view(-1, model.config.num_labels),\n",
    "                labels.view(-1),\n",
    "            )\n",
    "            return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"{OUTPUT_DIR}_seed{seed}\",\n",
    "        learning_rate=LR,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE * 2,\n",
    "        gradient_accumulation_steps=GRAD_ACCUMULATION,\n",
    "        num_train_epochs=EPOCHS,\n",
    "        weight_decay=0.05,\n",
    "        warmup_ratio=0.1,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"no\",\n",
    "        load_best_model_at_end=False,\n",
    "        metric_for_best_model=\"macro_f1\",\n",
    "        greater_is_better=True,\n",
    "        fp16=True,\n",
    "        report_to=\"none\",\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "    trainer = WeightedTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds_tok,\n",
    "        eval_dataset=eval_ds_tok,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=4)],\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    test_results = trainer.evaluate(held_out_test_tok)\n",
    "    macro_f1 = test_results[\"eval_macro_f1\"]\n",
    "    print(\"Seed:\", seed)\n",
    "    print(\"Macro-F1:\", round(macro_f1, 4))\n",
    "\n",
    "    return macro_f1\n",
    "\n",
    "\n",
    "# run over all seeds and summarize\n",
    "all_results = []\n",
    "for s in SEEDS:\n",
    "    score = run_single_seed(s)\n",
    "    all_results.append((s, score))\n",
    "\n",
    "scores = []\n",
    "for (_, result) in all_results:\n",
    "    scores.append(result)\n",
    "\n",
    "mean_f1 = np.mean(scores)\n",
    "std_f1 = np.std(scores)\n",
    "\n",
    "print(\"Performance summary:\")\n",
    "print(\"Mean macro-F1:\", round(mean_f1, 4))\n",
    "print(\"Std:\", round(std_f1, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEoLhrHms9p_"
   },
   "source": [
    "Taking a deeper look into seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 873,
     "referenced_widgets": [
      "c100be7c80ca4c409185f24fb9699da2",
      "d16f3b1516794d95b8ad05998cd932d2",
      "e8accbaabae6410c9080b9e42813c83d",
      "87903f4351e74703be418da7d514e9eb",
      "4216db3ad79e46feb944533159fcb3f0",
      "58aaa3c91b9b4a8893a8c6ee99cd65f9",
      "f7edd34e23e64eb79750c8b6969a72d4",
      "9d28b88665104d4f9f3fdad7dbcf0835",
      "30f17f43726d4802947a275526e5c502",
      "e38cb7acbc624223a81ad7faaffab1c8",
      "696e217a1b874fc291cc24f239e56989",
      "f5492ceeb90440018b20a4f5b09ea5b0",
      "c66aa89becff476c9fe5c60ce044bd90",
      "03d61cf5fccc45b2a83da9c1e58461cb",
      "3d1eefda168a4b62bc16a3ac1ba74a81",
      "8aed6de8ab7f429d82cf265495cb153e",
      "8079987071f74338a392db1b27d2bfff",
      "5fcd6a9fdf4f46e491a1b7c5afbc2ab6",
      "e3b5913b596e4513bc425e670f11b4d3",
      "e2461e2b0a6242afbc35e456548265bd",
      "487b913795a0413d90c5b3b50687e3aa",
      "8aac221d62fc4b04b3bd5e9055a08614",
      "256960853458478584d71c9f81a6f375",
      "cae93fc3e2e642e89b86d1f9fe1430d8",
      "c25caf2044a74e34aa90ec7b910612e9",
      "4841f3040164447ab35b63b54a8aadd2",
      "62749cbbd1e74f50abf87706734129b7",
      "5140a2222c2742979d27ddc54a34fb86",
      "745a858ccd7c4fe9a96914799af75707",
      "9b5b8180d70c4640a61dc81f789eda0a",
      "19af37f0541a46b39d9d2e21d1c38c6f",
      "98da1b98d1e04de28fec373cb25b288c",
      "6101ef8cc38d43f486ebef7ed6a9bc0e",
      "dee579db89594797882077918fe2dddb",
      "1f7d6933e2174be0b1b16e2e9f496b28",
      "69143e3228f544a6ad88cb0bb58f2ccb",
      "ec9cf2299d1241d497e190ab0f0cb6bd",
      "682e5cf314d44aa894c86130ae02d27d",
      "e21d6c30f2e24cee97930c9ae558cc70",
      "e75114d2452f458eac67f8ea115c3d0e",
      "7987cf23658548e3bcbd3a76817290cb",
      "6fd524fa7a96454a90af47ee247b073a",
      "8becca173d194297ba7e55b6e4ebf4b4",
      "c45556cbc7b044a2ac8c5c52854741cc",
      "5807e47a61cd48b6b8c0aad8eae5651a",
      "c58e1e8b69fa4221b9d0e9805476bfd5",
      "7c579dae755b49b9bb467d8d380c6d2d",
      "8ba0e8e93abe430c95014e2e609ba672",
      "5f402190252e4e28aa8e5c345952a972",
      "b94b93dccd174abe8459a823d5748039",
      "d87a700dbdff4dad99efdb4703839b34",
      "2b86aa8e1d0d4abb954c5a45c8f81500",
      "bc1a4db5e6764307a18d34e16ca6e828",
      "05b1752103104f6286f35828e5a356c0",
      "22f505370ab347b6b9b7d41a21727bd5",
      "ec8bab8594ef410bafd0ab9c64e348e1",
      "c407d18b68a648e0a914a00edd7dc4d7",
      "fb47105797fe49f8b51f77f60c922404",
      "8f14d6999f564976890866530b85422c",
      "3399ea4a117e41cca6f560c626ec781d",
      "1229c2c402584217a7409f4c82b4b4d7",
      "1c69cca9c74943498c97c65b9c9487c9",
      "cbcd7504ca0546aaae330f7ac84ff4d3",
      "f4d12757610f4da4b2491c8ddffe154d",
      "8996cf0a010f4dc7a659f0ffd01a696d",
      "e5c59b8e091848159a749a091f7d1cdc",
      "e19b2367a99f45268805e4abb802b2cb",
      "b4a2249c66a74d729291a16a6da436fe",
      "d03be0b56b124c2ea356cd857f758b62",
      "62a52c3c74d6427f871db182d238ceeb",
      "724e32cd460145e39b294b1fe14a75a3",
      "8eb020bc7e134deba15b306a142c3941",
      "b24bdff924d94282b790a4c0c029c6d6",
      "96d9207397b54e8e9a97453c7f9c09d6",
      "3699aa5c3e0f4d77bc2a35b2f9cab11e",
      "b45184fe333f4fa2b56465eb70b20cfa",
      "e35e0d52fe8b4995906f464b5ab9b2e2",
      "7d2aa48d39e440c3a6121c82054b820c",
      "46b86f7d267d4c72ac0d0bd006bc5889",
      "347389546bf445c3b1a547ca55e600ac",
      "0793974604e647cbae6d397a8045e6cc",
      "d896c8cd93cf4155b7b1b25b520b0ba1",
      "8d67d380408744be85fd859eb11ac0ac",
      "ff7cad01ad074164920ca0af58973d9e",
      "dc2c2a7f01c14a478d9f0ee69926b7a1",
      "22cbd21a32034b60b8f3bcc2b5f15095",
      "34351b616b724d4aa50a707a59d2dc55",
      "278da874bc634578bc9ab4aab8be4667",
      "844ca2bd898a445a8028b828f279e176",
      "7358cb1b4ed4408d9b4f291cea0590fd",
      "bc9d456f0f0242fd80c8db2e0f6d924e",
      "dd9444b198fe4fb19604cd0c0ac3d53d",
      "a2f4c5517d254808a878f536eb40d4f6",
      "5e131474e93042c481006c95158e58fe",
      "7bdf536464a34bd1b794b881d1e358f5",
      "1e9bb17b838944d1afa2605342a2a624",
      "d79969480ada4954a2ab124a42abd900",
      "e6dd24bd208d4678bbb69dd03aceeff8",
      "1847e7bef62649ee8917e32e789267f3"
     ]
    },
    "id": "vWu6zdv_810J",
    "outputId": "3acdb105-c55e-426c-8dfe-e98ede53e828"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c100be7c80ca4c409185f24fb9699da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5492ceeb90440018b20a4f5b09ea5b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256960853458478584d71c9f81a6f375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee579db89594797882077918fe2dddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5807e47a61cd48b6b8c0aad8eae5651a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8bab8594ef410bafd0ab9c64e348e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19b2367a99f45268805e4abb802b2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d2aa48d39e440c3a6121c82054b820c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844ca2bd898a445a8028b828f279e176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1925' max='2625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1925/2625 21:00 < 07:38, 1.53 it/s, Epoch 11/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.950711</td>\n",
       "      <td>0.514469</td>\n",
       "      <td>0.338236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.898111</td>\n",
       "      <td>0.565916</td>\n",
       "      <td>0.338165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.104500</td>\n",
       "      <td>1.845922</td>\n",
       "      <td>0.553055</td>\n",
       "      <td>0.415265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.104500</td>\n",
       "      <td>1.735260</td>\n",
       "      <td>0.601286</td>\n",
       "      <td>0.526697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.104500</td>\n",
       "      <td>1.760721</td>\n",
       "      <td>0.588424</td>\n",
       "      <td>0.525385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.730900</td>\n",
       "      <td>1.797224</td>\n",
       "      <td>0.623794</td>\n",
       "      <td>0.572865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.730900</td>\n",
       "      <td>1.883703</td>\n",
       "      <td>0.649518</td>\n",
       "      <td>0.598144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.730900</td>\n",
       "      <td>1.907409</td>\n",
       "      <td>0.636656</td>\n",
       "      <td>0.582219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.407600</td>\n",
       "      <td>2.061466</td>\n",
       "      <td>0.607717</td>\n",
       "      <td>0.560595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.407600</td>\n",
       "      <td>2.099586</td>\n",
       "      <td>0.630225</td>\n",
       "      <td>0.577821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.407600</td>\n",
       "      <td>2.145255</td>\n",
       "      <td>0.633441</td>\n",
       "      <td>0.586445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final macro-F1: 0.5723\n",
      "Final accuracy: 0.6203\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    "    set_seed,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from google.colab import files\n",
    "\n",
    "\n",
    "# seeding\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "# cuDNN determinism for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# configuration\n",
    "MODEL_NAME = \"microsoft/deberta-v3-large\"\n",
    "OUTPUT_DIR = \"./deberta_task2\"\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 4\n",
    "GRAD_ACCUMULATION = 4\n",
    "LR = 8e-6\n",
    "EPOCHS = 15\n",
    "\n",
    "\n",
    "# data\n",
    "dataset = load_dataset(\"ailsntua/QEvasion\")\n",
    "\n",
    "def preprocess(example):\n",
    "    clarity = example.get(\"clarity_label\", \"Unknown\")\n",
    "    if clarity is None:\n",
    "        clarity = \"Unknown\"\n",
    "    text = f\"Context: {clarity} | Question: {example['question']} Answer: {example['interview_answer']}\"\n",
    "    return {\"text\": text, \"evasion_label\": example[\"evasion_label\"]}\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": (preds == labels).mean(),\n",
    "        \"macro_f1\": f1_score(labels, preds, average=\"macro\"),\n",
    "    }\n",
    "\n",
    "full_data = dataset[\"train\"].map(preprocess)\n",
    "if \"test\" in dataset:\n",
    "    comp_test_ds = dataset[\"test\"].map(preprocess)\n",
    "\n",
    "full_data = full_data.class_encode_column(\"evasion_label\")\n",
    "\n",
    "# train / dev / held-out split\n",
    "split1 = full_data.train_test_split(\n",
    "    test_size=0.1,\n",
    "    seed=SEED,\n",
    "    stratify_by_column=\"evasion_label\",\n",
    ")\n",
    "train_dev_ds = split1[\"train\"]\n",
    "held_out_test_ds = split1[\"test\"]\n",
    "\n",
    "split2 = train_dev_ds.train_test_split(\n",
    "    test_size=0.1,\n",
    "    seed=SEED,\n",
    "    stratify_by_column=\"evasion_label\",\n",
    ")\n",
    "train_ds = split2[\"train\"]\n",
    "eval_ds = split2[\"test\"]\n",
    "\n",
    "labels = train_ds.features[\"evasion_label\"].names\n",
    "label2id = {name: i for i, name in enumerate(labels)}\n",
    "id2label = {i: name for name, i in label2id.items()}\n",
    "\n",
    "\n",
    "# tokenization\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "    )\n",
    "\n",
    "train_ds = train_ds.map(tokenize_fn, batched=True)\n",
    "eval_ds = eval_ds.map(tokenize_fn, batched=True)\n",
    "held_out_test_ds = held_out_test_ds.map(tokenize_fn, batched=True)\n",
    "\n",
    "train_ds = train_ds.map(lambda x: {\"labels\": x[\"evasion_label\"]})\n",
    "eval_ds = eval_ds.map(lambda x: {\"labels\": x[\"evasion_label\"]})\n",
    "held_out_test_ds = held_out_test_ds.map(lambda x: {\"labels\": x[\"evasion_label\"]})\n",
    "\n",
    "\n",
    "# class weights\n",
    "y_train = train_ds[\"evasion_label\"]\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train,\n",
    ")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "# trainer\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss_fct = nn.CrossEntropyLoss(\n",
    "            weight=class_weights_tensor,\n",
    "            label_smoothing=0.1,\n",
    "        )\n",
    "        loss = loss_fct(\n",
    "            logits.view(-1, model.config.num_labels),\n",
    "            labels.view(-1),\n",
    "        )\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    learning_rate=LR,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE * 2,\n",
    "    gradient_accumulation_steps=GRAD_ACCUMULATION,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    weight_decay=0.05,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    load_best_model_at_end=False,\n",
    "    metric_for_best_model=\"macro_f1\",\n",
    "    greater_is_better=True,\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=4)],\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "# evaluation\n",
    "test_results = trainer.evaluate(held_out_test_ds)\n",
    "print(\"Final macro-F1:\", round(test_results[\"eval_macro_f1\"], 4))\n",
    "print(\"Final accuracy:\", round(test_results[\"eval_accuracy\"], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 775,
     "referenced_widgets": [
      "a087f881a842481ba6cf6432a1c497f6",
      "41dfc0748c224751824d64799c3e0b0d",
      "ddbee409949a4ea8b669cff6d8576f6f",
      "2960d42a770d4d3eadfa52b67cedb23b",
      "6eb72ce9bdfb482fb0c4e952a13c74e6",
      "148102c25ff044ff80314daea311630d",
      "b59a4293bb0a4bf2aee4d5257c443ddd",
      "0871fc9ddeb7499db1f7f73eaec8a1a4",
      "94b591b26dae4d3691c0e62286b1e10e",
      "3a9a8a9e95ca47c2b37cdc66da619003",
      "4b92df432e514844a76e4b837cd9b304",
      "afa4b7024bd6498b88c8a9fe48ce6056",
      "72f4a37d4c694298b2a91499476ebe02",
      "c8c00d182cb5463aa343c14393c56e3c",
      "3fcfcb995183483cb950245a9eed425e",
      "317fce5a87484b07ac1c094fbc6596d2",
      "9774dde809b94bb083bc01786f8a6e1d",
      "4f5ef9d510064a17b8db72db0f8672c2",
      "65c450508520463bbfbe29a57b0e6d7d",
      "340e94d62374461db10604168363a283",
      "c2110c4911c94efdb6b39e6c2ead7ae0",
      "751e1af9885543209d2c92da6a92bb08"
     ]
    },
    "id": "gdROYdr582Sq",
    "outputId": "66521609-b1c7-4ecc-a932-a30917515366"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a087f881a842481ba6cf6432a1c497f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa4b7024bd6498b88c8a9fe48ce6056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='2625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/2625 28:59, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.950003</td>\n",
       "      <td>0.524116</td>\n",
       "      <td>0.341180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.937106</td>\n",
       "      <td>0.549839</td>\n",
       "      <td>0.273221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.105400</td>\n",
       "      <td>1.860395</td>\n",
       "      <td>0.562701</td>\n",
       "      <td>0.429975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.105400</td>\n",
       "      <td>1.805746</td>\n",
       "      <td>0.556270</td>\n",
       "      <td>0.467838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.105400</td>\n",
       "      <td>1.718144</td>\n",
       "      <td>0.585209</td>\n",
       "      <td>0.519791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.743600</td>\n",
       "      <td>1.783485</td>\n",
       "      <td>0.636656</td>\n",
       "      <td>0.564101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.743600</td>\n",
       "      <td>1.878573</td>\n",
       "      <td>0.614148</td>\n",
       "      <td>0.557299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.743600</td>\n",
       "      <td>1.940078</td>\n",
       "      <td>0.620579</td>\n",
       "      <td>0.570426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.436100</td>\n",
       "      <td>2.061039</td>\n",
       "      <td>0.620579</td>\n",
       "      <td>0.563424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.436100</td>\n",
       "      <td>2.086612</td>\n",
       "      <td>0.620579</td>\n",
       "      <td>0.568620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.436100</td>\n",
       "      <td>2.118716</td>\n",
       "      <td>0.623794</td>\n",
       "      <td>0.582515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.190600</td>\n",
       "      <td>2.216756</td>\n",
       "      <td>0.620579</td>\n",
       "      <td>0.576814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.190600</td>\n",
       "      <td>2.247791</td>\n",
       "      <td>0.617363</td>\n",
       "      <td>0.574162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.190600</td>\n",
       "      <td>2.269636</td>\n",
       "      <td>0.617363</td>\n",
       "      <td>0.574817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.088900</td>\n",
       "      <td>2.270320</td>\n",
       "      <td>0.623794</td>\n",
       "      <td>0.579427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final macro-F1: 0.5728\n",
      "Final accuracy: 0.6174\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    "    set_seed,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from google.colab import files\n",
    "\n",
    "\n",
    "# seeding\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "# cuDNN determinism for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# configuration\n",
    "MODEL_NAME = \"microsoft/deberta-v3-large\"\n",
    "OUTPUT_DIR = \"./deberta_task2\"\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 4\n",
    "GRAD_ACCUMULATION = 4\n",
    "LR = 8e-6\n",
    "EPOCHS = 15\n",
    "\n",
    "\n",
    "# data\n",
    "dataset = load_dataset(\"ailsntua/QEvasion\")\n",
    "\n",
    "def preprocess(example):\n",
    "    clarity = example.get(\"clarity_label\", \"Unknown\")\n",
    "    if clarity is None:\n",
    "        clarity = \"Unknown\"\n",
    "    text = f\"Context: {clarity} | Question: {example['question']} Answer: {example['interview_answer']}\"\n",
    "    return {\"text\": text, \"evasion_label\": example[\"evasion_label\"]}\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": (preds == labels).mean(),\n",
    "        \"macro_f1\": f1_score(labels, preds, average=\"macro\"),\n",
    "    }\n",
    "\n",
    "full_data = dataset[\"train\"].map(preprocess)\n",
    "if \"test\" in dataset:\n",
    "    comp_test_ds = dataset[\"test\"].map(preprocess)\n",
    "\n",
    "full_data = full_data.class_encode_column(\"evasion_label\")\n",
    "\n",
    "# train / dev / held-out split\n",
    "split1 = full_data.train_test_split(\n",
    "    test_size=0.1,\n",
    "    seed=SEED,\n",
    "    stratify_by_column=\"evasion_label\",\n",
    ")\n",
    "train_dev_ds = split1[\"train\"]\n",
    "held_out_test_ds = split1[\"test\"]\n",
    "\n",
    "split2 = train_dev_ds.train_test_split(\n",
    "    test_size=0.1,\n",
    "    seed=SEED,\n",
    "    stratify_by_column=\"evasion_label\",\n",
    ")\n",
    "train_ds = split2[\"train\"]\n",
    "eval_ds = split2[\"test\"]\n",
    "\n",
    "labels = train_ds.features[\"evasion_label\"].names\n",
    "label2id = {name: i for i, name in enumerate(labels)}\n",
    "id2label = {i: name for name, i in label2id.items()}\n",
    "\n",
    "\n",
    "# tokenization\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "    )\n",
    "\n",
    "train_ds = train_ds.map(tokenize_fn, batched=True)\n",
    "eval_ds = eval_ds.map(tokenize_fn, batched=True)\n",
    "held_out_test_ds = held_out_test_ds.map(tokenize_fn, batched=True)\n",
    "\n",
    "train_ds = train_ds.map(lambda x: {\"labels\": x[\"evasion_label\"]})\n",
    "eval_ds = eval_ds.map(lambda x: {\"labels\": x[\"evasion_label\"]})\n",
    "held_out_test_ds = held_out_test_ds.map(lambda x: {\"labels\": x[\"evasion_label\"]})\n",
    "\n",
    "\n",
    "# class weights\n",
    "y_train = train_ds[\"evasion_label\"]\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train,\n",
    ")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "# trainer\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss_fct = nn.CrossEntropyLoss(\n",
    "            weight=class_weights_tensor,\n",
    "            label_smoothing=0.1,\n",
    "        )\n",
    "        loss = loss_fct(\n",
    "            logits.view(-1, model.config.num_labels),\n",
    "            labels.view(-1),\n",
    "        )\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    learning_rate=LR,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE * 2,\n",
    "    gradient_accumulation_steps=GRAD_ACCUMULATION,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    weight_decay=0.05,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    load_best_model_at_end=False,\n",
    "    metric_for_best_model=\"macro_f1\",\n",
    "    greater_is_better=True,\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=4)],\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "# evaluation\n",
    "test_results = trainer.evaluate(held_out_test_ds)\n",
    "print(\"Final macro-F1:\", round(test_results[\"eval_macro_f1\"], 4))\n",
    "print(\"Final accuracy:\", round(test_results[\"eval_accuracy\"], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 679
    },
    "id": "ek0ZQLj582sE",
    "outputId": "4453ab6e-fc24-4a17-b2b2-e95997a25c22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2450' max='2625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2450/2625 26:54 < 01:55, 1.52 it/s, Epoch 14/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.973989</td>\n",
       "      <td>0.501608</td>\n",
       "      <td>0.333939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.897040</td>\n",
       "      <td>0.524116</td>\n",
       "      <td>0.325869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.107000</td>\n",
       "      <td>1.804468</td>\n",
       "      <td>0.565916</td>\n",
       "      <td>0.449354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.107000</td>\n",
       "      <td>1.729563</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>0.517879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.107000</td>\n",
       "      <td>1.750425</td>\n",
       "      <td>0.585209</td>\n",
       "      <td>0.524754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.759300</td>\n",
       "      <td>1.781302</td>\n",
       "      <td>0.601286</td>\n",
       "      <td>0.515721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.759300</td>\n",
       "      <td>1.839293</td>\n",
       "      <td>0.617363</td>\n",
       "      <td>0.543590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.759300</td>\n",
       "      <td>1.845430</td>\n",
       "      <td>0.627010</td>\n",
       "      <td>0.554245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.495400</td>\n",
       "      <td>1.958704</td>\n",
       "      <td>0.623794</td>\n",
       "      <td>0.546990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.495400</td>\n",
       "      <td>2.002862</td>\n",
       "      <td>0.630225</td>\n",
       "      <td>0.561017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.495400</td>\n",
       "      <td>2.091083</td>\n",
       "      <td>0.614148</td>\n",
       "      <td>0.544724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.225500</td>\n",
       "      <td>2.141365</td>\n",
       "      <td>0.614148</td>\n",
       "      <td>0.554945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.225500</td>\n",
       "      <td>2.199818</td>\n",
       "      <td>0.620579</td>\n",
       "      <td>0.556497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.225500</td>\n",
       "      <td>2.223965</td>\n",
       "      <td>0.614148</td>\n",
       "      <td>0.549988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final macro-F1: 0.6009\n",
      "Final accuracy: 0.6348\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    "    set_seed,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from google.colab import files\n",
    "\n",
    "\n",
    "# seeding\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "# cuDNN determinism for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# configuration\n",
    "MODEL_NAME = \"microsoft/deberta-v3-large\"\n",
    "OUTPUT_DIR = \"./deberta_task2\"\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 4\n",
    "GRAD_ACCUMULATION = 4\n",
    "LR = 8e-6\n",
    "EPOCHS = 15\n",
    "\n",
    "\n",
    "# data\n",
    "dataset = load_dataset(\"ailsntua/QEvasion\")\n",
    "\n",
    "def preprocess(example):\n",
    "    clarity = example.get(\"clarity_label\", \"Unknown\")\n",
    "    if clarity is None:\n",
    "        clarity = \"Unknown\"\n",
    "    text = f\"Context: {clarity} | Question: {example['question']} Answer: {example['interview_answer']}\"\n",
    "    return {\"text\": text, \"evasion_label\": example[\"evasion_label\"]}\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": (preds == labels).mean(),\n",
    "        \"macro_f1\": f1_score(labels, preds, average=\"macro\"),\n",
    "    }\n",
    "\n",
    "full_data = dataset[\"train\"].map(preprocess)\n",
    "if \"test\" in dataset:\n",
    "    comp_test_ds = dataset[\"test\"].map(preprocess)\n",
    "\n",
    "full_data = full_data.class_encode_column(\"evasion_label\")\n",
    "\n",
    "# train / dev / held-out split\n",
    "split1 = full_data.train_test_split(\n",
    "    test_size=0.1,\n",
    "    seed=SEED,\n",
    "    stratify_by_column=\"evasion_label\",\n",
    ")\n",
    "train_dev_ds = split1[\"train\"]\n",
    "held_out_test_ds = split1[\"test\"]\n",
    "\n",
    "split2 = train_dev_ds.train_test_split(\n",
    "    test_size=0.1,\n",
    "    seed=SEED,\n",
    "    stratify_by_column=\"evasion_label\",\n",
    ")\n",
    "train_ds = split2[\"train\"]\n",
    "eval_ds = split2[\"test\"]\n",
    "\n",
    "labels = train_ds.features[\"evasion_label\"].names\n",
    "label2id = {name: i for i, name in enumerate(labels)}\n",
    "id2label = {i: name for name, i in label2id.items()}\n",
    "\n",
    "\n",
    "# tokenization\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "    )\n",
    "\n",
    "train_ds = train_ds.map(tokenize_fn, batched=True)\n",
    "eval_ds = eval_ds.map(tokenize_fn, batched=True)\n",
    "held_out_test_ds = held_out_test_ds.map(tokenize_fn, batched=True)\n",
    "\n",
    "train_ds = train_ds.map(lambda x: {\"labels\": x[\"evasion_label\"]})\n",
    "eval_ds = eval_ds.map(lambda x: {\"labels\": x[\"evasion_label\"]})\n",
    "held_out_test_ds = held_out_test_ds.map(lambda x: {\"labels\": x[\"evasion_label\"]})\n",
    "\n",
    "\n",
    "# class weights\n",
    "y_train = train_ds[\"evasion_label\"]\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train,\n",
    ")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "# trainer\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss_fct = nn.CrossEntropyLoss(\n",
    "            weight=class_weights_tensor,\n",
    "            label_smoothing=0.1,\n",
    "        )\n",
    "        loss = loss_fct(\n",
    "            logits.view(-1, model.config.num_labels),\n",
    "            labels.view(-1),\n",
    "        )\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    learning_rate=LR,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE * 2,\n",
    "    gradient_accumulation_steps=GRAD_ACCUMULATION,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    weight_decay=0.05,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    load_best_model_at_end=False,\n",
    "    metric_for_best_model=\"macro_f1\",\n",
    "    greater_is_better=True,\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=4)],\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "# evaluation\n",
    "test_results = trainer.evaluate(held_out_test_ds)\n",
    "print(\"Final macro-F1:\", round(test_results[\"eval_macro_f1\"], 4))\n",
    "print(\"Final accuracy:\", round(test_results[\"eval_accuracy\"], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E2yV3Ro983_u"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
