{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "77aacdddf9ac4c44bd1e1857528f6e66",
      "d509bc7c5f4c4d7fb27877537bb45c92",
      "81e1ae5d9f60465eb9a1f35ff22468b4",
      "d4b916e008d3452eab5f6c8dd44a0a18",
      "040d556ded504166b728c151abc41ae3",
      "1b64efcb7a984e7caa73727ddf6ee3de",
      "e6c28c2d195049eb81adfae1b5e003da",
      "c6e65987df2b4d3ba5cfcf8d0cba0763",
      "5eea2639f6ff4d14a4599dcb8f7d399b",
      "9967f8091501435e83a9f2c2c2c38724",
      "7c199c07c4234a33998fbbecce6be421",
      "714801a0487345d5939c91dcf4c0c995",
      "600b3681eebc45508604de3c2ccd2f73",
      "3bd54d720d344e7d9e8fda65f7b4306f",
      "8236b695bf184b72b98c7fae10d4dda8",
      "5037d64bfa0741ae9db52ebefa9ed9ea",
      "d80fd35f8f514aa7afcbe43094974895",
      "a5d476e9c78643fd94c3c558bde489e1",
      "5b9aa14be3994a7bb8d33353f6af08f1",
      "c6c864548e554288a9f843b09139c501",
      "dde06938bd064cf8a8e56ab6e8c03aed",
      "a8c0a5ce3509451bb88ef9080104a0ae",
      "83266b809d0b4443ba9d43f406a853aa",
      "722ffb8d7d0f4522a0209e5948b34b28",
      "bbb6fd19ba0647caa1349b0e24d50eea",
      "0d92eec02a7c475f91d977a4866e92a0",
      "afd8e8dc58b5463eb46e78381c539525",
      "a26ac6b2a8534a469d2d0e7ef86f74d1",
      "7557e8152b7b437cac1bcca134440fb6",
      "dff67493bac949d48403667c713d00a4",
      "d90384e533a445a9bb468ae64a9264eb",
      "e7a5844a28424a6bbd0e1736f9cd9ae5",
      "71b91609ccd3479fa98b85d40b671d5e",
      "47d23ddc7ab148429ef21f5b35c36676",
      "cc2139bde5bb4ca481cd26b60e10a8a9",
      "c7148bf729b44b72b860cc3f0c431c28",
      "18e6597119d44f579a12840c12e7027e",
      "614f8512e54045edbe8d0fb41f0c127d",
      "668e47bd4d8d4148a6a764dcd1f610ba",
      "300287445bd54f7aaa3f44f4be05a26a",
      "097fd179a07147aa954dd1b472c39217",
      "f1c88d9cb81c491f8e18922d955d1c08",
      "b3eced332e734a85b7e0eef43cfcf7a2",
      "440103daf2a64b61a67caedaaf2b4db6",
      "33bee7ec19a044168865cc3e0d3c311c",
      "f6dcfdb939e24a80874fc89dd387f443",
      "3d60407cd02a49b4bd63b68544506f14",
      "6f5fa92e23d2455fa0c783a962a662e6",
      "d6e7f1602bff4a0c987fc16f0d691258",
      "547e7cd53a904c859744635f9125ce5b",
      "008eba338a464cb883110f674d936dad",
      "3c9f8224aca6422c9be2d2ae06654d62",
      "1f78fc2ceabe4a6b880800d20c29f691",
      "9978d10a817942bbbae210d5f513638e",
      "24d621d9b4eb403aa3e53f048e2bd248",
      "36ca6c938b4948a696268802bdd0bb5f",
      "6501ff8fdc344016843744811f84ba14",
      "0373b291a3e140548403e83027ba936a",
      "83e3acabeec04dcba96136084149b187",
      "cb4c7fb7138d4b5481ccdc3fca7ea8dd",
      "df11e458ad61450fa703359333f29031",
      "5f20996f8fe54fd0abfaf112f25ae574",
      "b3b686236f474400b67205761591a42e",
      "60a48d390c9c435fb00d4858ac6e64eb",
      "77497fd551b14461804bf564d274b877",
      "1ed05541ef1941468eb0ad25ba867030",
      "b4ba6d9c6fd145268be7bf4d15d948f7",
      "10447d2f9126445f921691e42bed1b30",
      "54a9d65cad4f420484b2a660c8bc0059",
      "a98dc355f73945bb9e39137d37136361",
      "d856ea4d672d4bf59997348d2a676471",
      "e46914432efd469fb07c2efd11486671",
      "53957c19a31641cf9410dffb5b56689a",
      "32b91412a6cb443aa4983e55c8fbc678",
      "c7a281aee6bd4e129612bf321b733214",
      "fbe147daea194be6b6f7cede7c5bcda6",
      "f7a17d211e5748f9b546b92613ad4b98",
      "2d11dce0b4734467b3c31a83af2e6624",
      "f92c7f421d9e40efbd74a9539031ef97",
      "20f80d6b66fe48f18ff8972c01c9d0d0",
      "a10b3caff4f94199953b2fc8a5e81148",
      "96d3970534a14c17b1335004b697175b",
      "5dc7f282e632433ab0562a06a349934f",
      "7846b9694faa4a8f8900adabb8af13e6",
      "0e202cd002e74613b4bd7452aeaee063",
      "971db727825a48d8ad0fff2cfaf1400b",
      "268a8304d97c45588435c3ac0aba8e64",
      "a5d564dc9793433d84879a82b56f4b46",
      "7ff2687e78534e4685bc54f0f7980921",
      "f29bb827031f4fb68c526221e23b26e0",
      "8f1804623b5242fe89c25e6d768251fc",
      "cc9747d2c39f4a96b186863d9614747a",
      "24ec040c80ca471a91e559a65cc0b33c",
      "02bc8acdd1fb42c8a9aab377bdf2cfcb",
      "886854996a904c39898031d17c5b761b",
      "357fff609efe4c469f8889d7b585e127",
      "d7c1ca726ad64a72a1aa6ca05d74d11f",
      "4e632a20f5d2485d89b7ce25340beb41",
      "747930992c484107b6eed47fc2d80aff",
      "de12d0648dbe4cc0a2108407ab24e71e",
      "72c5348c4cfa4184a91f2596b0301a5b",
      "65eae3704ef24a17b5e9b672330b1018",
      "76c013c3f68f466495578459fc4b3862",
      "4513101e93e84d0aa318893e7eb2a1c9",
      "867bc6054b4c4338afc5738a86d11336",
      "2889dc0b9e4d4b52a5ce83fd4b19f7b5",
      "6f7edff0dc95437984ff846b3900d703",
      "aa701af9fca74433a1f2edb658a02be0",
      "4c243a4a081f4b58968653ae3b6ec4e8",
      "5db5e02adeaa47489e357b898ea5b050",
      "49517f7c35cd4cde99a6c472b0fb28d0",
      "be4b180233124617a9232db96ddcc962",
      "103f1ad6552a4afe810f65053513f1fd",
      "f11e6ab2a4c24c7fb110487b4646229e",
      "5b59ef71386148818ac44c4533e7c6d2",
      "4d0543009ac9461e97eedcb47816dc53",
      "bcec04ea87474b13ab1194a85f2b0e3d",
      "8a8d28fa5f5f464ba067e46e3cfcc65f",
      "6231538e8fc84eeca2295c91a0ee0a12",
      "86354aae78a843698df63fa08fcd2efb",
      "8f3426251640471ebaedde28a9bc37ac",
      "7cb126a718624846b538ae6a16015039",
      "6d4027dcc72a4e16a33dcf017e4d8b31",
      "dfff36abe9e8451aba45c8e5ad731a7b",
      "3d49c993ce954231bd7d442f22e40e97",
      "bd774ccf1da8443fbaef3f0c8425df17",
      "f05985dcdac34a22902d20ef5097906d",
      "15324fc96e29487fa17e73543b1d4ec6",
      "9175d86b7b33428e80bd02cba5fa6663",
      "a6cfb15889244b7db1dfa448be5b9197",
      "f667b47fa5a44009b7c955b2270c0e26",
      "e25c489b162e4146bc03fb04e77e5e48",
      "4adfda1b36494182a189d56a8bd21c93",
      "7e09ed81b9a64769945179009c3a15c6",
      "ab5ee8f351404b3a81f9a1319be590ab",
      "6ad4c3a5a0f64b6a84a15fc9f49af8cf",
      "4527167cc1694d5aa97b3c58927800d8",
      "194903439afe41788ce4153e2d679d08",
      "0f199bd153084681ae4e275add7ac390",
      "c1641c3f40da4f61906cdee9222e25bb",
      "265738a15dcd41eb9ff9dd7965595222",
      "1ed0f3653b574ad398279d4709ff9bc5",
      "9be11e1d8bdf4a0f93bc40ee62e3ab9e",
      "745c3df78470466ba4d203bb03d4e76a",
      "6c86ed45d8724b85b377a8b14791f536",
      "dcebd3044fe64b9a877e98c1afbbd8cf",
      "abcdd10cdeab485490d96ea90d4cbc07",
      "0c2970a67c7a448d957bf6460e750a3d",
      "9ba3b910c39e4f72889a2e6b1d7567ef",
      "9d62b494bdb64a2e82262582f4617d7c",
      "77bb4994ee5b4b07ac793f2b451015d6",
      "7c6867ea036e43bda616ef94a3d131c7",
      "268b358f4d3b498e8b1c95542b4c143e",
      "e8ebed3365ff4294be239f8818890fda",
      "590e1c45581b4f1db3a7643ad0c32757",
      "fa6b5fb9e9624d6c9a06c41a8a088577",
      "31939bc39e2244ab98a182b5ee3b4a9d",
      "a3e1177fd80842b199a8b0ceb75789ce",
      "1b5ac3ce1051423fad2da64f240ad323",
      "4e3cbf349e954c488822d42ada156692",
      "facdaf0a8b7e41eeb226347dfbb4f832",
      "c0db333315854fa6adf8ea29cb5521d1",
      "ae493ebe405f4426912f127045ac8279",
      "216c90911b854db996220d8a137db185",
      "e7107a5fb9e94b319f46179403349d05",
      "06265259f20c43059d3e41aabc17e74d",
      "d2a184e13a694f86ad695b738a8207cb",
      "8edfe87e309e4f1a82fae2e450fe950d",
      "973a5f1e9b254c75855a5c0517812b38",
      "e4e205c0fb3849f8ae27eeb6c3075b7b",
      "e53af10495a84502b73197ccb2b10bd8",
      "b200192b218846d88b6e103cb05cedeb",
      "7e8095be8e0a4919b12d25bdd727b8e4",
      "30519324ea6d4b46be3811258dbb7b93",
      "94d5e3e56ce4402da6f276238b531aef",
      "b789ffd2dc924827b0cbbcdb51acd7cf",
      "cf491d27de704049b3d04a5b4b6ebef3",
      "fc441523f65e49be89f742772273ac9b",
      "48cc87b0937748ffb31d1ac428f42e62",
      "e47044a3f2c748b2a1099b3a178d0e99",
      "86de8acef18f42b1899afee5c851ebd8",
      "69331ee9472e4235bf39fb3e789db9b3",
      "af817178d14145f98f5e4aff5c5ff6b6",
      "d96e9081616b4e98b8345fcb0891c3f1",
      "1f8adde0f8014b85b87c3dc1c2982a46",
      "99ba3f86358d47829bb612fd23f5a957",
      "1f5f4cc216a440f58364fe3f6baf392e",
      "939e837ceb0e4cbb84c5298b2abffe75",
      "18cffd25aa4046b1bdd11afbd4db0d49",
      "b3dcc07711434d3bae0b607e4787fdf7",
      "71a31d4f942f4871aa4b3b0f89bf04df",
      "09e78f4241964ca298be866093338ae9",
      "5331021c4d564b0d93ebcb2be3223a49",
      "5f6543dad7d742c0902e4524c6ca6301",
      "8164e0c553f54a899ce59b443e595c72",
      "64a636a5b063402b8bf348057a034e5f",
      "ea623ff8775247689c5a8401c9b2afed",
      "26472f39e64f45708f6be34e6a84f354",
      "3ee19279807943aa8c3c0bff909e3b57",
      "8998891f48474d15a876752c9b9fc6b1",
      "6d78b1f6cab7405fabd927bc0232aa8a",
      "fb1f91943f2647b2be4788781fec72e6",
      "3cf662dfde2442f781bdcdd48f6e0cfb",
      "7c8e2788fac64b69bcb872429b55f80b",
      "d42e7bd5f40446e3829cd8dc729393ab",
      "7674be3a2d674f81aa772bb608c5d041",
      "6730cbaea3cc4fe188c08b8f5e560a8e",
      "c67b221615a0427499d7b46919023045",
      "9e27e8854321405cb25c62bd03864181",
      "5d66f4487df046e4a3c901609ce8506d",
      "c26a815c16e94357af18cea859f87c26",
      "2e18e2c797354d44899d892566d58af6",
      "5621b43db0654c74a9c2b1ec703cb779",
      "a33d45cbabef4c2a94ceac4325792ade",
      "4d39e96ca4954c3598705fb8ce8b6287",
      "513423337ff8414c8e34d80f9f1ea78a",
      "b1b1212d07cc4fbc89dbe7d499788659",
      "cba61ea6578a488e8fa3ed3b35c8c2d5",
      "ae55127056c64a68aa961283eb55d216",
      "76b38814edaa4f4abf994ad18c4093e5",
      "44cd63c900884e4fbbdf5d2db6192b00",
      "d71ac512a1054421ae20df7d978e7586",
      "d3bb4556a9c94d68b66afd07177a590b",
      "f34e8ceb7aa3443a92ba0a682c9eda9b",
      "a90f56b2ce174aad94b7860129b2b1c7",
      "26166d2961524ae9857b969936d33ab2",
      "8a4b69e00a4946218c0291ad8b17cb98",
      "96c8fe5d3a0f401ca0f71c032f15297f",
      "0fb9b21604ed4404aa37468986c030be",
      "354401b0411749d58a71ded42e2a4f33",
      "3d7b0009a31941f493e8dfcc8c5520e1",
      "ba10089c4cad4b17b2492b13b3bed406",
      "fe646d40a8ab42d6a17fd5342cfd896c",
      "37c6589f7bad4428907d43c52ee71d63",
      "5e266e3ad5bb41389d30a8ca5b7ea9ce",
      "1d212218167c41e198d7615e612d937b",
      "7828c4760a96429d8cb84926bc804076",
      "61627d88ea92477faa7ca31f1aa3d315",
      "fd6249a4062447daa767f20665b20946",
      "73792aaa9c68425fb61a9c78236f7d7b",
      "0e76a1c65a10474f95ad397ae4dbd65d",
      "740f9adc07cc4ae8b67fd823eff32b82",
      "e577a8c8d44e4a919588c5c4b732059d",
      "7fdf1adfa48f49c7b5942b75c6b00744",
      "65c5f0916de840e68802ae24a8e8e3e8",
      "96608f98c51b49c681e909cd41f299ad",
      "96e84d33ca5e4842aae99eecf23bacd4",
      "7805ef630a9941b5bd5c9dbfa6006777",
      "8cd6e0f9c2204abaacb86eb331b28d32",
      "56ecba31db104e7392103bfb14a0c201",
      "a94b536c645c4f0082dac683b21b377c",
      "06cff289476f4eff94c5ee9bbb586854",
      "0afc5162ec19499e95be57bd75d4aa62",
      "6a5acf7e7dd1409abb5bca2fc7edceb6",
      "d75275ebcc1e4ba9a8e6b51193311ca3",
      "7036d4ff0d6847ab8f03655cbabde8e3",
      "32d682452c3e4a70acaa10d45452935a",
      "432ba276b75241d6a625b27ab28f44f5",
      "7782fbc33a4c44feb79db6a0d01d49f7",
      "ead173fe80e545259a6892635d54ccf6",
      "39e8bb762b574dc1b8bfa3ab0c8cb9f5",
      "a12f23666f8b4a699a814492bd22347b",
      "917ed384d6b847c793e6f32b106bd66f",
      "6fc71e755a42482a888df543337bb3e9",
      "50458f7865394d81ae3644c27055c22a",
      "0dd7fea4489d4bd2a239d15c31023498",
      "8817d8de09a540529bdbb8791d4b2d77",
      "136b3f5892ca4fff9d98fb0b81e4ef68",
      "bd147ed0406442a49ae3dc96a714e610",
      "404feda58a97412ea8ad78a5297e23c9",
      "1593bdeb3fec4e3dbd05651159e85fe1",
      "56e5f168debd48949b15437c8cd44f98",
      "4a6d9ef2425c4bea8b037f0a4f27d9a9",
      "2933c04a9b664c829cb16b92b4d4b677",
      "f34c394f0260454f9aa1481951987a3c",
      "309d7c3eee4d42da8a72d369fa06f440",
      "1caa53ecb80047ce807d0b8329836cc4",
      "f1e6fbb477934287af3d8e045b589009",
      "2c880eb5ca2c4335b3d99cf0254c322c",
      "0e98d3ad208440e19886181f43963dc8",
      "4558d760d33e424aa759dc18e4c3f90e",
      "66aea4ccadba4a70ae32579afcacbf3d",
      "97e428ce844f45a2bf8eac72991d766c",
      "3b4f850ee6d8408894530ea0ad26279e",
      "000e18bb409f459fa1369eecacc0d369",
      "12c1809e0870442db90537e7c5c78850",
      "97668dd667de4164bfef526ac44abbf3",
      "45902a1a654d4a2f9ac22e7b4dc1eddf",
      "38f06191cec84feca6270e1a1a6eecc3",
      "10393a72f78a4201a0021da00dbb30fa",
      "ce393c65035e402f95555c063f7d609c",
      "08094203b34a48e994dffb5785ba589d",
      "9587e169671b4b2fbec3bbafbd533549",
      "778bdf7d41b4417db1bb20b3ad745f2e",
      "94857c8560854b74a7336d4a3d36c1c5",
      "8aafe2e6329b4bdb863a496fb45c7bc6",
      "af58f4a55bf14bef890f9506201cfa75",
      "b098c8f931ae40eb99f0c17ddb4da112",
      "a71dae8d414b4fb390b386650a7d6cac",
      "c06a8e68fd7c450b8efd8a8ea4e0eb61",
      "a311418087ef4ab3b7fb17a9295db073",
      "7bfd7a2fa1364bc59942eb27f29326f2",
      "11260c98e62a44dda5e8985bcb3919bb",
      "1540606acd7849a9a7181b138705da5d",
      "2d0809136cd44f5597b9788f486de51b",
      "3632c6ba8aaf4790ba60b636654003cd",
      "8aadae8dca2e4445adfa122da55c136b",
      "7f8d9dbd2c754b18b8c52c927d079229",
      "57097de5f7be415cbfd61a4c14ac9d2c",
      "0996f22833e944c5bc5ac3e54eb95fb5",
      "6dbb6f0818e6485989f331f8ad2373b3",
      "d130c080eaf1416298429cbd4a3fde11",
      "804586c975194b5e987ff1fa70dfb128",
      "e62fe1f61f15407ba9d1de1ab983a81f",
      "9417c931a9734b1d976db3f3b8cf7821",
      "bd70a96985f740ff933a4c6a57484936",
      "d724f91a52c54f2291e9b0ff673ad796",
      "e3406117a4604eda8f176fa747679673",
      "1a8d6d4a3c294840bad426ad3da3e886",
      "b52a83e5ceb54043bb3b72805376e240",
      "ff97d891ab1c47ddb70eb6052e650efc",
      "cca163dfa37e4a3583b0545f3d49cae7",
      "4a38086943cc439bad29a3b2f9cdc932",
      "b3b09399e95c48b68c3c0842ed8ca43b",
      "baa14935b1404c19a6986689c9e2700a",
      "236c51db9f5347e9a6025be8aa25f402",
      "56a45a47035b460990929c92351d71e9",
      "57c19f34f02c435fb7a1c891ae96d9a6",
      "3929452d19304cba860213be298a95c3",
      "a1c1d58baaba4920bbb78063a76b8fce",
      "e7e31dbf3b8446899aadc01858383097",
      "33f5f8b3e642412eb63fb0ca3d57399b",
      "53c521cbaa6549ba847c249082ce9dd8",
      "817fa7d473b443d58948e02256408ac3",
      "9e8989429c484b5db34b59914eb0558d",
      "7f9d56f251234deab97b1f6445437111",
      "2b784a90f91844f79c45ea25ae06dd05",
      "97496bf45b974212a941473baf613eac",
      "2702530c96304a8c8c84d4ab67821a50",
      "7a22fb023b6f4cb7ad27487d9ebfebb0",
      "720625efad124970816626de03ae3e17",
      "73a9ae4a88d0405d8d8d669782982bf7",
      "9f9bddaf690f49a1afdfc033289763e0",
      "07c05bf52acb4598a715980973cb66e8",
      "a30025fccf8f4f978c4079a68dd20d85",
      "ce02f3c9e9804e6a8c6f2b741d4f6df4",
      "cfe792f683824efd9ccd90a9e782f5bd",
      "c8ecc7650a4a4a968e359e65d39fdde2",
      "50ac5eaf00c7472c9b3378e4510dd9aa",
      "0bd8204a997243ed81900cf3c9bbffba",
      "3161808d9d7a4074a92fd8996f465af1",
      "e65f296f2bb34353a22197b4d00b0860",
      "8485d7a205e84639af28390340a6c865",
      "bb3cbda6d0f1437895338b4519c0b10f",
      "df5cc852b87d4807b984909dc2567a56",
      "826c5f0715f1466aa87d64645e43ec3e",
      "e1b49aa6c5c14f9da5400b7cbd86c8a8",
      "36277ec6c6614bee8c3d3788054fba30",
      "87084ad4b7df4a9ab1bbc059c7413473",
      "a3993a568b6b46ea875af2ca92c09e15",
      "a0513828d742446394f628939f301d45",
      "576879e27b5a462c879240f4060dfb1a",
      "c2efb1e67cde465c987d2ff4a424b42c"
     ]
    },
    "id": "CbaAcH4P_dbh",
    "outputId": "a1791b72-a547-4e1f-937d-8b6ae0a8129e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77aacdddf9ac4c44bd1e1857528f6e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714801a0487345d5939c91dcf4c0c995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/3.90M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83266b809d0b4443ba9d43f406a853aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/259k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d23ddc7ab148429ef21f5b35c36676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33bee7ec19a044168865cc3e0d3c311c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ca6c938b4948a696268802bdd0bb5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ba6d9c6fd145268be7bf4d15d948f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                          | LR         | F1 Score   | Accuracy  \n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d11dce0b4734467b3c31a83af2e6624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff2687e78534e4685bc54f0f7980921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de12d0648dbe4cc0a2108407ab24e71e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49517f7c35cd4cde99a6c472b0fb28d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb126a718624846b538ae6a16015039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4adfda1b36494182a189d56a8bd21c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745c3df78470466ba4d203bb03d4e76a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590e1c45581b4f1db3a7643ad0c32757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06265259f20c43059d3e41aabc17e74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf491d27de704049b3d04a5b4b6ebef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/874M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training microsoft/deberta-v3-large with LR=6e-06...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939e837ceb0e4cbb84c5298b2abffe75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/874M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1750' max='1750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1750/1750 20:03, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.934633</td>\n",
       "      <td>0.514469</td>\n",
       "      <td>0.313996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.890892</td>\n",
       "      <td>0.556270</td>\n",
       "      <td>0.299446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.081400</td>\n",
       "      <td>1.815648</td>\n",
       "      <td>0.559486</td>\n",
       "      <td>0.421622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.081400</td>\n",
       "      <td>1.765336</td>\n",
       "      <td>0.578778</td>\n",
       "      <td>0.498560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.081400</td>\n",
       "      <td>1.742920</td>\n",
       "      <td>0.614148</td>\n",
       "      <td>0.560135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.758400</td>\n",
       "      <td>1.763422</td>\n",
       "      <td>0.607717</td>\n",
       "      <td>0.535364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.758400</td>\n",
       "      <td>1.793359</td>\n",
       "      <td>0.610932</td>\n",
       "      <td>0.536739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.758400</td>\n",
       "      <td>1.798722</td>\n",
       "      <td>0.620579</td>\n",
       "      <td>0.584594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.562400</td>\n",
       "      <td>1.835942</td>\n",
       "      <td>0.636656</td>\n",
       "      <td>0.579547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.562400</td>\n",
       "      <td>1.842330</td>\n",
       "      <td>0.633441</td>\n",
       "      <td>0.578713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: microsoft/deberta-v3-large (LR: 6e-06) -> F1: 0.5709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee19279807943aa8c3c0bff909e3b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d66f4487df046e4a3c901609ce8506d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training microsoft/deberta-v3-large with LR=1e-05...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1400' max='1750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1400/1750 16:12 < 04:03, 1.44 it/s, Epoch 8/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.010729</td>\n",
       "      <td>0.495177</td>\n",
       "      <td>0.257005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.868127</td>\n",
       "      <td>0.530547</td>\n",
       "      <td>0.326434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.090500</td>\n",
       "      <td>1.805673</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>0.448772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.090500</td>\n",
       "      <td>1.785795</td>\n",
       "      <td>0.614148</td>\n",
       "      <td>0.538567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.090500</td>\n",
       "      <td>1.687865</td>\n",
       "      <td>0.652733</td>\n",
       "      <td>0.641571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.694400</td>\n",
       "      <td>1.732186</td>\n",
       "      <td>0.633441</td>\n",
       "      <td>0.589723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.694400</td>\n",
       "      <td>1.778614</td>\n",
       "      <td>0.643087</td>\n",
       "      <td>0.598188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.694400</td>\n",
       "      <td>1.815991</td>\n",
       "      <td>0.639871</td>\n",
       "      <td>0.616471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: microsoft/deberta-v3-large (LR: 1e-05) -> F1: 0.5423\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44cd63c900884e4fbbdf5d2db6192b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/761 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba10089c4cad4b17b2492b13b3bed406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e577a8c8d44e4a919588c5c4b732059d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.38M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5acf7e7dd1409abb5bca2fc7edceb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50458f7865394d81ae3644c27055c22a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309d7c3eee4d42da8a72d369fa06f440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97668dd667de4164bfef526ac44abbf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b098c8f931ae40eb99f0c17ddb4da112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57097de5f7be415cbfd61a4c14ac9d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b52a83e5ceb54043bb3b72805376e240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-large-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training xlnet-large-cased with LR=1e-05...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e31dbf3b8446899aadc01858383097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1750' max='1750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1750/1750 20:36, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.475846</td>\n",
       "      <td>0.218650</td>\n",
       "      <td>0.109280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.944175</td>\n",
       "      <td>0.546624</td>\n",
       "      <td>0.244882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9.259200</td>\n",
       "      <td>1.899196</td>\n",
       "      <td>0.527331</td>\n",
       "      <td>0.318072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9.259200</td>\n",
       "      <td>1.884804</td>\n",
       "      <td>0.540193</td>\n",
       "      <td>0.349066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>9.259200</td>\n",
       "      <td>1.860370</td>\n",
       "      <td>0.585209</td>\n",
       "      <td>0.436261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7.637300</td>\n",
       "      <td>1.882291</td>\n",
       "      <td>0.549839</td>\n",
       "      <td>0.368513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7.637300</td>\n",
       "      <td>1.798001</td>\n",
       "      <td>0.559486</td>\n",
       "      <td>0.475307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>7.637300</td>\n",
       "      <td>1.778831</td>\n",
       "      <td>0.572347</td>\n",
       "      <td>0.507065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>7.177500</td>\n",
       "      <td>1.757619</td>\n",
       "      <td>0.588424</td>\n",
       "      <td>0.518124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>7.177500</td>\n",
       "      <td>1.756116</td>\n",
       "      <td>0.581994</td>\n",
       "      <td>0.516023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: xlnet-large-cased (LR: 1e-05) -> F1: 0.5138\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a9ae4a88d0405d8d8d669782982bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8485d7a205e84639af28390340a6c865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-large-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training xlnet-large-cased with LR=2e-05...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1750' max='1750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1750/1750 20:49, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.526704</td>\n",
       "      <td>0.205788</td>\n",
       "      <td>0.037926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.512107</td>\n",
       "      <td>0.305466</td>\n",
       "      <td>0.051998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10.307600</td>\n",
       "      <td>2.503928</td>\n",
       "      <td>0.305466</td>\n",
       "      <td>0.051998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10.307600</td>\n",
       "      <td>2.517178</td>\n",
       "      <td>0.305466</td>\n",
       "      <td>0.051998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>10.307600</td>\n",
       "      <td>2.469103</td>\n",
       "      <td>0.260450</td>\n",
       "      <td>0.088138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>10.190600</td>\n",
       "      <td>2.213534</td>\n",
       "      <td>0.180064</td>\n",
       "      <td>0.093922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>10.190600</td>\n",
       "      <td>1.933395</td>\n",
       "      <td>0.456592</td>\n",
       "      <td>0.250540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>10.190600</td>\n",
       "      <td>1.892194</td>\n",
       "      <td>0.463023</td>\n",
       "      <td>0.300091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>8.157000</td>\n",
       "      <td>1.885592</td>\n",
       "      <td>0.556270</td>\n",
       "      <td>0.295046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>8.157000</td>\n",
       "      <td>1.884456</td>\n",
       "      <td>0.533762</td>\n",
       "      <td>0.358476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: xlnet-large-cased (LR: 2e-05) -> F1: 0.3827\n",
      "                        Model  Learning Rate  Macro F1  Accuracy\n",
      "0  microsoft/deberta-v3-large       0.000006  0.570860  0.608696\n",
      "1  microsoft/deberta-v3-large       0.000010  0.542350  0.594203\n",
      "2           xlnet-large-cased       0.000010  0.513815  0.591304\n",
      "3           xlnet-large-cased       0.000020  0.382677  0.576812\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets scikit-learn accelerate torch pandas\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    "    set_seed,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "EXPERIMENT_CONFIG = [\n",
    "    {\"model_name\": \"microsoft/deberta-v3-large\", \"lr\": 6e-6, \"batch_size\": 4},\n",
    "    {\"model_name\": \"microsoft/deberta-v3-large\", \"lr\": 1e-5, \"batch_size\": 4},\n",
    "    {\"model_name\": \"xlnet-large-cased\",          \"lr\": 1e-5, \"batch_size\": 4},\n",
    "    {\"model_name\": \"xlnet-large-cased\",          \"lr\": 2e-5, \"batch_size\": 4},\n",
    "]\n",
    "\n",
    "OUTPUT_DIR_BASE = \"./comparison_task2\"\n",
    "MAX_LEN = 512\n",
    "EPOCHS = 10\n",
    "GRAD_ACCUMULATION = 4\n",
    "SEED = 42\n",
    "\n",
    "set_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "dataset = load_dataset(\"ailsntua/QEvasion\")\n",
    "\n",
    "def preprocess_base(example):\n",
    "    clarity = example.get(\"clarity_label\", \"Unknown\") or \"Unknown\"\n",
    "    text = f\"Context: {clarity} | Question: {example['question']} Answer: {example['interview_answer']}\"\n",
    "    return {\"text\": text, \"evasion_label\": example[\"evasion_label\"]}\n",
    "\n",
    "full_data = dataset[\"train\"].map(preprocess_base)\n",
    "full_data = full_data.class_encode_column(\"evasion_label\")\n",
    "\n",
    "split1 = full_data.train_test_split(test_size=0.1, seed=SEED, stratify_by_column=\"evasion_label\")\n",
    "train_dev_ds = split1[\"train\"]\n",
    "held_out_test_ds = split1[\"test\"]\n",
    "\n",
    "split2 = train_dev_ds.train_test_split(test_size=0.1, seed=SEED, stratify_by_column=\"evasion_label\")\n",
    "train_ds = split2[\"train\"]\n",
    "eval_ds = split2[\"test\"]\n",
    "\n",
    "labels = train_ds.features[\"evasion_label\"].names\n",
    "label2id = {name: i for i, name in enumerate(labels)}\n",
    "id2label = {i: name for name, i in label2id.items()}\n",
    "\n",
    "y_train = train_ds[\"evasion_label\"]\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": (preds == labels).mean(),\n",
    "        \"macro_f1\": f1_score(labels, preds, average=\"macro\"),\n",
    "    }\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=class_weights_tensor, label_smoothing=0.1)\n",
    "        loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "results_table = []\n",
    "\n",
    "print(f\"{'Model':<30} | {'LR':<10} | {'F1 Score':<10} | {'Accuracy':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for run in EXPERIMENT_CONFIG:\n",
    "    model_name = run[\"model_name\"]\n",
    "    lr = run[\"lr\"]\n",
    "\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "    if \"xlnet\" in model_name:\n",
    "        tokenizer.padding_side = \"left\"\n",
    "    else:\n",
    "        tokenizer.padding_side = \"right\"\n",
    "\n",
    "    def tokenize_fn(batch):\n",
    "        return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=MAX_LEN)\n",
    "\n",
    "    current_train = train_ds.map(tokenize_fn, batched=True).map(lambda x: {\"labels\": x[\"evasion_label\"]})\n",
    "    current_eval = eval_ds.map(tokenize_fn, batched=True).map(lambda x: {\"labels\": x[\"evasion_label\"]})\n",
    "    current_test = held_out_test_ds.map(tokenize_fn, batched=True).map(lambda x: {\"labels\": x[\"evasion_label\"]})\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(labels),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "\n",
    "    run_output_dir = f\"{OUTPUT_DIR_BASE}/{model_name.split('/')[-1]}_lr{lr}\"\n",
    "    args = TrainingArguments(\n",
    "        output_dir=run_output_dir,\n",
    "        learning_rate=lr,\n",
    "        per_device_train_batch_size=run[\"batch_size\"],\n",
    "        per_device_eval_batch_size=run[\"batch_size\"] * 2,\n",
    "        gradient_accumulation_steps=GRAD_ACCUMULATION,\n",
    "        num_train_epochs=EPOCHS,\n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.1,\n",
    "        fp16=True,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"macro_f1\",\n",
    "        report_to=\"none\",\n",
    "        save_total_limit=1,\n",
    "        seed=SEED,\n",
    "    )\n",
    "\n",
    "    trainer = WeightedTrainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=current_train,\n",
    "        eval_dataset=current_eval,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTraining {model_name} with LR={lr}\")\n",
    "    trainer.train()\n",
    "\n",
    "    eval_results = trainer.evaluate(current_test)\n",
    "    f1 = eval_results[\"eval_macro_f1\"]\n",
    "    acc = eval_results[\"eval_accuracy\"]\n",
    "\n",
    "    results_table.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Learning Rate\": lr,\n",
    "        \"Macro F1\": f1,\n",
    "        \"Accuracy\": acc\n",
    "    })\n",
    "\n",
    "    print(f\"Result: {model_name} (LR: {lr}) -> F1: {f1:.4f}\")\n",
    "\n",
    "df_results = pd.DataFrame(results_table).sort_values(by=\"Macro F1\", ascending=False)\n",
    "print(df_results)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
