{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "fa11f1afcd02410282504fd92a6acdeb",
      "27308d38853b473e8b0b437aa9476c18",
      "11821dc2154a49a080c4917061357ea2",
      "a17cbef588bf4a5887008e386b9990aa",
      "2eafad4df76e4cf6a72ece213edd326e",
      "2d0f83cdcbb74fbcad775c49c9fd2fea",
      "84e0f15f191f4fb98e3ece3dcea57a52",
      "56a62e7a807c4c249fc44e666df9e46a",
      "e61e6a9fbab645b3ac0ac628424e3ce3",
      "c98960dfb73243c9b5352d3f14d9b2fe",
      "bec6a40c3b05435586922a7c2c7d2643",
      "dd092330a3484ba5acb859daed1906c6",
      "0479e288fc0d4ac1864105c246c63ae0",
      "4d57bc7765be4475a8d7951d42bab255",
      "c319a4b41bb8404cb224bd192b2094aa",
      "7592437c2fe643fa9f00dd472803372b",
      "a8fa773443344153866e8a833243badd",
      "2f97bf5c115b431e97f970ac7c8451a9",
      "4141c5e13b664e69951c9edbc063c27d",
      "a5c0739a48034165bf4d4d822c79d03e",
      "fe166adb137543a0a6cfa1248a39b784",
      "690fba5a3e224b91ac5f0e1c548b5a5e",
      "ec20150db7f4412e9e0afe2ff3dd8bb2",
      "f3fbcd53a4fd4fbaa5e0584a43d72eec",
      "2be932e3c7c84b979bc3e11afd3ce36f",
      "a064f61ae6364ce6a307ffe3b2ffa95d",
      "ef19f34c11ec4eafb0d15d646103c0ed",
      "b76f0c859db3460894f2bd41cd555373",
      "418106a0fdae4342a27f4c6853094da3",
      "6a073ac7ece8462dbfc5c6946df76264",
      "8747d84f885c44a696bbfa2d21a5573b",
      "4505f87ea39b41aab48f1c23cb803448",
      "a624b7d853544a7dab8e9abcc8b3dfc1",
      "0ca52064db1d4f53a365fc8bafd8f941",
      "1823b92e7f8b4258ae6ecc6f1d3bc965",
      "31c39b38e05f4d09b992c879fdd840d8",
      "9ec95a8c20ba4933a78f9ba386ed7787",
      "4d91229bba624fa5a0b9d76b5f62d826",
      "57681c2566154e389788eecdcaae3d17",
      "68c37d6b92614b8595c70e2c0b39e21e",
      "cef09d82910d47509c24cda4d9a39c79",
      "535fa08fc11f4e7d82123e3732502a1c",
      "6cfd01bef0924a858a8863a86663ca84",
      "ac1a2569b1624f21a86568ba6beb5d1f",
      "3f2be3ffbada4974ac7278f1ae290023",
      "aeb5250c4e5e44698b2d3e64f384850e",
      "8143db974c834df98ff19634282471ab",
      "68468579861648e9b5e283cd63de7394",
      "cf69f46320e64a42a94cadd285804f6a",
      "d5c9805684c94d7ba408965c9fd90702",
      "57d2c04658b345d1bc410376e87f62be",
      "2dea5fce0eb642a190620d54e077b979",
      "e685a358601f47d3a09b574ff1c54bc2",
      "62af507e98a14791b9f18b621616cb0e",
      "ed0cd18c398c4748abbc2b6738136214",
      "7a38a56bd585470b9abaf17f78a0e697",
      "6f817e5745744ddaa2007a032e16797e",
      "f096895e005b478e87af488e412ba954",
      "1b0e62ef75c94f8a9f0c1446acaf7e22",
      "73ad131e0668451a88111b8c18aadad9",
      "4c8e054e58394ff9abb23a0690d70153",
      "a08230032daf4b5badc6d5e5f9f0b06f",
      "dbe6b9741aa349a6ace4eff5a887b560",
      "4cf18d09b7ea4f3abee4420218191e31",
      "db84173cea3f4729b2e8be581acde20b",
      "7ed222c8f7a64519a67e3c1d95656774",
      "18fc89fadba944579cf52391bbfc7724",
      "dc02ff45ee2d428b9331ed7737a92035",
      "49ae9721662b4a87bff243efd8d207de",
      "6992c19ed3aa4b8c9b4aa8bc24104be0",
      "35cdb5ec6b7f422aa1eae120160e9606",
      "95d351cb4f0c4c4898d9d5a1f8bc28ae",
      "bc54aa904b204034940829e6164afde7",
      "dc04d35dfb144725a2d6aeeb9b268927",
      "43ea611245e64469a951209747667af0",
      "82d3522606a54704837ce579346c335f",
      "9b09bb8a6bc14b1fae9ba622c1bb8b44",
      "fe5879fdf59d42dda4b519df00381a27",
      "bc706d7beb5345a4a98f432a7a40f813",
      "11031e18a6db482ab7a39b8b17d070af",
      "9c0c4da18c324aacaea72fe95ab92442",
      "2d0195b459324f20918095b8a27dc3c1",
      "f3f4e11ae61e483cb1f68576bf0fa325",
      "209adfd31130417aa200125813832e10",
      "be922d2ef16c47458f142dac5608f5a0",
      "d58f0bf898924127aedf5b6179aef987",
      "172432b0067d444e8a9f69b756f4efe2",
      "d5a05438e3e54a88b0e08302a1aa4407",
      "f52a2ff00cbf451e96b8f3593d56a77d",
      "bfcf8af798e647afa575d90207327c8f",
      "21995859107d4aada65957d06a7f10a4",
      "f5489415fa054684b3a1801f3ad43ace",
      "17ed172173024be88762e6fcb596dc4f",
      "7a5e14dc4eac488e9403b1bc80b47f61",
      "68f7147ee5b14bac931a00175bbec8f1",
      "31241f774b6349a9ab21b3dd39198ad7",
      "8668df19953c41a79f6591e0a7a6d761",
      "633d2c468978491caf10355cc6dbdfd7",
      "ed60d9b8097544ef82e8edd09cc85939",
      "22add8887b8e49f290e2da193c30332d",
      "01b465226fa341bb8408bb19baaa67a5",
      "e79e1ad6c6444737aec82cd2aa2bbbca",
      "d72dd6fdc7404d618fb6397d7f419357",
      "812f68c842664502bcdd418739b0ba56",
      "5603852ef3fb425baccf32faf773ab14",
      "3f31eed54cc24af495e890aa4e428336",
      "99ac4f1c4b8343e188c526bc8b0e6ded",
      "76814340e23e4e4ca0cb2149f0d85c75",
      "0e0a2ead2e5b4c89a9eb303331502b5f",
      "3df95866212d4ebf9a3f89e4620636eb",
      "59fb1cdbbc8b4ed897b9c0e390de0ead",
      "3f301cdf63054928b54fd5489c73e78f",
      "cf2c123b70f5430ca3e81bd2f9c0bb11",
      "d4b7b4e7314d42e4b67eb330951823b2",
      "02e4db0fadfd4dd8bbb4d3e6916af75a",
      "01797291482148a58658d8161d6d4eaf",
      "6e149c3642704794ac42948ae8930d2f",
      "e745061e25c44c71ba62bc6a6e975641",
      "b06a64a3a44041cf9b7f3212152c7335",
      "1c54c1ca887b45f28059cac5f46452f9",
      "54aac64243f9422684c2aadf8d1a5967",
      "6fd98ea6792b421ab0e922a3666d6d5f",
      "2ea97d493cb74009ae4be6b54e9cdbe5",
      "3cc1e4c013fa4d76906f18299a04c50a",
      "76f454eb6bcb479087d4fa252207474f",
      "0748d7940bae4cbdac4dbe7db8466e57",
      "431d680c65494495a4e9062440db7f3f",
      "466131b592aa4dc3b9ff28474dd05303",
      "558803bb93e44003a361d6477a3bcc84",
      "f71d4d76f38140308a519a3f39db1623",
      "73a8621a8dac471db18266cab8811259",
      "a08716e711494e63b95f6d96306581fd",
      "0e0c320e98cc478b9ba1dc39e5fb4c88",
      "7c02830e387e40bc9fe542cd723b9f43",
      "e6e332e0f408461ba49f55e8389d146f",
      "57fb7db75a6b403a9dfe66124af51f38",
      "8a0cb527f6024204b888568fc925a969",
      "8509fad82cc14fa89954de5fe0b665ff",
      "27356ba55db94c2eaa233614bf350669",
      "29162aaeeb924fb2827ac7bdb0cb6cd1",
      "6e472b9b8ab94994ac6b7be2d73cb55e",
      "ffddf5e7a56a471db6f267e9ca61d184",
      "b5e75c29e2c1487ea42852294637ca50",
      "70db24c555e24d808b71e815a2c2365d",
      "6351af8a510f42ea99533d600a62894d",
      "226273c71ee847af8c880bd9a899b90b",
      "55ade744d9ee4228aae9717c5cda6b74",
      "a609a49d51714d5f91a378fd06c1a336",
      "4fc7f8a05cd640f6b6b0bbd3d0817b9d",
      "68e14f769a4141b3a0f0ac05ca17539a",
      "132477ee71074a149847b83b1fd9422c",
      "55d91800348f44f5ad0fc862db477098",
      "4cc86924475c44528598e73d28339b89",
      "9f88bf456462432da1619b1666f140a5",
      "0ce56931473240fa9306e6b792779303",
      "6d28c2813b624e1ca82dd2b0edfb1a5d",
      "40228949717a4aedba3c39fe5f417708",
      "acb20676472f4fa58af35a27649eaa72",
      "b9ebd035657142a39004bd94aff3cc00",
      "0c8f4b8adf0f4002bc09df06ba87d7f1",
      "34e75f8ce2d34cd79dd9f93cea1511e9",
      "b232fecad19c4c8b9e99d3a26b62dcdd",
      "f6f8666e351d4717940116b524036d91",
      "92f2be48d3494e5594982d381a1029bd",
      "abc2ba53c4f54fcc90fd69a2522b79d8",
      "c263d0062b9f4e16bb3dd1474e90158b",
      "25358d40264b45f3a82229894bed4ded",
      "252ddcb2dc724d4bb5cae642e9d194f0",
      "1d4edc45e6b54d1da47c8adece95fefc",
      "76fac47d8d99405d9765abe9401da467",
      "3b965bc69d60450483f66f866b19c0b5",
      "6fb3601b33944236a29e318379fabe9e",
      "489ffb421ca347929fe42b20f20e6dd1",
      "aab317ae9d024071b0d679a90d0316f9",
      "796997586a4e4dbfa0a02133681e8e38",
      "0c1ab061bf5d4b67bb4c74a518c93c6e",
      "3d5fa9e422cd4c9da96b6ed7ddf62bf9",
      "c5c4143a86b84c048004717f7c5ca6b2",
      "18bd9339309348bd9fe98bb61c640db3",
      "5b9f515123e448cc9edec506be2dac62",
      "50cc813e682f458ba4e3ac3d99412eef",
      "b056e95c4f194545aea474204a7ae696",
      "764e2defa91942f5af54717295a74ac2",
      "e5a276773d984c069a879e47f852ba55",
      "af381861dd9e44599a98631aa687704e",
      "9e21b1d1d62245f8bd9fe5ed62e7735d",
      "0ccac1eca8e745c582fbe3a8096bff7d",
      "113277c299bb4f97af4b6a570eb9e0f4",
      "251d7cf0aebf4521b5dc4511fc0bedd8",
      "a46f941de77f4378b36012f4e3f1dd74",
      "728ae7a488d2455e99cbf37f4f4dd476",
      "a31b0d600a344376bdd89edcf48e019d",
      "f7f95275818c454eb9f77a16166d96fd",
      "d8c4877ba5e444e7824d96672a048492",
      "04d41ce4863746719f9e8d4a023197ec",
      "4f997ba6daf443fd8f44d03d80270a71",
      "a5bd3dc3a1c24882a483394b0e6e6623",
      "89ade900f4f641db9498e36a585bc222",
      "88d5a71e99624c6fb77dc8b2c30971b2",
      "5a5e0d11ea8b45aaade0232ab7dd7466",
      "33fb5afe207343aa943a5e213110e3ab",
      "a78b522cd1a346978d45a3272aa31105",
      "fa25ba6b887240019056d06fe6af528f",
      "1f63c6509c43490bb3202135864a8e3c",
      "173d639efda1404a8f1a7fb3ff76bfbc",
      "003b1fb6f0ad4868987b85d00fc929c6",
      "eb48fa82a83344f9bfb69b562ea3195c",
      "e9526a9ca57e4cbb932702e05432d8ea",
      "00a5295ff20745ed86fc075da71b7512",
      "8673a97205e54d168bde675ba64f1300",
      "8fbe66497bc94816b89bb2a2d113a5e0",
      "4ac58f4123744b8da2c847777b72471c",
      "bb3c2b3a8f8c48dc9670e448fbc6ed5a",
      "b7a498f8a111491c90a8d2b7c07bd4e2",
      "b179ca7893e44c6796aac292f0710eee",
      "56035c022cb24b4ab039f60e79323579",
      "5f12b8e68f444117b07c9303a49a1777",
      "a659be15145e41f18c80084e6623c75f",
      "8ad458f3fd8146d99acba731c9bc8591",
      "6f321d220d8b4457af67c283cd8bf58f"
     ]
    },
    "id": "WF4XfujwkGL0",
    "outputId": "e421833f-6870-420c-946e-01bdfdb040b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa11f1afcd02410282504fd92a6acdeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd092330a3484ba5acb859daed1906c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/3.90M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec20150db7f4412e9e0afe2ff3dd8bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/259k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ca52064db1d4f53a365fc8bafd8f941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2be3ffbada4974ac7278f1ae290023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a38a56bd585470b9abaf17f78a0e697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18fc89fadba944579cf52391bbfc7724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5879fdf59d42dda4b519df00381a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52a2ff00cbf451e96b8f3593d56a77d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Sizes: Train: 3103, Dev: 345, Test: 308\n",
      "Task 1 Labels: ['Ambivalent', 'Clear Non-Reply', 'Clear Reply']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22add8887b8e49f290e2da193c30332d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59fb1cdbbc8b4ed897b9c0e390de0ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fd98ea6792b421ab0e922a3666d6d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0c320e98cc478b9ba1dc39e5fb4c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3103 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70db24c555e24d808b71e815a2c2365d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce56931473240fa9306e6b792779303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c263d0062b9f4e16bb3dd1474e90158b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3103 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5fa9e422cd4c9da96b6ed7ddf62bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113277c299bb4f97af4b6a570eb9e0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d5a71e99624c6fb77dc8b2c30971b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/874M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8673a97205e54d168bde675ba64f1300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/874M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1552' max='2910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1552/2910 18:32 < 16:14, 1.39 it/s, Epoch 8/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.147692</td>\n",
       "      <td>0.576812</td>\n",
       "      <td>0.376133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.114032</td>\n",
       "      <td>0.536232</td>\n",
       "      <td>0.493122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.146000</td>\n",
       "      <td>0.999196</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.629563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.146000</td>\n",
       "      <td>0.940310</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.684450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.146000</td>\n",
       "      <td>1.046324</td>\n",
       "      <td>0.669565</td>\n",
       "      <td>0.649505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.870600</td>\n",
       "      <td>1.120988</td>\n",
       "      <td>0.649275</td>\n",
       "      <td>0.640127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.870600</td>\n",
       "      <td>1.230535</td>\n",
       "      <td>0.698551</td>\n",
       "      <td>0.649995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.640500</td>\n",
       "      <td>1.285336</td>\n",
       "      <td>0.669565</td>\n",
       "      <td>0.633248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final macro-F1: 0.6344\n",
      "Final accuracy: 0.6753\n",
      "Final loss: 0.9591\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets scikit-learn accelerate torch pandas\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    "    set_seed,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "SEED = 42\n",
    "MODEL_NAME = \"microsoft/deberta-v3-large\"\n",
    "OUTPUT_DIR = \"./deberta_task1_single\"\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 4\n",
    "GRAD_ACCUMULATION = 4\n",
    "LR = 8e-6\n",
    "EPOCHS = 15\n",
    "\n",
    "def set_deterministic(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_deterministic(SEED)\n",
    "set_seed(SEED)\n",
    "\n",
    "dataset = load_dataset(\"ailsntua/QEvasion\")\n",
    "\n",
    "def preprocess(example):\n",
    "    text = f\"Question: {example['question']} Answer: {example['interview_answer']}\"\n",
    "    return {\"text\": text, \"clarity_label\": example[\"clarity_label\"]}\n",
    "\n",
    "full_train = dataset[\"train\"].map(preprocess)\n",
    "held_out_test_ds = dataset[\"test\"].map(preprocess)\n",
    "full_train = full_train.class_encode_column(\"clarity_label\")\n",
    "held_out_test_ds = held_out_test_ds.class_encode_column(\"clarity_label\")\n",
    "\n",
    "split = full_train.train_test_split(\n",
    "    test_size=0.1,\n",
    "    seed=SEED,\n",
    "    stratify_by_column=\"clarity_label\",\n",
    ")\n",
    "train_ds = split[\"train\"]\n",
    "eval_ds = split[\"test\"]\n",
    "\n",
    "print(f\"Dataset Sizes: Train: {len(train_ds)}, Dev: {len(eval_ds)}, Test: {len(held_out_test_ds)}\")\n",
    "\n",
    "labels = train_ds.features[\"clarity_label\"].names\n",
    "label2id = {name: i for i, name in enumerate(labels)}\n",
    "id2label = {i: name for name, i in label2id.items()}\n",
    "print(f\"Task 1 Labels: {labels}\")\n",
    "\n",
    "y_train = train_ds[\"clarity_label\"]\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train,\n",
    ")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": (preds == labels).mean(),\n",
    "        \"macro_f1\": f1_score(labels, preds, average=\"macro\"),\n",
    "    }\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss_fct = nn.CrossEntropyLoss(\n",
    "            weight=class_weights_tensor,\n",
    "            label_smoothing=0.1,\n",
    "        )\n",
    "        loss = loss_fct(\n",
    "            logits.view(-1, model.config.num_labels),\n",
    "            labels.view(-1),\n",
    "        )\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "    )\n",
    "\n",
    "\n",
    "current_train_ds = train_ds.map(tokenize_fn, batched=True)\n",
    "current_eval_ds = eval_ds.map(tokenize_fn, batched=True)\n",
    "current_test_ds = held_out_test_ds.map(tokenize_fn, batched=True)\n",
    "current_train_ds = current_train_ds.map(lambda x: {\"labels\": x[\"clarity_label\"]})\n",
    "current_eval_ds = current_eval_ds.map(lambda x: {\"labels\": x[\"clarity_label\"]})\n",
    "current_test_ds = current_test_ds.map(lambda x: {\"labels\": x[\"clarity_label\"]})\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    learning_rate=LR,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE * 2,\n",
    "    gradient_accumulation_steps=GRAD_ACCUMULATION,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    weight_decay=0.05,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"macro_f1\",\n",
    "    greater_is_better=True,\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=current_train_ds,\n",
    "    eval_dataset=current_eval_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=4)],\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "test_results = trainer.evaluate(current_test_ds)\n",
    "\n",
    "print(\"Final macro-F1:\", round(test_results[\"eval_macro_f1\"], 4))\n",
    "print(\"Final accuracy:\", round(test_results[\"eval_accuracy\"], 4))\n",
    "print(\"Final loss:\", round(test_results[\"eval_loss\"], 4))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
