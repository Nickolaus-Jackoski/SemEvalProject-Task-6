{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "43aa225ef9e44c7fa8b617c11fa02051",
      "9b3d5c75c70f4296a646605ac29ca447",
      "c91bd8852be14ce5a9da8814baba2d74",
      "184682d5168d4448af0ba65f2fa7aff5",
      "5f46f23673664db69dade2778064f24f",
      "e4b18facd24e437999fdb7ab61e83c32",
      "3425453df45c499781c2cf32b838c1e6",
      "d9eb3c660af34fa6a7395105062d236f",
      "cfb58062ffd446fb8cb74307de452e91",
      "5e3047ca2d0c4ff1b59423161d729cd3",
      "62d6c2b2d88e459e9005906b61649641",
      "98b6b4deddbc4b61af6abac7f4e418f6",
      "3833bdc97cc84e0d9cef7df6dff21d07",
      "df9aa6b54e54442b9955d96fe03cf7dc",
      "2908ef55296d4b7ca0e1f9f73f3636f1",
      "ec283c00b7d6495580532a1440ab3558",
      "af3964d92de34fc89c72be9ccb3d0525",
      "831f27fc10df4b1ba980872388fed15e",
      "b2bd4a6d31eb420cafe09e7815baaf0c",
      "faf65c798ccf419b9da54954d3f5a5b5",
      "71ab5a200aa54cd2ba30d41dc6fcdf8f",
      "04e82ba068b747778390a43a3588a78d",
      "ff6b7709e0cc491dadfbbc579308620e",
      "ddb436bb283c4a56bc4ce4f73b8e7e6a",
      "bbd8b421023048fc8f864751fac48443",
      "e2afdb40361146a0809aafcf11fa8a3b",
      "0fab298fee4a4ee6b9cb6732259e5f9d",
      "7745cd79fd64493eaed4c4bd2a3ebaa0",
      "2e0cf98307454ce09c6bffdb1465ed31",
      "8079187f6b5b4aa88493785882b533a5",
      "2f282059563f4245bfc94b63aa343aaa",
      "08a5f7f334f94dd3b809f19ff1f23e72",
      "b0a0ffdaae2e4fb897cbdf9c28c092ab",
      "72f9e5df4c214367b084399226904144",
      "0b82821d75ae44d98bb5b84e4f2295ee",
      "64e597cc447d471cb241465e71c72639",
      "ba675315ae97474b96058fd16db61dca",
      "62269878a9e4489394f8dcea55644a9e",
      "92388b53ffe94c9eaac6f9a804048797",
      "45b28300ccb14b8da4a73866df50df4c",
      "1f2cfc8f44b04374b024b252a7d18d41",
      "9cea76c62f144e6484db9fc0f51abd13",
      "6f7f17a937194bacb7245c2e55ea9a91",
      "d9db2e2ca4924ef985a3cd2a8bfb310a",
      "2d921ed4b7144d54b5eaf20f866eec86",
      "efd7a35a9ddf427fa7a4c29b1bb547e8",
      "f1e90312c8704c07b96908caceca45b7",
      "e510261c52064dc2946c5e605aff46f3",
      "2e2c69208b6444d6837202250cc51f4d",
      "88fea79b299c4fbb9c482523326f79a5",
      "a35bf25380b3407a84c14e34b7fd8391",
      "d9f2c8727a424cd3a4a29d829350c0ce",
      "c3b85b2300c3434884f098b52568ae78",
      "487edea7846e4b5b8bc15607a5fbb7af",
      "9d768859b09941688034c04a019866a7",
      "2e8afb7c16224b63b851f22a0f6ece9b",
      "fba2e93614e1498991b5824a38e0d00f",
      "bd09a9950db54b75b68d41baabc025ae",
      "d696da4d9f0b4854bb4b247a7b3535b2",
      "35d67ee487bc456fa5fedfc65737aa6c",
      "d6768a251fa540589d52a9ba7202027a",
      "9317cb4aa5f74d40b722e755d366d7f3",
      "7e32f0b4513b41d381a6cbfbd80b698b",
      "f135af65bb43440293daeaeda3239913",
      "737b69d30a24486ca3641f44360f89f9",
      "33fe30358e064d8b8dd7bbad31745e08",
      "9a9a42348a37493c877f7685a6aff160",
      "cea7dd788fc94de8a60f4838866a5b23",
      "d66cd97bbd4b4974854934b3258bb278",
      "9b824da8a6f84720ba666a078c5157d5",
      "1d1cd822451e4f91b96f94ca564184bd",
      "cf3f85dc2b6147caa66d40477581fabd",
      "ac837a0b2a594f3c9cf0ccf62e03af7f",
      "08eb097ef9e04c9ba1666d6016b96cb6",
      "859fce347b9847aeaddfb523688eeb58",
      "1db767d1071f4a849993132b88716e28",
      "50a9b4226b1246f3811422981e40a93b",
      "da66a0a1107f40f3ba250e4913ad8237",
      "2a30eb99bed84d7da01a8f960596c453",
      "fb97fd8e38ec4fa69e55abdd2545ecb6",
      "be9ba5f2ab8541c29d57449b9c47e5d5",
      "b5c1fd05f3af4588a43d6f58bbffc185",
      "773d0b8eb9ff429784aaa03e47b8cf70",
      "e7c982497efd4e979562e3c40398abbf",
      "c58c8215387a45ffb1da95775c20a8ce",
      "557bc86bde9847648420dd4aeaf3796f",
      "2cbe509735a34a6b9b3b4bb7564e2638",
      "3dd67c3ab1dc462bb52753e424bc1ed4",
      "1760d307654f4117b01e5b66740590a9",
      "f42651d87b9448c6bb7c554e8849ebce",
      "99c83b115af4454eb52b2157592a7967",
      "42460e6222c343359fff3a1218b0d229",
      "34622bb48830456b9369cebde9540119",
      "ff747eb7fddc450fbf6f2254637216ff",
      "f25580fafec14c59b37e8d34da7f662a",
      "796817f7ec864353965f9d10269c2d76",
      "669eff4aad2048ff8b85bb13433ae1d0",
      "9bc0f879a3cd41bb8e0895b56f9bf94d",
      "d5c267bacc224ba2b5ac85528afbf858",
      "2c1e2b88a39a4b849fd59f1d63e07795",
      "828a99fffe1c4cb8ae3340d51490b26a",
      "cfbdd98e0b564bc19465e3362c4999da",
      "0abd612310a74b1caca369cb79566c0d",
      "a16064964ace470e89c5d01b31555b3f",
      "5434ad1216b24db996fe12c35adebb05",
      "021bfe3302a646c0bcf32ade09a5b18e",
      "131603e4ecd344c5a5d1e6d19d154356",
      "3dd96a72781042f2bdcda14fec983e6b",
      "1f9bf990e0e84e27ba2cd20159f7ae3c",
      "7aff24f7c2cf432484ebe4e634f092c2",
      "cef6fcbc64014c11aff54a90b57c0c95",
      "fe1c6cf9c1774b77b64f80a21bc5ece3",
      "9ba3079fbc4d4f46bdb02b03e05abffa",
      "f5abb11ea97f437ba978dd0680568586",
      "cb2ca3abd4624c7599c4b676362670ca",
      "d3478a265a774c7abfeec46e28371aed",
      "b356a9c8114741e981ebc353b17234ad",
      "517e0db37a79434d8da79bb383e391e4",
      "57293aa8bd2c4f7c90389bb1b32e0e70",
      "c550877323d2481fb2192999e69f1a66",
      "7e7ee65eff5645f89adbaabf5369a942",
      "080c4f74303d448ea8519e6e145d28dd",
      "421b0bb4e37346888c4d342e6b1b009a",
      "21032a76c09a4a498ee14ed305f9603b",
      "483ab1e101b144a0bfacc57dd5e5f975",
      "7e7685e3ddb44f60b0c2cd5e1601657e",
      "e44c4d0df5b44c318f5a54f21e3001bd",
      "c3297f58537f489daca7567a24646f10",
      "733187b47e534a009ab8a6f59011ac58",
      "e05c7f2c45c04070afdb792fb9c83aca",
      "5dbd19fafbbd4cb9b5308795a9e39ccf",
      "47d3044a302547bf9ef8b976877a40d0",
      "13702f4b03af4a4690c2fa6a603de87b",
      "f06536e1f94c4f9ca276cf6181483cf8",
      "a496dc22262d4239b6fd8eca7fd75ba0",
      "51999514cfec46c7baf173fe13c81cf0",
      "7416690f245d4740ac05aba58ac946b5",
      "90be7f33cbe04178a9c71bdaeda1b544",
      "e4bf70c594984c5fb40003ed933cad94",
      "b2ec1f605d8144c4821a145073c0a8cf",
      "f9a5295bad2b47c2ba4df5059638c9a3",
      "057faaba2ed8451ebc09ef0069992c6c",
      "c279bc2e396d4399a0d31a1d535f1c9c",
      "24f66c47e82a446294fbee3fb4b88d9b",
      "3746fabd9c184dc88509464bc67cebdc",
      "7116ffe7b7cb470a8aba03fb88030ca7",
      "97b6eca314904b9cb30c4e722f08e62d",
      "8032b30ff77c4f048abf25227e9d09f8",
      "e2ae98ebd56948a38d37b6bd82e4ff89",
      "896d24c81bce43a9838a4692a6a2cadc",
      "f2a7a1bd77ff47279098bd168b227da9",
      "d8e3e52e26fe4a968e2bdb817afdef0c",
      "2b56c1f36058406497bd2f26fa92142b",
      "281b8f9eac9048dcb88ad1e2736087c7",
      "af0002fa7d614f5b8736080adb60a432",
      "b9f3b50c3cfd4b11ac39f01ffa189e07",
      "3526ce8e95694c91be8c104d292e2d50",
      "aea724517f7048c29a3b5ba9c2719a37",
      "61ae1cf76a524a199ac96a4f059a9b45",
      "7d18565df370455a9f613022a3eba43d",
      "34e554521ebe41c69c0b96538b9cf79a",
      "80d2f1e3d7ad4727ae0ce2092245c89a",
      "8f22cb4a44d7491b86f74b920d422094",
      "6f5d811a192546dd802f3c136542e810",
      "a94834d03ac74a7bb7efae4c9a50e265",
      "4cbbf8eaa7ab4e08a99a53e50a8dad58",
      "5135545f2fb049cdb4966eea7823f3e6",
      "fa914b62af4c48bfb96f32faf2004a19",
      "1490fbe84cfa46f8a35b9c7fb463ca2a",
      "5aa7511b31bd4eecbc13d027b6d74259",
      "ef3586c8b83b4358a8e10dfea314e516",
      "f03e3d8108c1441b87784148c95c4347",
      "a8045d14e0af4c36bca131a08adedee5",
      "cf683ca199e64a14b12d7a980dff4ea8",
      "2576a6e92ee14fc9bde1553eb9a2f56f",
      "10ae8934d92844a5a5e9907aa1749040"
     ]
    },
    "id": "fFU-N6x4Ltzn",
    "outputId": "255b4f79-4511-400a-ad5e-e834e6fd17d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43aa225ef9e44c7fa8b617c11fa02051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b6b4deddbc4b61af6abac7f4e418f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/3.90M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff6b7709e0cc491dadfbbc579308620e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/259k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f9e5df4c214367b084399226904144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d921ed4b7144d54b5eaf20f866eec86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8afb7c16224b63b851f22a0f6ece9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9a42348a37493c877f7685a6aff160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da66a0a1107f40f3ba250e4913ad8237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1760d307654f4117b01e5b66740590a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1e2b88a39a4b849fd59f1d63e07795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef6fcbc64014c11aff54a90b57c0c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080c4f74303d448ea8519e6e145d28dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13702f4b03af4a4690c2fa6a603de87b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f66c47e82a446294fbee3fb4b88d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " training for seed: 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0002fa7d614f5b8736080adb60a432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/874M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cbbf8eaa7ab4e08a99a53e50a8dad58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/874M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2808' max='2808' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2808/2808 28:42, Epoch 13/13]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.140800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.748400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.566700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.307500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.153000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " training for seed: 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2808' max='2808' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2808/2808 28:59, Epoch 13/13]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.102800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.753500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.502300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.265400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.121800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " training for seed: 777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2808' max='2808' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2808/2808 28:56, Epoch 13/13]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.098400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.717900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.468300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.224200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.112300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_537ec739-639d-40a3-9719-b19996257b97\", \"submission_ensemble.csv\", 4105)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install -q transformers datasets scikit-learn accelerate torch pandas\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from google.colab import files\n",
    "\n",
    "\n",
    "SEEDS = [42, 77, 777]\n",
    "MODEL_NAME = \"microsoft/deberta-v3-large\"\n",
    "OUTPUT_DIR_BASE = \"./deberta_v3_ensemble\"\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 4\n",
    "GRAD_ACCUMULATION = 4\n",
    "LR = 8e-6\n",
    "EPOCHS = 13\n",
    "\n",
    "\n",
    "def set_all_seeds(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    set_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "set_all_seeds(42)\n",
    "\n",
    "dataset = load_dataset(\"ailsntua/QEvasion\")\n",
    "\n",
    "def preprocess_text(example):\n",
    "    clarity = example.get(\"clarity_label\", \"Unknown\")\n",
    "    if clarity is None:\n",
    "        clarity = \"Unknown\"\n",
    "    text = f\"Context: {clarity} | Question: {example['question']} Answer: {example['interview_answer']}\"\n",
    "    return {\"text\": text, \"evasion_label\": example.get(\"evasion_label\", -1)}\n",
    "\n",
    "train_ds = dataset[\"train\"].map(preprocess_text)\n",
    "\n",
    "if \"test\" in dataset:\n",
    "    test_ds = dataset[\"test\"].map(preprocess_text)\n",
    "else:\n",
    "    raise ValueError(\"Test set not found in QEvasion dataset!\")\n",
    "\n",
    "\n",
    "# encode labels on training set\n",
    "train_ds = train_ds.class_encode_column(\"evasion_label\")\n",
    "labels = train_ds.features[\"evasion_label\"].names\n",
    "label2id = {l: i for i, l in enumerate(labels)}\n",
    "id2label = {i: l for l, i in label2id.items()}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "    )\n",
    "\n",
    "train_ds = train_ds.map(tokenize_fn, batched=True)\n",
    "test_ds = test_ds.map(tokenize_fn, batched=True)\n",
    "\n",
    "# set labels\n",
    "train_ds = train_ds.map(lambda x: {\"labels\": x[\"evasion_label\"]})\n",
    "\n",
    "# class weights\n",
    "y_train = train_ds[\"evasion_label\"]\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train,\n",
    ")\n",
    "class_weights_tensor = torch.tensor(\n",
    "    class_weights,\n",
    "    dtype=torch.float,\n",
    ").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class ProTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\", None)\n",
    "        if logits is None:\n",
    "            logits = outputs[0]\n",
    "\n",
    "        loss_fct = nn.CrossEntropyLoss(\n",
    "            weight=class_weights_tensor,\n",
    "            label_smoothing=0.1,\n",
    "        )\n",
    "        loss = loss_fct(\n",
    "            logits.view(-1, model.config.num_labels),\n",
    "            labels.view(-1),\n",
    "        )\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "all_test_logits = []\n",
    "\n",
    "for seed in SEEDS:\n",
    "    print(f\"\\n training for seed: {seed}\")\n",
    "    set_all_seeds(seed)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=len(labels),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"{OUTPUT_DIR_BASE}_seed{seed}\",\n",
    "        learning_rate=LR,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        gradient_accumulation_steps=GRAD_ACCUMULATION,\n",
    "        num_train_epochs=EPOCHS,\n",
    "\n",
    "        weight_decay=0.05,\n",
    "        warmup_ratio=0.1,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        eval_strategy=\"no\",  # training on all data\n",
    "        save_strategy=\"no\",\n",
    "        load_best_model_at_end=False,\n",
    "\n",
    "        fp16=True,\n",
    "        report_to=\"none\",\n",
    "        seed=seed,\n",
    "        overwrite_output_dir=True,\n",
    "    )\n",
    "\n",
    "    trainer = ProTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    test_preds = trainer.predict(test_ds)\n",
    "    all_test_logits.append(test_preds.predictions)\n",
    "\n",
    "\n",
    "all_test_logits = np.stack(all_test_logits, axis=0)\n",
    "mean_logits = all_test_logits.mean(axis=0)\n",
    "\n",
    "pred_ids = np.argmax(mean_logits, axis=-1)\n",
    "pred_labels = [id2label[p] for p in pred_ids]\n",
    "\n",
    "if \"index\" not in test_ds.column_names:\n",
    "    test_ds = test_ds.add_column(\"index\", range(len(test_ds)))\n",
    "\n",
    "out_df = pd.DataFrame(\n",
    "    {\n",
    "        \"index\": test_ds[\"index\"],\n",
    "        \"evasion_label\": pred_labels,\n",
    "    }\n",
    ")\n",
    "\n",
    "out_df.to_csv(\"submission_ensemble.csv\", index=False)\n",
    "files.download(\"submission_ensemble.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0wXA_AZiLw9s"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
