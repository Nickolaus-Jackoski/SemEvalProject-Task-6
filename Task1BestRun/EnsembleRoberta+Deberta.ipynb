{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "fd799a24dea641b881582c369992d1be",
      "1de8ca7bb9d341fdb95f1ff0dbb69a1b",
      "870a79628f4640dea452a8f0e229ed59",
      "23773193cd7b4cc1800014207191acd8",
      "7140e705dc314a98bacf78f0e12fdddf",
      "d8c491f4a33c421b9053eb9f57abb763",
      "7d4ac260dafb46e38c0f9677c38a4684",
      "bc450a2a99a04a9d8ea5e07ab08ca31d",
      "31c830b0d29645b59d499d1a6880b346",
      "5936064e480a4a3194aaedf154e773ed",
      "1623484fdde5422c8b7a4af049ff1c30",
      "ea5291ab2a1d42d5ab20f82654778e93",
      "3863116d6b1c4d1f902ebfe3fd1d40ee",
      "1bfd3eee9d7f479586f14bebfd7b9120",
      "959fc4bb39a240bc91a303c8dfe16916",
      "88fa5808276145b3a33bb4e842c9c384",
      "430b27beaa8042c59cd51a78638ce210",
      "f2715171d60045d2ad2fe13650518175",
      "d41f1cb61f0a4e7bbf2ea6b17798548a",
      "5e16c0e39ab44f4095571da4f6a6bfb1",
      "195968e1dc6b4452b17ba90e61ad9124",
      "656a42a300ff40eea7215f2bfa959b37",
      "253c03753c334b2285c301c0998f740e",
      "8956c0c188ce4d159d2c7ceb76148b26",
      "fefb219a65ef4b8d85b198293d8f4100",
      "a9b6aaaac8614c1cbc92b621893170a8",
      "a5828a8bb64f48e8b78901d5d331c72c",
      "6c9e4ccea31443428aafa94e480edcad",
      "4e8213b3b58f4968a9bac726bcbda18d",
      "873acdfa8e734e4db0eef60df4ac1718",
      "fdc423f9f13d4b528ca9ae90f5795863",
      "dbae6c040c6c41ffabbaf1b289b83c5d",
      "5ff03fa4ad4a4474ba3aef43344480b3",
      "4f29cbacf3cd4944b9f1cf9be760f3f9",
      "29db76f503cc45b3868de569120a0d76",
      "0bba1de4a7164ec8aea8910b96ef4ca8",
      "46002255ab7145fb8336430007105a51",
      "cb491f63217a4221b70bc9e6ab711144",
      "e7cd3992932b41d99365f634b192d6b3",
      "fcadab4fde3e4795a55494c50ff0b48e",
      "b741b83dbf4a4b38967db0ea3da31542",
      "88a27e5e86114b3fa18cb16cf35b3b6a",
      "1eacadebb732481099f7b65aca3425b1",
      "9dc6fbde368a467b82eb6dbb84449d2b",
      "25368194ffd3401bb5c57a76b56e3f73",
      "28c7a11524ac4b19b1e637f21d73f958",
      "8b6219b6e2224b99955a259579899df8",
      "51988b3d766944bf9f826628fede1faf",
      "45fc0446d63941119fe9316b5dd755a8",
      "c4e0eba1ce3f43d196bb365c4fc350fc",
      "68b15fbc87bd446fb240ed951b3d65ce",
      "2f8151bac8bc411aab9c21e29bdb40ef",
      "e0b06758868f4435abaa560a7e21d6fc",
      "53994fbed5314ab696a99db4001977c6",
      "47ba0e9d6bde4337bfd8b9966e49da4f",
      "956d09b1a882490ab6894b3478d9870f",
      "1197e7fa3b4e494dbd05c581d5ca3cc4",
      "d13e06a56a804fe59049f3f90d63c5b4",
      "3d5a4809c8464236a83bf85312fcfc78",
      "5bc144ea7240415d8c49275e1a311ad7",
      "4ebc5b86b28f4e0cb5e0ea6de86d64e6",
      "79d0df2dcd3d495cb87a90009d0f6098",
      "fa45978c961b4d15beac56dae8953a16",
      "88cdc08e84a145878adc455ce378ff77",
      "f840e66525a84ae5a753345a2fe4fc63",
      "554c67b0d66645a2866121684101b868",
      "e4d60ca086af4ac19abbe31ee7962d7d",
      "58e57e2ad6cb43a2a8a9284968a97da0",
      "e19c158d98d9400a984db6019f804b5c",
      "493badbf390e4e22af8a8445f8eeedf3",
      "997134c343c84fcfa03c6ce7af3b5801",
      "be0083c88d2a4d08b46d1102ec586a75",
      "f482c5f7e74f4dfd92a90b8bcdf5a751",
      "8d66cf1d1eca4085ae7743bf5bb3c406",
      "c8696dda8abf4197ab9cbbbf4a746027",
      "c65c3dbc8cfe43328847546e42844412",
      "20d1b16120ee41faa761f272142de2f3",
      "90a80e8d53f94ba68199830805dfad7b",
      "7b0b798edecd448098e44b502f657d17",
      "c79d67f9817d45d9bb79eb6b0b01c1f8",
      "3f849ab1c9454360b7d49807849dbb77",
      "1c1559dc76624f18a1af3e77e190e5f1",
      "a453f218361544489e23fd1ee7e620eb",
      "1a3facedd46e415ca9bb6d27165d084f",
      "a432f373801c4e2bbe13f31f0535bfda",
      "53f3b209157841d980b62ec2adbbf540",
      "1f3d1b4c88c24d3d88fba66c211a57c1",
      "42ab35c241fe430bbedbcf6b54b519bd",
      "ab608c61d57d423592e6f2e1a440d9e1",
      "cfb7e321c89c4e0491279f7da6db60ff",
      "6722fbdb3adf41d7a475d75dd38b975a",
      "5c8bcc960b5140719c167eaecdf1f9fc",
      "94319ebd8db84dfc9397dc1217a70d4c",
      "aead94987ab240a99bb5c010395cc8cb",
      "b8996b07ca90493d947f566c928afda5",
      "e473086869064ef5a25ec65d325a496d",
      "3e46db4dc16341e1b1e72f3047cf5540",
      "908d73c96adb44b898dfbeadf13483b7",
      "59f98a0f774f4e7eb7d1584f0a369b43",
      "616bc6fe1ee34105a912eb535b6b2bc4",
      "4ea2136682864dfbad410f69cf7da699",
      "0dfc905feb8f419c91d403d03988390e",
      "767f9f8d4d214e52b4ac06d4509ccd8b",
      "8a85bf2e6083404cbb9fc3ff00ba8e1b",
      "eacb0855822341f0a256b9a661c8fff0",
      "11a56d5f1ba44c8d86e964f642a6375e",
      "95635a7a20684ff9a068115780b63554",
      "2b71eabbc6724b8782d1ed3acc450001",
      "936877cec84f4c05844a0072d5b9bba5",
      "3a3eaca853d04c45b5ed92af91ca845e",
      "95db3ae057d545808db9db777e82a3c3",
      "8047eb6f94b04d559346ea9ade33c003",
      "d92161c9ec5343df9e4ab3e049f8adb4",
      "39fbd58d46f549858798f8686440e214",
      "6802aefbf22548f2bb1e9c4fb883cca0",
      "0e1fb3b71d96431ba479dc94f02d0492",
      "e84bc137db354eca8046dbdf1800ef7d",
      "4ae3bfe0f2d5400d83699e6138b125da",
      "9b57342fe0964a088f81d46d62c27d15",
      "c5c837698d394fe2bb117b9d91589b5e",
      "c522867e48cd417c8322215fc9ac0181",
      "4840c2ca01af4a0b99451e05e8a904a2",
      "5cc0097bdc3f4aa98524b337e35f1c56",
      "cb4036bfe533448a87693ae5e85f7058",
      "4d364d4f2cdd4137bd29231f38a18a40",
      "eecc817d64384a29a498122950e196cd",
      "2dd8569e1abb4e5bbb857d88fd262519",
      "6b0471ce249c4a5c878ce6236abec5c1",
      "690fa040da90422aaa48c68261a5adbc",
      "08586e3d3b7f41829eb5f58133ad28e2",
      "33e9037b602d47b0ab7aa0a146edca09",
      "c221d7e058ef4b11b4ff35b267918832",
      "59cfbe04a52d4bb6a4fb3bea940f540b",
      "e05ab3d3b4114fbcb183be91ee4e5ae7",
      "96b788871ef5496aa71a48729ede327f",
      "a63bf3a6821d47b880ec9be6b9d42a8f",
      "8818aad26e604b2abc39bd49efdf5f79",
      "abe174d51f554dc385fea6f93a319c1a",
      "f6f4d46fc48f4b82982b57508ebbf9ee",
      "e882b9b4e7714af68cebc5e0037471b9",
      "1bb4359c0923442e80ea4a1c1adf7c45",
      "1832b1692e934c219f9beb652dc851b1",
      "af61683b06584ad1ad97b31f831530bd",
      "4dd5aabd74674fbaafda07a3dedd201a",
      "0bda350f02dc4575816b88787a3a67bc",
      "434863dd16054529b40106f8eb1fd39c",
      "0d4600bce51d46d8af5bb24e45158279",
      "06e1f4a7f77642eb92ab7e0fd4ad9be3",
      "5ad1c5507e694e189a8408dedbef9557",
      "e17fa9e8a3bf469c92a82c313d0394b7",
      "8313d6b382ef4ede8ca8a9bfd9370719",
      "4d1e6b46daf74734be23aa258d822bc1",
      "bcb9e81edd41455a82ac7be0e90d5a6d",
      "2536238e7d164f5988b81fc4696e6522",
      "ff1e06c126b945e6896acb1e72ced6db",
      "724d9e5360d44b67a15b4d322f3485f0",
      "cc1b9b88ff194ce883f124e5b7568fc1",
      "592ffbde2c214d8b97e95f1b70e2cb8f",
      "52d3a0630e954c938ecb1cd4c4d637dd",
      "80904556453448ef8f07e95ecc47f8ca",
      "30695a820fb94e4eb1bb25c5b6441808",
      "e4217e41a9ed4d6c946df688622eb238",
      "197399f23a9e4f2087c977ac85be30b2",
      "223b0d2cac884daea7f1d984c8c6c575",
      "dcacfad0543f4efaa74e675691cd7e1d",
      "2d6415b3c45f49f894ce886075c0673a",
      "33e8a9732c774196bf49ac38c6a456ff",
      "ef3ab488f8b149e4844f778eeff17b8e",
      "1aa86f01f75e43a38c9ca6b9123725a7",
      "dbd5ea8e5b7c4c548f5bbcd5cf75bca3",
      "72287a90ccad4c009e21119960473570",
      "713cef4089d9406398feb6a8afe57bb1",
      "a6f92503d97d4363b3b23cfcafdf1e42",
      "dfa8093223cf4853bc1da6b33477d34f",
      "fbd842e5e18a40cbb4d624668c725740",
      "7bb5209a73c14fa69dde74beb68e5b4e",
      "93017503a1b745829016e0e895dd65fe",
      "9b489e87ae4244909106a5e2c0eb4fc3",
      "a0554dd270474d9784d85b6805f925ec",
      "47b08566410a4da3b769be30ea30a6fe",
      "f1cbbd6801ba442c98a985203ed6c7f4",
      "195672ae93d84f49811fc9570a1371cf",
      "c1893ced461c4a2692f121cfed8c1a4a",
      "f4a62d927c674f42b7f1bb00cea943a3",
      "5d25e98452224ccdb92554dbf6541b3f",
      "d1516504369b4dff86c501c10923019a",
      "00e125436a574bf5a10666fe78fdda3f",
      "f6aec5c92e524113ac7796a3b35b0c54",
      "e5e68dcdc2bb40b4b9a5a73d6173f290",
      "dd89969cbc044a19bf02c36c8dca3853",
      "b2738380c6b94be7bab3c9f67c460b62",
      "8239508574634b28b8611a6b4ab7737d",
      "2d983fc243004b3ca95e5e9375f579e0",
      "2cd99c63256f439ead4e74e288c4a42e",
      "7fdccfbdbd82438c8122de32a29da65c",
      "6df07abd3ce74d598fb6fd06238f8756",
      "9defd4bd18ab4148838bd6864ebd66df",
      "5aec52983f934be188213e568383dfe9",
      "d2e6edf8a51c49e4af4ab8607146a249",
      "b1c6f335fb0442609b33baf8a2a8e9a0",
      "9ecb6af34bb1408184d2d8573ea7abc1",
      "ff5d58215d7249fd9bcf647629cd80fb",
      "4d431d8809b04daf87ae292d603d16c6",
      "ee021a8d285f40639bae3a1ca7f9b380",
      "e6b35635472f46e68dd5e82300b637a7",
      "92571576fc204845b288b8d1c7720324",
      "222653117c444105bcac6d79bc52cfe8",
      "b79f16fea9144870bf5d93d4a5fa7c09",
      "dfbd67dedb6a48958a2345e89d744b59",
      "4d1954be543f42bb83f69001a33c0ef2",
      "3872274cce104bfe97345dc42a269fcc",
      "2956530bab8e442684b2b1d36b09dbf5",
      "39ba8a3691d54c988cbeed8bc3265c41",
      "1f427df892924cf89e208fb55c24e8c3",
      "d2b53518739b4225931dba2b062442bc",
      "e596637720bb499bb0a6743bd1a86045",
      "8bd19049169f4ac09a6bc098755c5405",
      "2329539e11094be6a54489d9cdf986a4",
      "2928e45b16464ce19d2b689c5a9d04bb",
      "d694424a34b84673abcbe6e3dd1868f3",
      "4f99a1fda0b647f8880c56ecfae0d78c",
      "8066506087f44361bc8c8986c23e0585",
      "ada63ee20bd94f0ba9d3afd29f90dc13",
      "0eddcacb062744dfbad95ce2566885e6",
      "113f1bf8de8341979ef17c1b2e9d131d",
      "aa7b2f0c58a448d2b7ff676599973be4",
      "b0c0f48ae4254e948a45225ab67a88fc",
      "a3231c3b132e46578a179e4e9c2064d2",
      "4cb807e1df764182b96b13b1a0d91706",
      "d41b7d9277484ba085ae1565ea3f331a",
      "eb9ff94515f24623bf7180b1cef4c04b",
      "21f0bc15de23420d9adeafd9e5f1545e",
      "80ac4d88904f480d92ee91f3bf83c2c1",
      "b928cd5770254fb892ace1c8064a29a7",
      "cb8db7ad124345c7babda76f0960d899",
      "64c3d4613c0144e58d6814b34ef0f19c",
      "fb6eaa2a6ba84829a7f5b6bb31c5716d",
      "0f853d99360e4baf941884922ac57d35",
      "e7c9605c83914499afc8ad055cbd9cee",
      "a0efb8827a184e76ace7debd2c2855f8",
      "4d70d4f4445d44f5ac20d1aad906df09",
      "00f67f1efe1b450cb970510f25a92263",
      "4e55af3100d8435e8a77eced55d6c373",
      "54ace1a02d9b4a69981f5b381ee5f68f",
      "03bc685941554385a2c9f553ced1341c",
      "0f0cd28fb7be41f8bd54265377824796",
      "09fba55b8d4949bda1c6383f4d3cccd5",
      "f4203f7e9a1e4ebd9ed7794b4d8da4a8",
      "ffcd685eb0f84441991263aeaf606e81",
      "85d60201c37046dbb43db29d68bb28a6",
      "f4747f23136d49d0b2c62909a79fd9e5",
      "bb2cd4f6cf1c4eefa527f56ee59011ca",
      "f8a47ab8a0e64843bad94dc9af07b242",
      "30f73ffa4f5e418196a34729c5d1f14b",
      "281b896c83c449429cc1dfc7254f6c07",
      "1924727054024a0f9ce9b22b3ad50c41",
      "e7ccbaed015049e5b3051c761c66a861",
      "d1ac2af337514c3fbe5cf2f639f52ac6",
      "57e5a130d51248b8825f39063c496c8b",
      "9ee3f43956d34c298eb4e8b4fef57efe",
      "21b70df1f0b74362a261e4d579f1cc90",
      "82adebc8c2a44fa8ac44f3285be2d55e",
      "845fd794fea4400996b93050595e9822",
      "f5b8ba1c95414864a0741739ca6d0d51",
      "6e39192d19224ee9ac7dddd657d79f07",
      "2bc2e680e1c24433a7b6d208be26ce6c",
      "af25ca4c903c40258bce2174cd2640a7",
      "f487ed6c371a49f6b7b5d5da1257889e",
      "90166d3df1034ebb87748d754f66a70d",
      "307b1107575945d4b37537617fa64be9",
      "81a01002f5044dcb8db3f61f81508bfa",
      "465dd34dd4674366bb65be0c5ab158a5",
      "5a24a2e0a7f84b70bf41c5410341f2f3",
      "2f3564b0a19044fca2f4842f6f524fc4",
      "a3fe8e857d654f4287cbd4dec6de0b0a",
      "1651cb11ba9e4d248ceb56b34c803acb",
      "2fd3944d1b6e40c7aa2af65c9adef15a",
      "475df3b0b51f4344a885411fc413c1e6",
      "430a8aa3c6174a3cbd9f99a4056fe606",
      "7855ff45bd5f4d449a357308bc6b35b6",
      "ba4846cc4b5843f2845717e48978484d",
      "d273f54f9ba1464ea48a40a2318f3cda",
      "d0cda5e35e824f5f9bf009d672d5db3e",
      "5108ea15dc8643a7bd5764c3780d256c",
      "6accb8b3029047bc92f5878f9d2f7a99",
      "323231ff6cee4e0e923211165d45a0e2",
      "76fa3c91a9b045a39cc84f3e5802eebf",
      "63d0e16e012c4508b44eaff444d29d8e",
      "6803621c019a4e78a8034a01a03ab9e1",
      "dc3ad8c0600149eabc03631326fe32ec",
      "d21e90fbd166426990d50af58714dc28",
      "1c399eedffb243b8b08798a0bd4889c9",
      "cee9970082d945648f0ad65eb90c9786",
      "3895a798369e4732b59210e983a8e6d1",
      "559b70bd857049399997dd9d433ffc4f",
      "259987169c944f849cf9d332e173dc02",
      "f421b8f950374cd69f1b7aa130c4d4c7",
      "57e9a6aeb4ce4dc0b8bd961fe4a0b009",
      "bad497c7d5a74579aa19d8fe5c82b5e4",
      "2430a75ec1544c0ab9aee9c855bdb0b2",
      "91bedce2412f464ca53f3e0f70e8a25a",
      "e20c16e2519746abab807ede040f3776",
      "2f75fb057f4343bd987933050f3996eb",
      "6a9ca626dfc14c2192e1922ee6758810",
      "c2ea32b0e9934ee9bff5b33191b26b5e",
      "ebf8ad3fbea349ecb2d375e2683e266b",
      "546d2b7a9c5c406583d9612bd30b4293",
      "8dbba20cc74f49b397bb3f679a0a4a6c",
      "f357d743f27c4a009fd1d60faee8c899",
      "7cdcf13173964fb783a9010f9b9b659a",
      "526d44a21ec6403b8b59aaa0276fa0f5",
      "f2f929238bbf441caecc3aa2a5dd4318",
      "2ff48e7c5ee7492980380d5d47bcc29b",
      "30206f5a90a24ae484dd720644f93115",
      "3e1863a482dd49ff86c64ec8992cbc15",
      "eb539805fc844f8ab048289d053f14e8",
      "7561f9fcf3874da09da1ad4cf7cfb96c",
      "7f67001370224f428c56e8b8c54dad54",
      "c5d4d9aba074450e97c6222f11f00f79",
      "870b5e22a8454d5dbfd15611ceffa58d",
      "bf06ab39f1f54e3ca02047939af8486a",
      "066b312d633044f1b8e3177d36170ff8",
      "441fba4e8a2545cab6e7a4fbb5270b4c",
      "a321a938f73243b6af0ae3acfe786209",
      "be7d1393b2484281aca18f2e9eae2793",
      "bcd3b73ae0b443a8bda8339193ef26d6",
      "e560347c72b9492689de4b64050d9508",
      "e2df239de850438ca1d8347ff4afb9cd",
      "d127553d381141aeb03b54a6f06196d9",
      "8702698deda64fb394d6d9fc6bd3c98b",
      "68928c0952d04998a0041617902902a6",
      "2add03ff83c341b09b877c26133b4e5f",
      "8a012ffad0fa4ebba6c77a7ebbb1c7f2",
      "4e357a61687b45e4964e6e9979ae0752",
      "14fe551d72394d77b6e64c1496449024",
      "7d7b94ce50f84187a47bc1831727080c",
      "25ddaf5f54f243c2b5c8da0fba8ac55f",
      "6ee15df24abc41778bd4dc7708902343",
      "40b3db3708764ae3843386d84d687c12",
      "d14c76eb72644b46abebb53788275a65",
      "423cb7b1acd945909d500369a7334733",
      "3fc24d9c63884115a08e3a40dcc89652",
      "71ce11719d4544cf9fcb04c7f4302f07",
      "ffbab440f8164fa9bb3ec5155aef770d",
      "9f33b34efaa24460a8b7c302a83deba3",
      "c4deacaeac5840598fbaceae4ca98dfc",
      "43e573d10d8a4a9d8f124bde38b4cab1",
      "e922777c8cbc4a0abe6d4c00e6f17ea1",
      "c337e0f472f74920abb40cc046ed5e4c",
      "f24bd353d9db42f2bb389cc3fb781d36",
      "b99eb6b9b4894077a40cddcd7351f49c",
      "234b8f6fb30d42a38042801a630f1691"
     ]
    },
    "id": "GlGOtQat1Dgc",
    "outputId": "be8b643c-f45f-46b5-b7c7-f6732ee17281"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd799a24dea641b881582c369992d1be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea5291ab2a1d42d5ab20f82654778e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/3.90M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253c03753c334b2285c301c0998f740e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/259k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f29cbacf3cd4944b9f1cf9be760f3f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25368194ffd3401bb5c57a76b56e3f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "956d09b1a882490ab6894b3478d9870f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d60ca086af4ac19abbe31ee7962d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a80e8d53f94ba68199830805dfad7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab608c61d57d423592e6f2e1a440d9e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Sizes: Train: 3103, Dev: 345, Test: 308\n",
      "Task 1 Labels: ['Ambivalent', 'Clear Non-Reply', 'Clear Reply']\n",
      "Class weights: [0.56336238 3.23229167 1.09222105]\n",
      "\n",
      "==== Training roberta-large on Task 1 (clarity) ====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616bc6fe1ee34105a912eb535b6b2bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95db3ae057d545808db9db777e82a3c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4840c2ca01af4a0b99451e05e8a904a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59cfbe04a52d4bb6a4fb3bea940f540b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd5aabd74674fbaafda07a3dedd201a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1e06c126b945e6896acb1e72ced6db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3103 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d6415b3c45f49f894ce886075c0673a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93017503a1b745829016e0e895dd65fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6aec5c92e524113ac7796a3b35b0c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3103 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e6edf8a51c49e4af4ab8607146a249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1954be543f42bb83f69001a33c0ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f99a1fda0b647f8880c56ecfae0d78c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1940' max='2910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1940/2910 12:05 < 06:03, 2.67 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.151585</td>\n",
       "      <td>0.544928</td>\n",
       "      <td>0.338321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.015206</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.644372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.120800</td>\n",
       "      <td>0.908888</td>\n",
       "      <td>0.704348</td>\n",
       "      <td>0.674941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.120800</td>\n",
       "      <td>0.930583</td>\n",
       "      <td>0.701449</td>\n",
       "      <td>0.690182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.120800</td>\n",
       "      <td>0.945508</td>\n",
       "      <td>0.692754</td>\n",
       "      <td>0.671421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>1.020973</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.692292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>1.117279</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.674360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.636300</td>\n",
       "      <td>1.104755</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.675082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.636300</td>\n",
       "      <td>1.174374</td>\n",
       "      <td>0.686957</td>\n",
       "      <td>0.655242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.636300</td>\n",
       "      <td>1.197047</td>\n",
       "      <td>0.707246</td>\n",
       "      <td>0.659014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating roberta-large on held-out Task 1 test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta-large Test macro-F1: 0.6077\n",
      "roberta-large Test accuracy: 0.6429\n",
      "roberta-large Test loss: 1.1199\n",
      "\n",
      "==== Training microsoft/deberta-v3-large on Task 1 (clarity) ====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f0bc15de23420d9adeafd9e5f1545e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e55af3100d8435e8a77eced55d6c373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f73ffa4f5e418196a34729c5d1f14b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e39192d19224ee9ac7dddd657d79f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3103 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1651cb11ba9e4d248ceb56b34c803acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76fa3c91a9b045a39cc84f3e5802eebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e9a6aeb4ce4dc0b8bd961fe4a0b009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3103 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f357d743f27c4a009fd1d60faee8c899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "870b5e22a8454d5dbfd15611ceffa58d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68928c0952d04998a0041617902902a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/874M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc24d9c63884115a08e3a40dcc89652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/874M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1940' max='2910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1940/2910 23:21 < 11:41, 1.38 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.128595</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.465801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.971670</td>\n",
       "      <td>0.591304</td>\n",
       "      <td>0.609191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.092900</td>\n",
       "      <td>0.929540</td>\n",
       "      <td>0.715942</td>\n",
       "      <td>0.699746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.092900</td>\n",
       "      <td>1.001110</td>\n",
       "      <td>0.675362</td>\n",
       "      <td>0.653081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.092900</td>\n",
       "      <td>1.062161</td>\n",
       "      <td>0.698551</td>\n",
       "      <td>0.667459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.762600</td>\n",
       "      <td>1.064228</td>\n",
       "      <td>0.736232</td>\n",
       "      <td>0.701412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.762600</td>\n",
       "      <td>1.247992</td>\n",
       "      <td>0.707246</td>\n",
       "      <td>0.662020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.590400</td>\n",
       "      <td>1.167956</td>\n",
       "      <td>0.727536</td>\n",
       "      <td>0.694583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.590400</td>\n",
       "      <td>1.208794</td>\n",
       "      <td>0.718841</td>\n",
       "      <td>0.683166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.590400</td>\n",
       "      <td>1.204805</td>\n",
       "      <td>0.727536</td>\n",
       "      <td>0.697142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating microsoft/deberta-v3-large on held-out Task 1 test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/deberta-v3-large Test macro-F1: 0.6695\n",
      "microsoft/deberta-v3-large Test accuracy: 0.711\n",
      "microsoft/deberta-v3-large Test loss: 1.1196\n",
      "\n",
      "==== Building RoBERTa + DeBERTa Ensemble on Task 1 test set ====\n",
      "Ensemble (RoBERTa + DeBERTa) Test accuracy: 0.6948\n",
      "Ensemble (RoBERTa + DeBERTa) Test macro-F1: 0.6501\n",
      "Saved ensemble predictions to: deberta_roberta_task1_ensemble/task1_ensemble_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# !pip install -q transformers datasets scikit-learn accelerate torch pandas\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    "    set_seed,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 4\n",
    "GRAD_ACCUMULATION = 4\n",
    "LR = 8e-6\n",
    "EPOCHS = 15\n",
    "\n",
    "DEBERTA_NAME = \"microsoft/deberta-v3-large\"\n",
    "ROBERTA_NAME = \"roberta-large\"\n",
    "\n",
    "DEBERTA_OUTPUT_DIR = \"./deberta_task1_single\"\n",
    "ROBERTA_OUTPUT_DIR = \"./roberta_task1_single\"\n",
    "\n",
    "ENSEMBLE_NAME = \"deberta_roberta_task1_ensemble\"\n",
    "\n",
    "\n",
    "# Reproducibility\n",
    "\n",
    "def set_deterministic(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_deterministic(SEED)\n",
    "set_seed(SEED)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# Load and preprocess QEvasion (Task 1: clarity_label)\n",
    "\n",
    "dataset = load_dataset(\"ailsntua/QEvasion\")\n",
    "\n",
    "def preprocess(example):\n",
    "    # Same pattern as your DeBERTa script\n",
    "    text = f\"Question: {example['question']} Answer: {example['interview_answer']}\"\n",
    "    return {\"text\": text, \"clarity_label\": example[\"clarity_label\"]}\n",
    "\n",
    "full_train = dataset[\"train\"].map(preprocess)\n",
    "held_out_test_ds = dataset[\"test\"].map(preprocess)\n",
    "\n",
    "# Encode Task 1 labels (3-way clarity)\n",
    "full_train = full_train.class_encode_column(\"clarity_label\")\n",
    "held_out_test_ds = held_out_test_ds.class_encode_column(\"clarity_label\")\n",
    "\n",
    "# Stratified split for train/dev\n",
    "split = full_train.train_test_split(\n",
    "    test_size=0.1,\n",
    "    seed=SEED,\n",
    "    stratify_by_column=\"clarity_label\",\n",
    ")\n",
    "train_ds = split[\"train\"]\n",
    "eval_ds = split[\"test\"]\n",
    "\n",
    "print(f\"Dataset Sizes: Train: {len(train_ds)}, Dev: {len(eval_ds)}, Test: {len(held_out_test_ds)}\")\n",
    "\n",
    "labels = train_ds.features[\"clarity_label\"].names\n",
    "label2id = {name: i for i, name in enumerate(labels)}\n",
    "id2label = {i: name for name, i in label2id.items()}\n",
    "print(f\"Task 1 Labels: {labels}\")\n",
    "\n",
    "# Class weights for imbalance\n",
    "y_train = train_ds[\"clarity_label\"]\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train,\n",
    ")\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "\n",
    "# Metrics\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": (preds == labels).mean(),\n",
    "        \"macro_f1\": f1_score(labels, preds, average=\"macro\"),\n",
    "    }\n",
    "\n",
    "\n",
    "# Custom Trainer with class weights\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss_fct = nn.CrossEntropyLoss(\n",
    "            weight=class_weights_tensor,\n",
    "            label_smoothing=0.1,\n",
    "        )\n",
    "        loss = loss_fct(\n",
    "            logits.view(-1, model.config.num_labels),\n",
    "            labels.view(-1),\n",
    "        )\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "# Helper: tokenization per model\n",
    "\n",
    "def tokenize_dataset_for_model(model_name, train_ds, eval_ds, test_ds):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def tokenize_fn(batch):\n",
    "        return tokenizer(\n",
    "            batch[\"text\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=MAX_LEN,\n",
    "        )\n",
    "\n",
    "    tokenized_train = train_ds.map(tokenize_fn, batched=True)\n",
    "    tokenized_eval = eval_ds.map(tokenize_fn, batched=True)\n",
    "    tokenized_test = test_ds.map(tokenize_fn, batched=True)\n",
    "\n",
    "    # Map clarity_label -> labels\n",
    "    tokenized_train = tokenized_train.map(lambda x: {\"labels\": x[\"clarity_label\"]})\n",
    "    tokenized_eval = tokenized_eval.map(lambda x: {\"labels\": x[\"clarity_label\"]})\n",
    "    tokenized_test = tokenized_test.map(lambda x: {\"labels\": x[\"clarity_label\"]})\n",
    "\n",
    "    # Set format for PyTorch\n",
    "    cols = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "    if \"token_type_ids\" in tokenized_train.column_names:\n",
    "        cols.append(\"token_type_ids\")\n",
    "\n",
    "    tokenized_train.set_format(type=\"torch\", columns=cols)\n",
    "    tokenized_eval.set_format(type=\"torch\", columns=cols)\n",
    "    tokenized_test.set_format(type=\"torch\", columns=cols)\n",
    "\n",
    "    return tokenized_train, tokenized_eval, tokenized_test\n",
    "\n",
    "\n",
    "# Helper: train a single model\n",
    "\n",
    "def train_single_model(model_name, output_dir):\n",
    "    print(f\"\\n==== Training {model_name} on Task 1 (clarity) ====\")\n",
    "\n",
    "    tokenized_train, tokenized_eval, tokenized_test = tokenize_dataset_for_model(\n",
    "        model_name, train_ds, eval_ds, held_out_test_ds\n",
    "    )\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(labels),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        learning_rate=LR,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE * 2,\n",
    "        gradient_accumulation_steps=GRAD_ACCUMULATION,\n",
    "        num_train_epochs=EPOCHS,\n",
    "        weight_decay=0.05,\n",
    "        warmup_ratio=0.1,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"macro_f1\",\n",
    "        greater_is_better=True,\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        report_to=\"none\",\n",
    "        seed=SEED,\n",
    "    )\n",
    "\n",
    "    trainer = WeightedTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_eval,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=4)],\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    print(f\"\\nEvaluating {model_name} on held-out Task 1 test set...\")\n",
    "    test_results = trainer.evaluate(tokenized_test)\n",
    "    print(f\"{model_name} Test macro-F1:\", round(test_results[\"eval_macro_f1\"], 4))\n",
    "    print(f\"{model_name} Test accuracy:\", round(test_results[\"eval_accuracy\"], 4))\n",
    "    print(f\"{model_name} Test loss:\", round(test_results[\"eval_loss\"], 4))\n",
    "\n",
    "    return trainer, tokenized_test\n",
    "\n",
    "\n",
    "# Train RoBERTa-large and DeBERTa-v3-large\n",
    "\n",
    "roberta_trainer, roberta_test = train_single_model(ROBERTA_NAME, ROBERTA_OUTPUT_DIR)\n",
    "deberta_trainer, deberta_test = train_single_model(DEBERTA_NAME, DEBERTA_OUTPUT_DIR)\n",
    "\n",
    "\n",
    "# Ensemble: average logits from both models on the test set\n",
    "\n",
    "print(\"\\n==== Building RoBERTa + DeBERTa Ensemble on Task 1 test set ====\")\n",
    "\n",
    "# Get raw logits (and labels) from both models\n",
    "roberta_preds = roberta_trainer.predict(roberta_test)\n",
    "deberta_preds = deberta_trainer.predict(deberta_test)\n",
    "\n",
    "roberta_logits = roberta_preds.predictions  # shape: (N, num_labels)\n",
    "deberta_logits = deberta_preds.predictions  # shape: (N, num_labels)\n",
    "labels_np = roberta_preds.label_ids         # same as deberta_preds.label_ids\n",
    "\n",
    "# Sanity check\n",
    "assert roberta_logits.shape == deberta_logits.shape, \"Logit shapes differ between models!\"\n",
    "assert np.array_equal(labels_np, deberta_preds.label_ids), \"Label order mismatch!\"\n",
    "\n",
    "# Simple ensemble: average logits\n",
    "ensemble_logits = (roberta_logits + deberta_logits) / 2.0\n",
    "ensemble_preds = np.argmax(ensemble_logits, axis=-1)\n",
    "\n",
    "ensemble_accuracy = (ensemble_preds == labels_np).mean()\n",
    "ensemble_macro_f1 = f1_score(labels_np, ensemble_preds, average=\"macro\")\n",
    "\n",
    "print(f\"Ensemble (RoBERTa + DeBERTa) Test accuracy: {ensemble_accuracy:.4f}\")\n",
    "print(f\"Ensemble (RoBERTa + DeBERTa) Test macro-F1: {ensemble_macro_f1:.4f}\")\n",
    "\n",
    "# Optionally, write out predictions to CSV for analysis\n",
    "os.makedirs(ENSEMBLE_NAME, exist_ok=True)\n",
    "out_path = os.path.join(ENSEMBLE_NAME, \"task1_ensemble_predictions.csv\")\n",
    "\n",
    "# Map back to label strings\n",
    "id2label_str = id2label\n",
    "pred_label_str = [id2label_str[int(i)] for i in ensemble_preds]\n",
    "true_label_str = [id2label_str[int(i)] for i in labels_np]\n",
    "\n",
    "df_out = pd.DataFrame(\n",
    "    {\n",
    "        \"true_label_id\": labels_np,\n",
    "        \"true_label\": true_label_str,\n",
    "        \"pred_label_id\": ensemble_preds,\n",
    "        \"pred_label\": pred_label_str,\n",
    "    }\n",
    ")\n",
    "df_out.to_csv(out_path, index=False)\n",
    "print(f\"Saved ensemble predictions to: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rhz6DVSo1GC4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
